<!doctype html>
<html lang="en"><head><meta charset="utf-8"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"><meta><title>非科班的科班</title><link rel="manifest" href="/manifest.json"><meta name="application-name" content="非科班的科班"><meta name="msapplication-TileImage" content="https://cdn.jsdelivr.net/gh/removeif/removeif-demo@latest/img/favicon.png"><meta name="apple-mobile-web-app-capable" content="yes"><meta name="apple-mobile-web-app-title" content="非科班的科班"><meta name="apple-mobile-web-app-status-bar-style" content="default"><meta description="一个钻研技术和热爱技术分享的博主"><meta property="og:type" content="blog"><meta property="og:title" content="非科班的科班"><meta property="og:url" content="https://removeif.github.io/"><meta property="og:site_name" content="非科班的科班"><meta property="og:description" content="一个钻研技术和热爱技术分享的博主"><meta property="og:locale" content="en_US"><meta property="og:image" content="https://pic3.zhimg.com/v2-bfd9b8d48b2d2ef0bcd80d2cc4cc6604_xl.jpg"><meta property="article:author" content="黎杜"><meta property="twitter:card" content="summary"><meta property="twitter:image" content="https://pic3.zhimg.com/v2-bfd9b8d48b2d2ef0bcd80d2cc4cc6604_xl.jpg"><script type="application/ld+json">{"@context":"https://schema.org","@type":"BlogPosting","mainEntityOfPage":{"@type":"WebPage","@id":"http://example.com"},"headline":"非科班的科班","image":["http://example.com/img/og_image.png"],"author":{"@type":"Person","name":"黎杜"},"description":"专注于技术钻研与分享的技术博主"}</script><link rel="icon" href="https://cdn.jsdelivr.net/gh/removeif/removeif-demo@latest/img/favicon.png"><link rel="stylesheet" href="https://cdnjs.loli.net/ajax/libs/font-awesome/5.12.0/css/all.min.css"><link rel="stylesheet" href="https://cdnjs.loli.net/ajax/libs/highlight.js/9.12.0/styles/atom-one-light.min.css"><link rel="stylesheet" href="https://fonts.loli.net/css2?family=Ubuntu:wght@400;600&amp;family=Source+Code+Pro"><link rel="stylesheet" href="/css/default.css"><link rel="stylesheet" href="https://cdnjs.loli.net/ajax/libs/font-awesome/5.12.0/css/all.min.css"><link rel="stylesheet" href="https://fonts.loli.net/css?family=Ubuntu:400,600|Source+Code+Pro|Monda:300,300italic,400,400italic,700,700italic|Roboto Slab:300,300italic,400,400italic,700,700italic|Microsoft YaHei:300,300italic,400,400italic,700,700italic|PT Mono:300,300italic,400,400italic,700,700italic&amp;amp;subset=latin,latin-ext|Inconsolata|Itim|Lobster.css"><script src="https://cdnjs.loli.net/ajax/libs/jquery/3.3.1/jquery.min.js"></script><script src="/js/globalUtils.js"></script><style>body>.footer,body>.navbar,body>.section{opacity:0}</style><!--!--><!--!--><script src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js" defer></script><!--!--><link rel="stylesheet" href="https://cdnjs.loli.net/ajax/libs/lightgallery/1.6.8/css/lightgallery.min.css"><link rel="stylesheet" href="https://cdnjs.loli.net/ajax/libs/justifiedGallery/3.7.0/css/justifiedGallery.min.css"><!--!--><!--!--><script src="https://cdnjs.loli.net/ajax/libs/pace/1.0.2/pace.min.js"></script><link rel="stylesheet" href="/live2d/waifu.css"><script type="text/javascript" async src="/live2d/autoload.js"></script><meta name="generator" content="Hexo 5.2.0"></head><body class="is-3-column has-navbar-fixed-top"><nav class="navbar navbar-main is-fixed-top"><div class="container"><div class="navbar-brand justify-content-center"><a class="navbar-item navbar-logo" href="/"><img src="https://cdn.jsdelivr.net/gh/removeif/removeif-demo@latest/img/logo.png" alt="非科班的科班" height="28"></a></div><div class="navbar-menu"><div class="navbar-start"><a class="navbar-item" href="/">主页</a><a class="navbar-item" href="/archives">归档</a><a class="navbar-item" href="/categories">分类</a><a class="navbar-item" href="/tags">标签</a><a class="navbar-item" href="/about">关于</a><a class="navbar-item" href="/friend">友情</a><a class="navbar-item" href="/message">留言</a></div><div class="navbar-end"><a class="navbar-item" target="_blank" rel="noopener" title="Download on GitHub" href="https://github.com/liduchang?tab=repositories"><i class="fab fa-github"></i></a><a class="navbar-item search" title="Search" href="javascript:;"><i class="fas fa-search"></i></a><a class="navbar-item" id="night-nav" title="Night Mode" href="javascript:;"><i class="fas fa-moon" id="night-icon"></i></a></div></div></div></nav><script type="text/javascript" src="/js/theme-setting.js"></script><section class="section"><div class="container"><div class="columns"><div class="column order-2 column-main is-8-tablet is-8-desktop is-6-widescreen"><!--!--><div class="card"><article class="card-content article" role="article"><div class="article-meta size-small is-uppercase level is-mobile"><div class="level-left"><i class="far fa-calendar-plus"> </i>2020-10-14  <a class="commentCountImg" href="/2020/10/14/%E6%88%91%E4%BB%A5%E4%B8%BA%E6%88%91%E5%AF%B9Mysql%E4%BA%8B%E5%8A%A1%E5%BE%88%E7%86%9F%EF%BC%8C%E7%9B%B4%E5%88%B0%E6%88%91%E9%81%87%E5%88%B0%E4%BA%86%E9%98%BF%E9%87%8C%E9%9D%A2%E8%AF%95%E5%AE%98/#comment-container"><span class="display-none-class">d41d8cd98f00b204e9800998ecf8427e</span><i class="far fa-comment-dots"></i> <span class="commentCount" id="d41d8cd98f00b204e9800998ecf8427e">99+</span>  </a><span class="level-item"><i class="far fa-clock"> </i>32 m  <i class="fas fa-pencil-alt"> </i>4.8 k</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2020/10/14/%E6%88%91%E4%BB%A5%E4%B8%BA%E6%88%91%E5%AF%B9Mysql%E4%BA%8B%E5%8A%A1%E5%BE%88%E7%86%9F%EF%BC%8C%E7%9B%B4%E5%88%B0%E6%88%91%E9%81%87%E5%88%B0%E4%BA%86%E9%98%BF%E9%87%8C%E9%9D%A2%E8%AF%95%E5%AE%98/"> </a></h1><div class="content"><h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>迎面走来了一个风尘仆仆的身穿格子衫的男子，手里拿着一个MacBook Pro，看着那稀少的发量，和那从容淡定的眼神。</p>
<p>我心里一颤，我去，这是架构师，架构师来面我技术面，我心里顿时不淡定了，表面很稳实则心里慌得一批。</p>
<p>果然，他手里拿着我的简历，快速的扫了一下，然后用眼角余光看了一下我，上来就开问。</p>
<h2 id="Mysql事务简介"><a href="#Mysql事务简介" class="headerlink" title="Mysql事务简介"></a>Mysql事务简介</h2><p><strong>面试官：</strong> 看你简历上说精通Mysql优化方法，你先来说说你对Mysql的事务的了解吧。</p>
<p>我心里喜了一下，这个简单啊，哥我可是北大(背大)的，再来面试之前，早就有准备的，二话不说，上去就是背。</p>
<p><strong>我：</strong> 好的，数据库的事务是指一组sql语句组成的数据库逻辑处理单元，在这组的sql操作中，要么全部执行成功，要么全部执行失败。</p>
<p><strong>我：</strong> 这里的一组sql操作，举个简单又经典的例子就是转账了，事务A中要进行转账，那么转出的账号要扣钱，转入的账号要加钱，这两个操作都必须同时执行成功，为了确保数据的一致性。</p>
<p><strong>面试官：</strong> 刚才你提到了数据一致性，你知道事务的特性吗？说说你的理解。</p>
<h2 id="ACID简介"><a href="#ACID简介" class="headerlink" title="ACID简介"></a>ACID简介</h2><p><strong>我：</strong> 在Mysql中事务的四大特性主要包含：<strong>原子性（Atomicity）</strong>、<strong>一致性（Consistent）</strong>、<strong>隔离性（Isalotion）</strong>、**持久性(Durable)**，简称为<code>ACID</code>。</p>
<p><strong>我：</strong> 原子性是指事务的原子性操作，对数据的修改要么全部执行成功，要么全部失败，实现事务的原子性，是基于日志的<code>Redo/Undo</code>机制。</p>
<p><strong>我：</strong> 一致性是指执行事务前后的状态要一致，可以理解为数据一致性。隔离性侧重指事务之间相互隔离，不受影响，这个与事务设置的隔离级别有密切的关系。</p>
<p><strong>我：</strong> 持久性则是指在一个事务提交后，这个事务的状态会被持久化到数据库中，也就是事务提交，对数据的新增、更新将会持久化到书库中。</p>
<p><strong>我：</strong> 在我的理解中，原子性、隔离性、持久性都是为了保障一致性而存在的，一致性也是最终的目的。</p>
<p>心里暗自欢喜，背完了，平时背的多，面试就会说，幸好难不倒我。</p>
<h2 id="ACID原理"><a href="#ACID原理" class="headerlink" title="ACID原理"></a>ACID原理</h2><p><strong>面试官：</strong> 刚才你说原子性是基于日志的<code>Redo/Undo</code>机制，你能说一说<code>Redo/Undo</code>机制吗？</p>
<p>啊哈？我都说了什么，不小心给自己埋了一颗大雷。不慌，哥脑子里还有货，假装若有所思的停了几十秒，接着背。</p>
<p><strong>我：</strong> Redo/Undo机制比较简单，它们将所有对数据的更新操作都写到日志中。</p>
<p><strong>我：</strong> Redo log用来记录某数据块被修改后的值，可以用来恢复未写入 data file 的已成功事务更新的数据；Undo log是用来记录数据更新前的值，保证数据更新失败能够回滚。</p>
<p><strong>我：</strong> 假如数据库在执行的过程中，不小心崩了，可以通过该日志的方式，回滚之前已经执行成功的操作，实现事务的一致性。</p>
<p><strong>面试官：</strong> 可以举一个场景，说一下具体的实现流程吗？</p>
<p><strong>我：</strong> 可以的，假如某个时刻数据库崩溃，在崩溃之前有事务A和事务B在执行，事务A已经提交，而事务B还未提交。当数据库重启进行 crash-recovery 时，就会通过Redo log将已经提交事务的更改写到数据文件，而还没有提交的就通过Undo log进行roll back。</p>
<h2 id="事务隔离级别"><a href="#事务隔离级别" class="headerlink" title="事务隔离级别"></a>事务隔离级别</h2><p><strong>面试官：</strong>  之前你还提到事务的隔离级别，你能说一说吗？</p>
<p><strong>我：</strong> 可以的，在Mysql中事务的隔离级别分为四大等级，<strong>读未提交（READ UNCOMMITTED）、读提交 （READ COMMITTED）、可重复读 （REPEATABLE READ）、串行化 （SERIALIZABLE）</strong>。</p>
<p><strong>我：</strong> 读未提交会读到另一个事务的未提交的数据，产生脏读问题，读提交则解决了脏读的，出现了不可重复读，即在一个事务任意时刻读到的数据可能不一样，可能会受到其它事务对数据修改提交后的影响，一般是对于update的操作。</p>
<p><strong>我：</strong> 可重复读解决了之前不可重复读和脏读的问题，但是由带来了幻读的问题，幻读一般是针对inser操作。</p>
<p><strong>我：</strong> 例如：第一个事务查询一个User表id=100发现不存在该数据行，这时第二个事务又进来了，新增了一条id=100的数据行并且提交了事务。</p>
<p><strong>我：</strong>  这时第一个事务新增一条id=100的数据行会报主键冲突，第一个事务再select一下，发现id=100数据行已经存在，这就是幻读。</p>
<p><strong>面试官：</strong>  小伙子你能演示一下吗？我不太会你能教教我吗？我电脑在这里，你演示我看一看。</p>
<p>男人的嘴骗人的鬼，我信你个鬼，你这糟老头子坏得很，出来装X总是要还的，只能默默含泪把它敲完。</p>
<p><strong>我：</strong> 首先创建一个User表，最为一个测试表，测试表里面有三个字段，并插入两条测试数据。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">CREATE TABLE User (</span><br><span class="line">  id INT(11) NOT NULL PRIMARY KEY AUTO_INCREMENT,</span><br><span class="line">  name VARCHAR(20),</span><br><span class="line">  age INT	DEFAULT 0</span><br><span class="line">) ENGINE&#x3D;InnoDB DEFAULT CHARSET&#x3D;gb2312;</span><br><span class="line"></span><br><span class="line">INSERT INTO &#96;user&#96; VALUES (1, &#39;zhangsan&#39;, 23);</span><br><span class="line">INSERT INTO &#96;user&#96; VALUES (2, &#39;lisi&#39;, 20);</span><br></pre></td></tr></table></figure>

<p><strong>我：</strong> 再Mysql中可以先查询一下他的默认隔离级别，可以看出Mysql的默认隔离级别是<code>REPEATABLE-READ</code>。<br><img src="https://img-blog.csdnimg.cn/20200531105115699.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQzMjU1MDE3,size_16,color_FFFFFF,t_70"><br><strong>我：</strong> 先来演示一下读未提交，先把默认的隔离级别修改为<code>READ UNCOMMITTED</code>。<br><img src="https://img-blog.csdnimg.cn/20200531110409614.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQzMjU1MDE3,size_16,color_FFFFFF,t_70"><br><strong>我：</strong> 他设置隔离级别的语句中set global transaction isolation level read uncommitted，这里的global也可以换成session，global表示全局的，而session表示当前会话，也就是当前窗口有效。</p>
<p><strong>我：</strong> 当设置完隔离级别后对于之前打开的会话，是无效的，要重新打开一个窗口设置隔离级别才生效。<br><img src="https://img-blog.csdnimg.cn/20200531110815371.png"><br><strong>我：</strong> 然后是开启事务，Mysql中开启事务有两种方式<code>begin/start transaction</code>，最后提交事务执行commit，或者回滚事务rollback。</p>
<p><strong>我：</strong> 在执行<code>begin/start transaction</code>命令，它们并不是一个事务的起点，在执行完它们后的第一个sql语句，才表示事务真正的启动 。</p>
<p><strong>我：</strong> 这里直接打开两个新的窗口，同时开启事务，再第一个窗口先update一个id=1的数据行name改为’非科班的科班’，执行成功。<br><img src="https://img-blog.csdnimg.cn/20200531111427949.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQzMjU1MDE3,size_16,color_FFFFFF,t_70"><br><strong>我：</strong> 然后再第二个窗口执行两次的查询，分别是窗口一update之前的查询和update之后的查询。<br><img src="https://img-blog.csdnimg.cn/20200531111645609.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQzMjU1MDE3,size_16,color_FFFFFF,t_70"><br><strong>我：</strong> 第一个session产生的未提交的事务的状态就会直接影响到第二sesison，也就是脏读。</p>
<p><strong>我：</strong> 对于读提交也是一样的，开启事务后，第一个事务先执行查询数据，然后第二个session执行update操作，但是还没有commit，这是第一个session再次select，数据并没有改变，再第二个session执行commit之后，第一个session再次select就是改变后的数据了。<br><img src="https://img-blog.csdnimg.cn/20200531113003546.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQzMjU1MDE3,size_16,color_FFFFFF,t_70"><br><strong>我：</strong> 这样第一个事务的查询结果就会收到第二事务的影响，这个也就是产生不可重复读的问题。</p>
<p><strong>面试官：</strong>  小伙子你能画一下他执行的过程图吗？你讲的我有点乱，我还没有彻底明白。</p>
<p>我心里一万只什么马在飞过，欲哭无泪，这面试官真难伺候，说时迟那时快，从左屁股兜抽出笔，从右屁股兜拿出纸，开始画。<br><img src="https://img-blog.csdnimg.cn/20200531154702184.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQzMjU1MDE3,size_16,color_FFFFFF,t_70"><br><strong>我：</strong> 这个是读提交的时间轴图，读未提交的时间轴突，原理也一样的，第二个select的时候数据就已经改变了。</p>
<p>这是面试官拿过我的图看了一点，微微的点了点头，嘴角露出思思的笑意，我想你这糟老头子应该不会再刁难我了吧。</p>
<p><strong>面试官：</strong>  嗯，你接着演示你的可重复读吧。</p>
<p><strong>我：</strong> 嗯，好的，然后就是可重复读，和之前一样的操作。<br><img src="https://img-blog.csdnimg.cn/20200531115041123.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQzMjU1MDE3,size_16,color_FFFFFF,t_70"><br><strong>我：</strong> 将两个session开启为<code>REPEATABLE READ</code>，同时开启事务，再第一个事务中先select，然后在第二个事务里面update数据行，可以发现即使第二个事务已经commit，第一个事务再次select数据也还是没有改变，这就解决了不可重复读的问题。</p>
<p><strong>我：</strong> 这里有个不同的地方就是在Mysql中，默认的不可重复读个隔离级别也解决了幻读的问题。</p>
<p><strong>我：</strong> 从上面的演示中可以看出第一个事务中先select一个id=3的数据行，这条数据行是不存在的，返回Empty set，然后第二个事务中insert一条id=3的数据行并且commit，第一个事务中再次select的，数据也好是没有id=3的数据行。</p>
<p><strong>我：</strong> 最后的串行化，样式步骤也是一样的，结果也和Mysql中默认的个可重复读隔离级别的结果一样，串行化的执行流程相当于把事务的执行过程变为顺序执行，我这边就不再做演示了。</p>
<p><strong>我：</strong> 这四大等级从上到下，隔离的效果是逐渐增强，但是性能却是越来越差。</p>
<h2 id="Mysql的锁机制"><a href="#Mysql的锁机制" class="headerlink" title="Mysql的锁机制"></a>Mysql的锁机制</h2><p><strong>面试官：</strong>  哦？性能越来越差？为什么会性能越来越差？你能说一说原因吗？</p>
<p>哎呀，我这嘴，少说一句会死啊，这下好了，这个得说底层实现原理了，从原来得假装若有所思，变成了真正得若有所思。</p>
<p><strong>我：</strong> 这个得从Mysq的锁说起，在Mysql中的锁可以分为分<strong>享锁/读锁（Shared Locks）</strong>、<strong>排他锁/写锁（Exclusive Locks）</strong> 、<strong>间隙锁</strong>、<strong>行锁（Record Locks）</strong>、<strong>表锁</strong>。</p>
<p><strong>我：</strong> 在四个隔离级别中加锁肯定是要消耗性能的，而读未提交是没有加任何锁的，所以对于它来说也就是没有隔离的效果，所以它的性能也是最好的。</p>
<p><strong>我：</strong> 对于串行化加的是一把大锁，读的时候加共享锁，不能写，写的时候，家的是排它锁，阻塞其它事务的写入和读取，若是其它的事务长时间不能写入就会直接报超时，所以它的性能也是最差的，对于它来就没有什么并发性可言。</p>
<p><strong>我：</strong> 对于读提交和可重复读，他们俩的实现是兼顾解决数据问题，然后又要有一定的并发行，所以在实现上锁机制会比串行化优化很多，提高并发性，所以性能也会比较好。</p>
<h2 id="事务底层实现原理"><a href="#事务底层实现原理" class="headerlink" title="事务底层实现原理"></a>事务底层实现原理</h2><p><strong>我：</strong> 他们俩的底层实现采用的是MVCC（多版本并发控制）方式进行实现。</p>
<p><strong>面试官：</strong>  你能先说一下先这几个锁的概念吗？我不是很懂，说说你的理解。</p>
<p><strong>我：</strong> 哦，好的，共享锁是针对同一份数据，多个读操作可以同时进行，简单来说即读加锁，不能写并且可并行读；排他锁针对写操作，假如当前写操作没有完成，那么它会阻断其它的写锁和读锁，即写加锁，其它读写都阻塞 。</p>
<p><strong>我：</strong> 而行锁和表锁，是从锁的粒度上进行划分的，行锁锁定当前数据行，锁的粒度小，加锁慢，发生锁冲突的概率小，并发度高，行锁也是MyISAM和InnoDB的区别之一，InnoDB支持行锁并且支持事务 。</p>
<p><strong>我：</strong> 而表锁则锁的粒度大，加锁快，开销小，但是锁冲突的概率大，并发度低。</p>
<p><strong>我：</strong> 间隙锁则分为两种：<code>Gap Locks</code>和<code>Next-Key Locks</code>。Gap Locks会锁住两个索引之间的区间，比如select * from User where id&gt;3 and id&lt;5 for update，就会在区间（3，5）之间加上Gap Locks。</p>
<p><strong>我：</strong> Next-Key Locks是Gap Locks+Record Locks形成闭区间锁select * from User where id&gt;=3 and id=&lt;5 for update，就会在区间[3,5]之间加上Next-Key Locks。</p>
<p><strong>面试官：</strong>  那Mysql中什么时候会加锁呢？</p>
<p><strong>我：</strong>  在数据库的增、删、改、查中，只有增、删、改才会加上排它锁，而只是查询并不会加锁，只能通过在select语句后显式加lock in share mode或者for update来加共享锁或者排它锁。</p>
<p><strong>面试官：</strong>  你在上面提到MVCC（多版本并发控制），你能说一说原理吗？</p>
<p><strong>我：</strong>  在实现MVCC时用到了一致性视图，用于支持读提交和可重复读的实现。</p>
<p><strong>我：</strong>  在实现可重复读的隔离级别，只需要在事务开始的时候创建一致性视图，也叫做快照，之后的查询里都共用这个一致性视图，后续的事务对数据的更改是对当前事务是不可见的，这样就实现了可重复读。</p>
<p><strong>我：</strong>  而读提交，每一个语句执行前都会重新计算出一个新的视图，这个也是可重复读和读提交在MVCC实现层面上的区别。</p>
<p><strong>面试官：</strong> 那你知道快照（视图）在MVCC底层是怎么工作的吗？</p>
<p><strong>我：</strong> 在InnoDB 中每一个事务都有一个自己的事务id，并且是唯一的，递增的 。</p>
<p><strong>我：</strong> 对于Mysql中的每一个数据行都有可能存在多个版本，在每次事务更新数据的时候，都会生成一个新的数据版本，并且把自己的数据id赋值给当前版本的row trx_id。</p>
<p><strong>面试官：</strong> 小伙子你可以画个图我看看吗？我不是很明白。</p>
<p>我有什么办法呢？完全没办法，只能又从屁股兜李拿出笔和纸，迅速的画了起来，相当这次面试要是不过血亏啊，浪费了我两张纸和笔水，多贵啊，只能豁出去了。</p>
<p><img src="https://img-blog.csdnimg.cn/20200531214014768.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQzMjU1MDE3,size_16,color_FFFFFF,t_70"><br><strong>我：</strong> 如图中所示，假如三个事务更新了同一行数据，那么就会有对应的三个数据版本。</p>
<p><strong>我：</strong> 实际上版本1、版本2并非实际物理存在的，而图中的U1和U2实际就是undo log，这v1和v2版本是根据当前v3和undo log计算出来的。</p>
<p><strong>面试官：</strong> 那对于一个快照来说，你直到它要遵循什么规则吗？</p>
<p><strong>我：</strong> 嗯，对于一个事务视图来说除了对自己更新的总是可见，另外还有三种情况：版本未提交的，都是不可见的；版本已经提交，但是是在创建视图之后提交的也是不可见的；版本已经提交，若是在创建视图之前提交的是可见的。</p>
<p><strong>面试官：</strong> 假如两个事务执行写操作，又怎么保证并发呢？</p>
<p><strong>我：</strong> 假如事务1和事务2都要执行update操作，事务1先update数据行的时候，先回获取行锁，锁定数据，当事务2要进行update操作的时候，也会取获取该数据行的行锁，但是已经被事务1占有，事务2只能wait。</p>
<p><strong>我：</strong> 若是事务1长时间没有释放锁，事务2就会出现超时异常 。</p>
<p><strong>面试官：</strong> 这个是在update的where后的条件是在有索引的情况下吧？</p>
<p><strong>我：</strong> 嗯，是的 。</p>
<p><strong>面试官：</strong> 那没有索引的条件下呢？没办法快速定位到数据行呢？</p>
<p><strong>我：</strong> 若是没有索引的条件下，就获取所有行，都加上行锁，然后Mysql会再次过滤符合条件的的行并释放锁，只有符合条件的行才会继续持有锁。</p>
<p><strong>我：</strong> 这样的性能消耗也会比较大。</p>
<p><strong>面试官：</strong> 嗯嗯</p>
<p>此时面试官看看手表一个多钟已经过去了，也已经到了饭点时刻，我想他应该是肚子饿了，不会继续追问吧，两人持续僵了三十秒，他终于开口了。</p>
<p><strong>面试官：</strong> 小伙子，现在时间也已经到了饭点了，今天的面试就到此结束吧，你回去等通知吧。</p>
<p><strong>我：</strong> 。。。。。。。。。。</p>
</div><div class="index-category-tag">  <hr></div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta size-small is-uppercase level is-mobile"><div class="level-left"><i class="far fa-calendar-plus"> </i>2020-10-14  <a class="commentCountImg" href="/2020/10/14/%E9%98%BF%E9%87%8CP6+%E7%9A%84Mysql%E9%94%81%E6%9C%BA%E5%88%B6%E4%BA%8C%E9%9D%A2%E8%AF%95%E6%80%BB%E7%BB%93%EF%BC%8C%E5%80%BC%E5%BE%97%E6%94%B6%E8%97%8F/#comment-container"><span class="display-none-class">d41d8cd98f00b204e9800998ecf8427e</span><i class="far fa-comment-dots"></i> <span class="commentCount" id="d41d8cd98f00b204e9800998ecf8427e">99+</span>  </a><span class="level-item"><i class="far fa-clock"> </i>43 m  <i class="fas fa-pencil-alt"> </i>6.5 k</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2020/10/14/%E9%98%BF%E9%87%8CP6+%E7%9A%84Mysql%E9%94%81%E6%9C%BA%E5%88%B6%E4%BA%8C%E9%9D%A2%E8%AF%95%E6%80%BB%E7%BB%93%EF%BC%8C%E5%80%BC%E5%BE%97%E6%94%B6%E8%97%8F/"> </a></h1><div class="content"><h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>前几天有粉丝和我聊到他找工作面试大厂时被问的问题，因为现在疫情期间，找工作也特别难找。他说面试的题目也比较难，都偏向于一两年的工作经验的面试题。</p>
<p>他说在一面的时候被问到Mysql的面试题，索引那块自己都回答比较满意，但是问到Mysql的锁机制就比较懵了。</p>
<p>因为平时没有关注Mysql的锁机制，当被问到高并发场景下锁机制是怎么保证数据的一致性的和事务隔离性的。</p>
<p>他把他面试的过程分享给了我，Mysql高并发锁机制的问题，几乎面大厂都有被问到，Mysql怎么在高并发下控制并发访问的？</p>
<p>我细想了一下，Mysql的锁机制确实非常重要，所以在这里做一个全面的总结整理，便于以后的查阅，也分享给各位读者大大们。</p>
<p>Mysql的锁机制还是有点难理解的，所以这篇文章采用图文结合的方式讲解难点，帮助大家理解，讲解的主要内容如下图的脑图所示，基本涵盖了Mysql锁机制的所有知识点。</p>
<h2 id="本文脑图"><a href="#本文脑图" class="headerlink" title="本文脑图"></a>本文脑图</h2><p><img src="https://img-blog.csdnimg.cn/20200620102235265.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQzMjU1MDE3,size_16,color_FFFFFF,t_70"></p>
<h2 id="锁种类"><a href="#锁种类" class="headerlink" title="锁种类"></a>锁种类</h2><p>Mysql中锁的分类按照不同类型的划分可以分成不同的锁，按照<strong>锁的粒度</strong>划分可以分成：<strong>表锁、页锁、行锁</strong>；按照<strong>使用的方式</strong>划分可以分为：<strong>共享锁</strong>和<strong>排它锁</strong>；按照思想的划分：<strong>乐观锁</strong>和<strong>悲观锁</strong>。</p>
<p>下面我们对着这几种划分的锁进行详细的解说和介绍，在了解设计者设计锁的概念的同时，也能深入的理解设计者的设计思想。</p>
<p><strong>表锁</strong>是粒度最大的锁，开销小，加锁快，不会出现死锁，但是由于粒度太大，因此造成锁的冲突几率大，并发性能低。</p>
<p>Mysql中<strong>MyISAM储存引擎就支持表锁</strong>，MyISAM的表锁模式有两种：<strong>表共享读锁</strong>和<strong>表独占写锁</strong>。</p>
<p>当一个线程获取到MyISAM表的读锁的时候，会阻塞其他用户对该表的写操作，但是不会阻塞其它用户对该用户的读操作。</p>
<p>相反的，当一个线程获取到MyISAM表的写锁的时候，就会阻塞其它用户的读写操作对其它的线程具有排它性。</p>
<p><strong>页锁</strong>的粒度是介于行锁和表锁之间的一种锁，因为页锁是在BDB中支持的一种锁机制，也很少没人提及和使用，所以这里制作概述，不做详解。</p>
<p><strong>行锁</strong>是粒度最小的锁机制，行锁的加锁开销性能大，加锁慢，并且会出现死锁，但是行锁的锁冲突的几率低，并发性能高。</p>
<p>行锁是InnoDB默认的支持的锁机制，MyISAM不支持行锁，这个也是InnoDB和MyISAM的区别之一。</p>
<p>行锁在使用的方式上可以划分为：<strong>共享读锁（S锁）</strong>和<strong>排它写锁（X锁）</strong>。</p>
<p>当一个事务对Mysql中的一条数据行加上了S锁，当前事务不能修改该行数据只能执行度操作，其他事务只能对该行数据加S锁不能加X锁。</p>
<p>若是一个事务对一行数据加了X锁，该事物能够对该行数据执行读和写操作，其它事务不能对该行数据加任何的锁，既不能读也不能写。</p>
<p><strong>悲观锁和乐观锁是在很多框架都存在的一种思想，不要狭义地认为它们是某一种框架的锁机制</strong>。</p>
<p>数据库管理系统中为了控制并发，保证在多个事务执行时的数据一致性以及事务的隔离性，使用悲观锁和乐观锁来解决并发场景下的问题。</p>
<p>Mysql中<strong>悲观锁的实现是基于Mysql自身的锁机制实现，而乐观锁需要程序员自己去实现的锁机制</strong>，最常见的乐观锁实现就锁机制是<strong>使用版本号实现</strong>。</p>
<p>乐观锁设计思想的在<code>CAS</code>的运用也是比较经典，之前我写过一篇关于CAS的文章，大家感兴趣的可以参考这一篇[]。</p>
<p>从上面的介绍中说了每一种锁的概念，但是很难说哪一种锁就是最好的，锁没有最好的，只有哪种业务场景最适合哪种锁，具体业务具体分析。</p>
<p>下面我们就具体基于Mysql的存储引擎详细的分析每一种锁在存储引擎中的运用和实现。</p>
<h2 id="MyISAM"><a href="#MyISAM" class="headerlink" title="MyISAM"></a>MyISAM</h2><p>MyISAM中默认支持的表级锁有两种：<strong>共享读锁</strong>和<strong>独占写锁</strong>。表级锁在MyISAM和InnoDB的存储引擎中都支持，但是InnoDB默认支持的是行锁。</p>
<p>Mysql中平时读写操作都是隐式的进行加锁和解锁操作，Mysql已经自动帮我们实现加锁和解锁操作了，若是想要测试锁机制，我们就要显示的自己控制锁机制。</p>
<p>Mysql中可以通过以下sql来显示的在事务中显式的进行加锁和解锁操作：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">&#x2F;&#x2F; 显式的添加表级读锁</span><br><span class="line">LOCK TABLE 表名 READ</span><br><span class="line">&#x2F;&#x2F; 显示的添加表级写锁</span><br><span class="line">LOCK TABLE 表名 WRITE</span><br><span class="line">&#x2F;&#x2F; 显式的解锁（当一个事务commit的时候也会自动解锁）</span><br><span class="line">unlock tables;</span><br></pre></td></tr></table></figure>
<p>下面我们就来测试一下MyISAM中的表级锁机制，首先创建一个测试表<code>employee</code> ，这里要指定存储引擎为MyISAM，并插入两条测试数据：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">CREATE TABLE IF NOT EXISTS employee (</span><br><span class="line">    id INT PRIMARY KEY auto_increment,</span><br><span class="line">    name VARCHAR(40),</span><br><span class="line">    money INT</span><br><span class="line">)ENGINE MyISAM</span><br><span class="line"></span><br><span class="line">INSERT INTO employee(name, money) VALUES(&#39;黎杜&#39;, 1000);</span><br><span class="line">INSERT INTO employee(name, money) VALUES(&#39;非科班的科班&#39;, 2000);</span><br></pre></td></tr></table></figure>
<p>查看一下，表结果如下图所示：<br><img src="https://img-blog.csdnimg.cn/20200621161832765.png"></p>
<h3 id="MyISAM表级写锁"><a href="#MyISAM表级写锁" class="headerlink" title="MyISAM表级写锁"></a>MyISAM表级写锁</h3><p>（1）与此同时再开启一个session窗口，然后在第一个窗口执行下面的sql，在session1中给表添加写锁：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">LOCK TABLE employee WRITE</span><br></pre></td></tr></table></figure>
<p>（2）可以在session2中进行查询或者插入、更新该表数据，可以发现都会处于等待状态，也就是session1锁住了整个表，导致session2只能等待：<br><img src="https://img-blog.csdnimg.cn/20200621165218743.png"><br>（3）在session1中进行查询、插入、更新数据，都可以执行成功：<br><img src="https://img-blog.csdnimg.cn/20200621165401984.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQzMjU1MDE3,size_16,color_FFFFFF,t_70"><br><strong>总结：</strong> 从上面的测试结果显示<strong>当一个线程获取到表级写锁后，只能由该线程对表进行读写操作，别的线程必须等待该线程释放锁以后才能操作</strong>。</p>
<h3 id="MyISAM表级共享读锁"><a href="#MyISAM表级共享读锁" class="headerlink" title="MyISAM表级共享读锁"></a>MyISAM表级共享读锁</h3><p>（1）接下来测试一下表级共享读锁，同样还是利用上面的测试数据，第一步还是在session1给表加读锁。<br><img src="https://img-blog.csdnimg.cn/20200621202719205.png"><br>（2）然后在session1中尝试进行插入、更新数据，发现都会报错，只能查询数据。<br><img src="https://img-blog.csdnimg.cn/20200621202937489.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQzMjU1MDE3,size_16,color_FFFFFF,t_70"><br>（3）最后在session2中尝试进行插入、更新数据，程序都会进入等待状态，只能查询数据，直到session1解锁表session2才能插入、更新数据。<br><img src="https://img-blog.csdnimg.cn/20200621203135851.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQzMjU1MDE3,size_16,color_FFFFFF,t_70"><br><strong>总结：</strong> 从上面的测试结果显示<strong>当一个线程获取到表级读锁后，该线程只能读取数据不能修改数据，其它线程也只能加读锁，不能加写锁</strong>。</p>
<h3 id="MyISAM表级锁竞争情况"><a href="#MyISAM表级锁竞争情况" class="headerlink" title="MyISAM表级锁竞争情况"></a>MyISAM表级锁竞争情况</h3><p>MyISAM存储引擎中，可以通过查询变量来查看并发场景锁的争夺情况，具体执行下面的sql语句：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">show status like &#39;table%&#39;;</span><br></pre></td></tr></table></figure>
<p><img src="https://img-blog.csdnimg.cn/20200621204431202.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQzMjU1MDE3,size_16,color_FFFFFF,t_70"><br>主要是查看<code>table_locks_waited</code>和<code>table_locks_immediate</code>的值的大小分析锁的竞争情况。</p>
<p><code>Table_locks_immediate</code>：表示能够立即获得表级锁的锁请求次数；<code>Table_locks_waited</code>表示不能立即获取表级锁而需要等待的锁请求次数分析，<strong>值越大竞争就越严重</strong>。</p>
<h3 id="并发插入"><a href="#并发插入" class="headerlink" title="并发插入"></a>并发插入</h3><p>通过上面的操作演示，详细的说明了表级共享锁和表级写锁的特点。但是在平时的执行sql的时候，这些<strong>解锁和释放锁都是Mysql底层隐式的执行的</strong>。</p>
<p>上面的演示只是为了证明显式的执行事务的过程共享锁和表级写锁的加锁和解锁的特点，实际并不会这么做的。</p>
<p>在我们平时执行select语句的时候就会隐式的加读锁，执行增、删、改的操作时就会隐式的执行加写锁。</p>
<p>MyISAM存储引擎中，虽然读写操作是串行化的，但是它也支持并发插入，这个需要设置内部变量<code>concurrent_insert</code>的值。</p>
<p>它的值有三个值<code>0、1、2</code>。可以通过以下的sql查看<code>concurrent_insert</code>的默认值为**AUTO(或者1)**。<br><img src="https://img-blog.csdnimg.cn/20200621210320525.png"><br>concurrent_insert的值为<code>NEVER (or 0)</code>表示不支持比并发插入；值为<code>AUTO(或者1）</code>表示在MyISAM表中没有被删除的行，运行另一个线程从表尾插入数据；值为<code>ALWAYS (or 2)</code>表示不管是否有删除的行，都允许在表尾插入数据。</p>
<h3 id="锁调度"><a href="#锁调度" class="headerlink" title="锁调度"></a>锁调度</h3><p>MyISAM存储引擎中，<strong>假如同时一个读请求，一个写请求过来的话，它会优先处理写请求</strong>，因为MyISAM存储引擎中认为写请求比都请求重要。</p>
<p>这样就会导致，<strong>假如大量的读写请求过来，就会导致读请求长时间的等待，或者”线程饿死”，因此MyISAM不适合运用于大量读写操作的场景</strong>，这样会导致长时间读取不到用户数据，用户体验感极差。</p>
<p>当然可以通过设置<code>low-priority-updates</code>参数，设置请求链接的优先级，使得Mysql优先处理读请求。</p>
<h2 id="InnoDB"><a href="#InnoDB" class="headerlink" title="InnoDB"></a>InnoDB</h2><p>InnoDB和MyISAM不同的是，InnoDB支持<strong>行锁</strong>和<strong>事务</strong>，行级锁的概念前面以及说了，这里就不再赘述，事务的四大特性的概述以及实现的原理可以参考这一篇[]。</p>
<p>InnoDB中除了有<strong>表锁</strong>和<strong>行级锁</strong>的概念，还有Gap Lock（间隙锁）、Next-key Lock锁，<strong>间隙锁主要用于范围查询的时候，锁住查询的范围，并且间隙锁也是解决幻读的方案</strong>。</p>
<p>InnoDB中的行级锁是<strong>对索引加的锁，在不通过索引查询数据的时候，InnoDB就会使用表锁</strong>。</p>
<p><strong>但是通过索引查询的时候是否使用索引，还要看Mysql的执行计划</strong>，Mysql的优化器会判断是一条sql执行的最佳策略。</p>
<p>若是Mysql觉得执行索引查询还不如全表扫描速度快，那么Mysql就会使用全表扫描来查询，这是即使sql语句中使用了索引，最后还是执行为全表扫描，加的是表锁。</p>
<p>若是对于Mysql的sql执行原理不熟悉的可以参考这一篇文章[]。最后是否执行了索引查询可以通过<code>explain</code>来查看，我相信这个大家都是耳熟能详的命令了。</p>
<h3 id="InnoDB行锁和表锁"><a href="#InnoDB行锁和表锁" class="headerlink" title="InnoDB行锁和表锁"></a>InnoDB行锁和表锁</h3><p>InnoDB的行锁也是分为行级<strong>共享读锁（S锁）</strong>和<strong>排它写锁（X锁）</strong>，原理特点和MyISAM的表级锁两种模式是一样的。</p>
<p>若想显式的给表加行级读锁和写锁，可以执行下面的sql语句：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">&#x2F;&#x2F; 给查询sql显示添加读锁</span><br><span class="line">select ... lock in share mode;</span><br><span class="line">&#x2F;&#x2F; 给查询sql显示添加写锁</span><br><span class="line">select ... for update；</span><br></pre></td></tr></table></figure>

<p>（1）下面我们直接进入锁机制的测试阶段，还是创建一个测试表，并插入两条数据：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">&#x2F;&#x2F; 先把原来的MyISAM表给删除了</span><br><span class="line">DROP TABLE IF EXISTS employee;</span><br><span class="line">CREATE TABLE IF NOT EXISTS employee (</span><br><span class="line">    id INT PRIMARY KEY auto_increment,</span><br><span class="line">    name VARCHAR(40),</span><br><span class="line">    money INT</span><br><span class="line">)ENGINE INNODB;</span><br><span class="line">&#x2F;&#x2F; 插入测试数据</span><br><span class="line">INSERT INTO employee(name, money) VALUES(&#39;黎杜&#39;, 1000);</span><br><span class="line">INSERT INTO employee(name, money) VALUES(&#39;非科班的科班&#39;, 2000);</span><br></pre></td></tr></table></figure>
<p>（2）创建的表中可以看出对表中的字段只有id添加了主键索引，接着就是在session1窗口执行<code>begin</code>开启事务，并执行下面的sql语句：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">&#x2F;&#x2F; 使用非索引字段查询，并显式的添加写锁</span><br><span class="line">select * from employee where name&#x3D;&#39;黎杜&#39; for update;</span><br></pre></td></tr></table></figure>
<p>（3）然后在session2中执行update语句，上面查询的式id=1的数据行，下面update的是id=2的数据行，会发现程序也会进入等待状态：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">update employee set name&#x3D;&#39;ldc&#39; where id &#x3D;2;</span><br></pre></td></tr></table></figure>
<p>可见若是<strong>使用非索引查询，直接就是使用的表级锁</strong>，锁住了整个表。<br><img src="https://img-blog.csdnimg.cn/20200621223021791.png"><br>（4）若是session1使用的是id来查询，如下图所示：<br><img src="https://img-blog.csdnimg.cn/2020062122333567.png"><br>（5）那么session2是可以成功update其它数据行的，但是这里我建议使用数据量大的表进行测试，因为前面我说过了<strong>是否执行索引还得看Mysql的执行计划，对于一些小表的操作，可能就直接使用全表扫描</strong>。<br><img src="https://img-blog.csdnimg.cn/2020062122355042.png"><br>（6）还有一种情况就是：假如我们给name字段也加上了普通索引，那么通过普通索引来查询数据，并且查询到多行数据，拿它是锁这多行数据还是锁整个表呢？</p>
<p>下面我们来测试一下，首先给<strong>name字段添加普通索引</strong>，如下图所示：<br><img src="https://img-blog.csdnimg.cn/2020062122442481.png"><br>（6）并插入一条新的数据name值与id=2的值相同，并显式的加锁，如下若是：<br><img src="https://img-blog.csdnimg.cn/20200621225724753.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQzMjU1MDE3,size_16,color_FFFFFF,t_70"><br>（7）当update其它数据行name值不是ldc的也会进入等待状态，并且通过explain来查看是否name=’ldc’有执行索引，可以看到sql语句是有执行索引条件的。<br><img src="https://img-blog.csdnimg.cn/2020062123005862.png"><br><img src="https://img-blog.csdnimg.cn/20200621230443688.png"><br>结论：从上面的测试锁机制的演示可以得出以下几个结论：</p>
<ol>
<li>执行非索引条件查询执行的是表锁。</li>
<li>执行索引查询是否是加行锁，还得看Mysql的执行计划，可以通过explain关键字来查看。</li>
<li>用普通键索引的查询，遇到索引值相同的，也会对其他的操作数据行的产生影响。</li>
</ol>
<h3 id="InnoDB间隙锁"><a href="#InnoDB间隙锁" class="headerlink" title="InnoDB间隙锁"></a>InnoDB间隙锁</h3><p>当我们使用范围条件查询而不是等值条件查询的时候，InnoDB就会给符合条件的范围索引加锁，在条件范围内并不存的记录就叫做”间隙（GAP）”</p>
<p>大家大概都知道在事务的四大隔离级别中，不可重复读会产生幻读的现象，只能通过提高隔离级别到串行化来解决幻读现象。</p>
<p>但是Mysql中的不可重复是已经解决了幻读问题，它通过引入间隙锁的实现来解决幻读，通过给符合条件的间隙加锁，防止再次查询的时候出现新数据产生幻读的问题。</p>
<p>例如我们执行下面的sql语句，就会对id大于100的记录加锁，在id&gt;100的记录中肯定是有不存在的间隙：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Select * from  employee where id&gt; 100 for update;</span><br></pre></td></tr></table></figure>
<p>（1）接着来测试间隙锁，新增一个字段num，并将num添加为普通索引、修改之前的数据使得num之间的值存在间隙，操作如下sql所示：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">alter table employee add num int not null default 0;</span><br><span class="line">update employee set num &#x3D; 1 where id &#x3D; 1;</span><br><span class="line">update employee set num &#x3D; 1 where id &#x3D; 2;</span><br><span class="line">update employee set num &#x3D; 3 where id &#x3D; 3;</span><br><span class="line">insert into employee values(4,&#39;kris&#39;,4000,5);</span><br></pre></td></tr></table></figure>
<p><img src="https://img-blog.csdnimg.cn/2020062207201165.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQzMjU1MDE3,size_16,color_FFFFFF,t_70"><br>（2）接着在session1的窗口开启事务，并执行下面操作：<br><img src="https://img-blog.csdnimg.cn/20200622072428549.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQzMjU1MDE3,size_16,color_FFFFFF,t_70"><br>（3）同时打开窗口session2，并执行新增语句：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">insert into employee values(5,&#39;ceshi&#39;,5000,2);  &#x2F;&#x2F; 程序出现等待</span><br><span class="line">insert into employee values(5,&#39;ceshi&#39;,5000,4);  &#x2F;&#x2F; 程序出现等待</span><br><span class="line">insert into employee values(5,&#39;ceshi&#39;,5000,6);  &#x2F;&#x2F; 新增成功</span><br><span class="line">insert into employee values(6,&#39;ceshi&#39;,5000,0);  &#x2F;&#x2F; 新增成功</span><br></pre></td></tr></table></figure>
<p><strong>从上面的测试结果显示在区间（1,3]U[3,5)之间加了锁，是不能够新增数据行，这就是新增num=2和num=4失败的原因，但是在这个区间以外的数据行是没有加锁的，可以新增数据行</strong>。</p>
<p>根据索引的有序性，而普通索引是可以出现重复值，那么当我们第一个sesson查询的时候只出现一条数据num=3，为了解决第二次查询的时候出现幻读，也就是出现两条或者更多num=3这样查询条件的数据。</p>
<p>Mysql在满足where条件的情况下，给<code>（1,3]U[3,5)</code>区间加上了锁不允许插入num=3的数据行，这样就解决了幻读。</p>
<p>这里抛出几种情况接着来测试间隙锁。主键索引（唯一索引）是否会加上间隙所呢？范围查询是否会加上间隙锁？使用不存在的检索条件是否会加上间隙锁？</p>
<p>先来说说：<strong>主键索引（唯一索引）是否会加上间隙所呢？</strong></p>
<p>因为主键索引具有唯一性，不允许出现重复，那么当进行等值查询的时候id=3，只能有且只有一条数据，是不可能再出现id=3的第二条数据。</p>
<p>因此它只要锁定这条数据（锁定索引），在下次查询当前读的时候不会被删除、或者更新id=3的数据行，也就保证了数据的一致性，所以主键索引由于他的唯一性的原因，是不需要加间隙锁的。</p>
<p>再来说说第二个问题：<strong>范围查询是否会加上间隙锁？</strong></p>
<p>直接在session1中执行下面的sql语句，并在session2中在这个num&gt;=3的查询条件内和外新增数据：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">select * from employee where num&gt;&#x3D;3 for update;</span><br><span class="line">insert into employee values(6,&#39;ceshi&#39;,5000,2);  &#x2F;&#x2F; 程序出现等待</span><br><span class="line">insert into employee values(7,&#39;ceshi&#39;,5000,4);  &#x2F;&#x2F; 程序出现等待</span><br><span class="line">insert into employee values(8,&#39;ceshi&#39;,5000,1);  &#x2F;&#x2F; 新增数据成功</span><br></pre></td></tr></table></figure>
<p>我们来分析以下原理：单查询num&gt;=3的时候，在现有的employee表中满足条件的数据行，如下所示：<br>|id| num |<br>|–|–|<br>| 3 |  3|<br>| 4 |5  |<br>| 5 |6  |</p>
<p>那么在设计者的角度出发，我为了解决幻读的现象：在num&gt;=3的条件下是必须加上间隙锁的。</p>
<p>而在小于num=3中，下一条数据行就是num=1了，为了防止在（1，3]的范围中加入了num=3的数据行，所以也给这个间隙加上了锁，这就是添加num=2数据行出现等待的原因。</p>
<p>最后来说一说：<strong>使用不存在的检索条件是否会加上间隙锁？</strong></p>
<p>假如是查询num&gt;=8的数据行呢？因为employee表并不存在中num=8的数据行，num最大num=6，所以为了解决幻读（6，8]与num&gt;=8也会加上锁。</p>
<p>说到这里我相信很多人已经对间隙锁有了清晰和深入的认识，可以说是精通了，又可以和面试官互扯了。</p>
<p>假如你是第一次接触Mysql的锁机制，第一次肯定是懵的，建议多认真的看几遍，跟着案例敲一下自己深刻的去体会，慢慢的就懂了。</p>
<h2 id="死锁"><a href="#死锁" class="headerlink" title="死锁"></a>死锁</h2><p>死锁在InnoDB中才会出现死锁，MyISAM是不会出现死锁，因为MyISAM支持的是表锁，一次性获取了所有得锁，其它的线程只能排队等候。</p>
<p>而InnoDB默认支持行锁，获取锁是分步的，并不是一次性获取所有得锁，因此在锁竞争的时候就会出现死锁的情况。</p>
<p>虽然InnoDB会出现死锁，但是并不影响InnoDB最受欢成为迎的存储引擎，MyISAM可以理解为串行化操作，读写有序，因此支持的并发性能低下。</p>
<h3 id="死锁案例一"><a href="#死锁案例一" class="headerlink" title="死锁案例一"></a>死锁案例一</h3><p>举一个例子，现在数据库表employee中六条数据，如下所示：<br><img src="https://img-blog.csdnimg.cn/20200622125933728.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQzMjU1MDE3,size_16,color_FFFFFF,t_70"><br>其中name=ldc的有两条数据，并且name字段为普通索引，分别是id=2和id=3的数据行，现在假设有两个事务分别执行下面的两条sql语句：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">&#x2F;&#x2F; session1执行</span><br><span class="line">update employee set num &#x3D; 2 where name &#x3D;&#39;ldc&#39;;</span><br><span class="line">&#x2F;&#x2F; session2执行</span><br><span class="line">select * from employee where id &#x3D; 2 or id &#x3D;3;</span><br></pre></td></tr></table></figure>

<p>其中session1执行的sql获取的数据行是两条数据，假设先获取到第一个id=2的数据行，然后cpu的时间分配给了另一个事务，另一个事务执行查询操作获取了第二行数据也就是id=3的数据行。</p>
<p>当事务2继续执行的时候获取到id=3的数据行，锁定了id=3的数据行，此时cpu又将时间分配给了第一个事务，第一个事务执行准备获取第二行数据的锁，发现已经被其他事务获取了，它就处于等待的状态。</p>
<p>当cpu把时间有分配给了第二个事务，第二个事务准备获取第一行数据的锁发现已经被第一个事务获取了锁，这样就行了死锁，两个事务彼此之间相互等待。</p>
<h3 id="死锁案例二"><a href="#死锁案例二" class="headerlink" title="死锁案例二"></a>死锁案例二</h3><p>第二种死锁情况就是当一个事务开始并且update一条id=1的数据行时，成功获取到写锁，此时另一个事务执行也update另一条id=2的数据行时，也成功获取到写锁（id为主键）。</p>
<p>此时cpu将时间分配给了事务一，事务一接着也是update id=2的数据行，因为事务二已经获取到id=2数据行的锁，所以事务已处于等待状态。</p>
<p>事务二有获取到了时间，像执行update id=1的数据行，但是此时id=1的锁被事务一获取到了，事务二也处于等待的状态，因此形成了死锁。</p>
<table>
<thead>
<tr>
<th>session1</th>
<th>session2</th>
</tr>
</thead>
<tbody><tr>
<td>begin;update t set name=’测试’ where id=1;</td>
<td>begin</td>
</tr>
<tr>
<td></td>
<td>update t set name=’测试’ where id=2;</td>
</tr>
<tr>
<td>update t set name=’测试’ where id=2;</td>
<td></td>
</tr>
<tr>
<td>等待…..</td>
<td>update t set name=’测试’ where id=1;</td>
</tr>
<tr>
<td>等待…..</td>
<td>等待……</td>
</tr>
</tbody></table>
<h3 id="死锁的解决方案"><a href="#死锁的解决方案" class="headerlink" title="死锁的解决方案"></a>死锁的解决方案</h3><p>首先要解决死锁问题，在程序的设计上，当发现程序有高并发的访问某一个表时，尽量对该表的执行操作串行化，或者锁升级，一次性获取所有的锁资源。</p>
<p>然后也可以设置参数<code>innodb_lock_wait_timeout</code>，超时时间，并且将参数<code>innodb_deadlock_detect</code> 打开，当发现死锁的时候，自动回滚其中的某一个事务。</p>
<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>上面详细的介绍了MyISAM和InnoDB两种存储引擎的锁机制的实现，并进行了测试。</p>
<p>MyISAM的表锁分为两种模式：<strong>共享读锁</strong>和<strong>排它写锁</strong>。获取的读锁的线程对该数据行只能读，不能修改，其它线程也只能对该数据行加读锁。</p>
<p>获取到写锁的线程对该数据行既能读也能写，对其他线程对该数据行的读写具有排它性。</p>
<p>MyISAM中默认写优先于去操作，因此MyISAM一般不适合运用于大量读写操作的程序中。</p>
<p>InnoDB的行锁虽然会出现死锁的可能，但是InnoDB的支持的并发性能比MyISAM好，行锁的粒度最小，一定的方法和措施可以解决死锁的发生，极大的发挥InnoDB的性能。</p>
<p>InnoDB中引入了间隙锁的概念来决解出现幻读的问题，也引入事务的特性，通过事务的四种隔离级别，来降低锁冲突，提高并发性能。</p>
</div><div class="index-category-tag">  <hr></div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta size-small is-uppercase level is-mobile"><div class="level-left"><i class="far fa-calendar-plus"> </i>2020-10-14  <a class="commentCountImg" href="/2020/10/14/%E5%88%86%E5%B8%83%E5%BC%8Fid%E7%94%9F%E6%88%90%E7%AD%96%E7%95%A5%EF%BC%8C%E6%88%91%E5%92%8C%E9%9D%A2%E8%AF%95%E5%AE%98%E6%89%AF%E4%BA%86%E4%B8%80%E4%B8%AA%E5%8D%8A%E5%B0%8F%E6%97%B6/#comment-container"><span class="display-none-class">d41d8cd98f00b204e9800998ecf8427e</span><i class="far fa-comment-dots"></i> <span class="commentCount" id="d41d8cd98f00b204e9800998ecf8427e">99+</span>  </a><span class="level-item"><i class="far fa-clock"> </i>30 m  <i class="fas fa-pencil-alt"> </i>4.5 k</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2020/10/14/%E5%88%86%E5%B8%83%E5%BC%8Fid%E7%94%9F%E6%88%90%E7%AD%96%E7%95%A5%EF%BC%8C%E6%88%91%E5%92%8C%E9%9D%A2%E8%AF%95%E5%AE%98%E6%89%AF%E4%BA%86%E4%B8%80%E4%B8%AA%E5%8D%8A%E5%B0%8F%E6%97%B6/"> </a></h1><div class="content"><h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>面试官：小伙子，你还记得我吗？我是上次面试你的那个面试官。</p>
<p>我心想：我去，怎么会不记得，我又不是青年痴呆，上次害我画了那么多图，还使劲敲了一个多钟的电脑，满脑子都是你的阴影。</p>
<p>我：记得记得，您好，很高兴能通过二面，能够继续和您交流技术问题。</p>
<p>我违背良心说这话真的好吗，姑且就那么一次吧，面个试都那么难？</p>
<p>面试官又快速的扫了一下的简历，可能上次看过一次，都快过了一个多星期了，都忘了吧。</p>
<p>面试官：我看你简历上面写着深入了解分布式，并且也做过分布式项目，挺好的，那你知道分布式项目中生成分布式ID的方法有哪些吗？</p>
<p>我：这个我知道，生成分布式Id的方法主要有以下几种：</p>
<ol>
<li>数据库自增ID。</li>
<li>数据库水平拆分，设置初始值和相同的自增步长。</li>
<li>批量申请自增ID。</li>
<li>UUID生成。</li>
<li>Redis的方式。</li>
<li>雪花算法。</li>
<li>百度UidGenerator算法</li>
<li>美团Leaf算法</li>
</ol>
<p>面试官：哦，不错能说出那么多，你能说一说对于上面的每一种方式的分析和理解吗？</p>
<p>我心想：我去，这下可糗大了，那么多，我只是大概知道主要的，怎么可能每一种都去了解和深入，一下子说了那么多不是给自己挖坑吗？</p>
<p>哎，没办法出来混，总是要还的，只能说自己知道的吧？不知道的大概粗糙的略过。</p>
<h2 id="数据库的自增"><a href="#数据库的自增" class="headerlink" title="数据库的自增"></a>数据库的自增</h2><p>我：嗯嗯，好的。数据库的自增，很容易理解，开发过的人员都知道，在创建表的时候，指定主键<code>auto_increment</code>（自增）便可以实现。</p>
<p>我：但是使用数据库的自增ID，虽然简单，会带来ID重复的问题，并且单机版的ID自增，并且每次生成一个ID都会访问数据库一次，DB的压力也很大，并没有什么并发性能可言。</p>
<p>面试官：恩额。</p>
<p>我看看面试官正听着有味，时不时摸摸他稀少的发量额头，深邃的目光透露出他的沉稳，这可能就是一个成熟架构师的魅力吧，让多少码渣苦读《Java编程思想》《Java核心技术》《Effectice java》《Java并发编程实战》《代码整洁之道》《重构: 改善既有代码的设计》……，都无法达到的境界，我乘热打铁，接着下面的回答。</p>
<p>我：针对上面的数据库自增ID出现的问题：ID重复、性能不好。就出现了集群版的生成分布式ID方案。<strong>数据库水平拆分，设置初始值和相同的自增步长</strong>和<strong>批量申请自增ID</strong>。</p>
<h2 id="数据库水平拆分，设置初始值和相同的自增步长"><a href="#数据库水平拆分，设置初始值和相同的自增步长" class="headerlink" title="数据库水平拆分，设置初始值和相同的自增步长"></a>数据库水平拆分，设置初始值和相同的自增步长</h2><p>我：<strong>数据库水平拆分，设置初始值和相同的自增步长</strong>是指在DB集群的环境下，将数据库进行水平划分，然后每个数据库设置<strong>不同的初始值</strong>和<strong>相同的步长</strong>，这样就能避免ID重复的情况。</p>
<p>面试官：小伙子，不好意思打断一下，你可以画个图吗，这个我有点没明白你讲的意思？</p>
<p>我能有什么办法阿，完全没办法，只能从裤兜里拿出笔和纸，快速的画了一张图。</p>
<p><img src="https://img-blog.csdnimg.cn/20200706225115533.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQzMjU1MDE3,size_16,color_FFFFFF,t_70"><br>我：我这里假设有三个数据库，为每一个数据库设置初始值，设置初始值可以通过下面的sql进行设置：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">set @@auto_increment_offset &#x3D; 1;     &#x2F;&#x2F; 设置初始值</span><br><span class="line">set @@auto_increment_increment &#x3D; 2;  &#x2F;&#x2F; 设置步长</span><br></pre></td></tr></table></figure>
<p>我：三个数据的初始值分别设置为1、2、3，一般步长设置为数据库的数据，这里数据库数量为3，所以步长也设置为3。</p>
<p>面试官：若是面对再次扩容的情况呢？</p>
<p>我：恩额，扩容的情况是这种方法的一个缺点，上面我说的步长一般设置为数据库的数量，这是在确保后期不会扩容的情况下，若是确定后期会有扩容情况，在前期设计的的时候可以将步长设置长一点，<strong>预留一些初始值给后续扩容使用</strong>。</p>
<p>我：总之，这种方案还是优缺点的，但是也有自己的优点，缺点就是：<strong>后期可能会面对无ID初始值可分的窘境，数据库总归是数据库，抗高并发也是有限的</strong>。</p>
<p>我：它的优点就是算是解决了<strong>DB单点的问题</strong>。</p>
<p>面试官：恩额。</p>
<h2 id="批量申请自增ID"><a href="#批量申请自增ID" class="headerlink" title="批量申请自增ID"></a>批量申请自增ID</h2><p>我：<strong>批量申请自增ID</strong>的解决方案可以解决无ID可分的问题，它的原理就是一次性给对应的数据库上分配一批的id值进行消费，使用完了，再回来申请。</p>
<p>这次我很自觉的从裤兜里拿出笔和纸，画出了下面的这张图，历史总是那么惊人的相似。<br><img src="https://img-blog.csdnimg.cn/20200707080247905.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQzMjU1MDE3,size_16,color_FFFFFF,t_70"><br>我：在设计的初始阶段可以设计一个有初始值字段，并有步长字段的表，当每次要申请批量ID的时候，就可以去该表中申请，每次申请后<strong>初始值=上一次的初始值+步长</strong>。</p>
<p>我：这样就能保持初始值是每一个申请的ID的最大值，避免了ID的重复，并且每次都会有ID使用，一次就会生成一批的id来使用，这样访问数据库的次数大大减少。</p>
<p>我：但是这一种方案依旧有自己的缺点，依然不能抗真正意义上的高并发。</p>
<h2 id="UUID生成"><a href="#UUID生成" class="headerlink" title="UUID生成"></a>UUID生成</h2><p>我：第四种方式是使用<strong>UUID生成</strong>的方式生成分布式ID，UUID的核心思想是使用<strong>机器的网卡、当地时间、一个随机数</strong>来生成UUID。</p>
<p>我：使用UUID的方式只需要调用<code>UUID.randomUUID().toString()</code>就可以生成，这种方式方便简单，本地生成，不会消耗网络。</p>
<p>我：当时简单的东西，出现的问题就会越多，不利于存储，16字节128位，通常是以36位长度的字符串表示，很多的场景都不适合。</p>
<p>我：并且UUID生成的无序的字符串，查询效率低下，没有实际的业务含义，不具备自增特性，所以都不会使用UUID作为分布式ID来使用。</p>
<p>面试官：恩额，那你知道生成UUID的方式有几种吗？不知道没关系，这个只是作为一个扩展。</p>
<p>我：这个我只知道可以通过<strong>当前的时间戳及机器mac地址</strong>来生成，可以确保生成的UUID全球唯一，其它的没有了解过。</p>
<p>面试官：嗯嗯，没关系的。</p>
<h2 id="Redis的方式"><a href="#Redis的方式" class="headerlink" title="Redis的方式"></a>Redis的方式</h2><p>我：为了解决上面纯关系型数据库生成分布式ID无法抗高并发的问题，可以使用Redis的方式来生成分布式ID。</p>
<p>我：Redis本身有<code>incr</code>和<code>increby</code> 这样自增的命令，保证原子性，生成的ID也是有序的。</p>
<p>我：Redis基于内存操作，性能高效，不依赖于数据库，数据天然有序，利于分页和排序。</p>
<p>我：但是这个方案也会有自己的缺点，因为增加了中间件，需要自己编码实现工作量增大，增加复杂度。</p>
<p>我：使用Redis的方式还要考虑持久化，Redis的持久化有两种<strong>RDB和AOF</strong>，<strong>RDB是以快照的形式进行持久化，会丢失上一次快照至此时间的数据</strong>。</p>
<p>我：<strong>AOF可以设置一秒持久化一次，丢失的数据是秒内的</strong>，也会存在可能上一次自增后的秒内的ID没有持久化的问题。</p>
<p>我：但是这种方法相对于上面的关系型数据库生成分布式ID的方法而言，已经优越了许多。</p>
<p>我：若是数据量比较大的话，重启Redis的时间也会比较长，可以采用Redis的集群方式。</p>
<p>面试官：你能手写一下Redis的生成分布式ID的工具类代码吗？</p>
<p>我奔溃了，我最怕手写了，因为工具类这种东西，基本就是项目开始的时候写一次，后面对后市重复使用，记不住，还要手写，这也太难为我怕虎了吧。</p>
<p>我：手写应该不行，因为有些API记不住，工具类基本就是项目开始的时候写一些，后续都没有去看过了，没有专门去记它。</p>
<p>我：我可以使用您的电脑吗？使用电脑应该可以敲出这些工具类。</p>
<p>面试官：可以的，这边电脑给你，你在这个测试项目下吧。</p>
<p>我：好的，谢谢。</p>
<p>时间流逝中……..</p>
<p>大概敲了几分钟，废了九牛二虎之力，终于敲出来了，有好多API记不住，只能慢慢的找了，写了主要两种方式来生成分布式ID。</p>
<p>第一种是使用<code>RedisAtomicLong</code> 原子类使用CAS操作来生成ID。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line">@Service</span><br><span class="line">public class RedisSequenceFactory &#123;</span><br><span class="line">    @Autowired</span><br><span class="line">    RedisTemplate&lt;String, String&gt; redisTemplate;</span><br><span class="line"></span><br><span class="line">    public void setSeq(String key, int value, Date expireTime) &#123;</span><br><span class="line">        RedisAtomicLong counter &#x3D; new RedisAtomicLong(key, redisTemplate.getConnectionFactory());</span><br><span class="line">        counter.set(value);</span><br><span class="line">        counter.expireAt(expireTime);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    public void setSeq(String key, int value, long timeout, TimeUnit unit) &#123;</span><br><span class="line">        RedisAtomicLong counter &#x3D; new RedisAtomicLong(key, redisTemplate.getConnectionFactory());</span><br><span class="line">        counter.set(value);</span><br><span class="line">        counter.expire(timeout, unit);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    public long generate(String key) &#123;</span><br><span class="line">        RedisAtomicLong counter &#x3D; new RedisAtomicLong(key, redisTemplate.getConnectionFactory());</span><br><span class="line">        return counter.incrementAndGet();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    public long incr(String key, Date expireTime) &#123;</span><br><span class="line">        RedisAtomicLong counter &#x3D; new RedisAtomicLong(key, redisTemplate.getConnectionFactory());</span><br><span class="line">        counter.expireAt(expireTime);</span><br><span class="line">        return counter.incrementAndGet();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    public long incr(String key, int increment) &#123;</span><br><span class="line">        RedisAtomicLong counter &#x3D; new RedisAtomicLong(key, redisTemplate.getConnectionFactory());</span><br><span class="line">        return counter.addAndGet(increment);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    public long incr(String key, int increment, Date expireTime) &#123;</span><br><span class="line">        RedisAtomicLong counter &#x3D; new RedisAtomicLong(key, redisTemplate.getConnectionFactory());</span><br><span class="line">        counter.expireAt(expireTime);</span><br><span class="line">        return counter.addAndGet(increment);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>第二种是使用<code>redisTemplate.opsForHash()</code>和结合<code>UUID</code>的方式来生成生成ID。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">public Long getSeq(String key,String hashKey,Long delta) throws BusinessException&#123;</span><br><span class="line">        try &#123;</span><br><span class="line">            if (null &#x3D;&#x3D; delta) &#123;</span><br><span class="line">                delta&#x3D;1L;</span><br><span class="line">            &#125;</span><br><span class="line">            return redisTemplate.opsForHash().increment(key, hashKey, delta);</span><br><span class="line">        &#125; catch (Exception e) &#123;  &#x2F;&#x2F; 若是redis宕机就采用uuid的方式</span><br><span class="line">            int first &#x3D; new Random(10).nextInt(8) + 1;</span><br><span class="line">            int randNo&#x3D;UUID.randomUUID().toString().hashCode();</span><br><span class="line">            if (randNo &lt; 0) &#123;</span><br><span class="line">                randNo&#x3D;-randNo;</span><br><span class="line">            &#125;</span><br><span class="line">            return Long.valueOf(first + String.format(&quot;%16d&quot;, randNo));</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure>
<p>我把电脑移回给面试官，他很快的扫了一下我的代码，说了一句。</p>
<p>面试官：小伙子，不写注释哦，这个习惯不好哦。</p>
<p>我：哦哦，谢谢提醒，不好意思，下次我会注意的。</p>
<h2 id="雪花算法"><a href="#雪花算法" class="headerlink" title="雪花算法"></a>雪花算法</h2><p>我：第六种方式是<strong>雪花算法</strong>，也是现在市面上比较流行的生成分布式ID的方法。</p>
<p>说着说着，我知道画图又是必不可少的了，于是在桌子上有画了起来，面试官好奇的看看我，知道了我在干啥，又耐心的等了等。</p>
<p>我：他是采用64bit作为id生成类型，并且将64bit划分为，如下图的几段。</p>
<p>我顺手把我画的图递给他看了看，接着对着这个图进行解释。<br><img src="https://img-blog.csdnimg.cn/20200707203956167.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQzMjU1MDE3,size_16,color_FFFFFF,t_70"><br>我：第一位作为标识位，因为Java中long类型的时代符号的，因为ID位正数，所以第一位位0。</p>
<p>我：接着的41bit是时间戳，毫秒级位单位，注意这里的时间戳并不是指当前时间的时间戳，而是值之间差（<strong>当前时间-开始时间</strong>）。</p>
<p>我：这里的开始时间一般是指ID生成器的开始时间，是由我们程序自己指定的。</p>
<p>我：接着后面的10bit：包括5位的<strong>数据中心标识ID（datacenterId）和5位的机器标识ID（workerId）</strong>，可以最多标识1024个节点（1&lt;&lt;10=1024）。</p>
<p>我：最的12位是序列号，12位的计数顺序支持每个节点每毫秒差生4096序列号（1&lt;&lt;12=4096）。</p>
<p>我：雪花算法使用数据中心ID和机器ID作为标识，不会产生ID的重复，并且是在本地生成，不会消耗网络，效率高，有数据显示，每秒能生成26万个ID。</p>
<p>我：但是雪花算法也是又自己的缺点，因为雪花算法的计算依赖于时间，若是系统时间回拨，就会产生重复ID的情况。</p>
<p>面试官：那对于时间回拨产生重复ID的情况，你有什么比较好的解决方案吗？</p>
<p>我：在雪花算法的实现中，若是其前置的时间等于当前的时间，就抛出异常，也可以关闭掉时间回拨。</p>
<p>我：对于回拨时间比较短的，可以等待回拨时间过后再生成ID。</p>
<p>面试官：你可以帮我敲一个雪花算法吗？我这键盘给你。</p>
<p>我：。。。</p>
<p>我：好的。</p>
<p>时间流逝中……</p>
<p>过了几分钟时间，也总算是把雪花算法给敲出来了，真正要老命，面个试怎么就那么难呢？</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br></pre></td><td class="code"><pre><span class="line">&#x2F;**</span><br><span class="line"> * 雪花算法</span><br><span class="line"> * @author：黎杜</span><br><span class="line"> *&#x2F;</span><br><span class="line">public class SnowflakeIdWorker &#123;</span><br><span class="line"></span><br><span class="line">    &#x2F;** 开始时间截 *&#x2F;</span><br><span class="line">    private final long twepoch &#x3D; 1530051700000L;</span><br><span class="line"></span><br><span class="line">    &#x2F;** 机器id的位数 *&#x2F;</span><br><span class="line">    private final long workerIdBits &#x3D; 5L;</span><br><span class="line"></span><br><span class="line">    &#x2F;** 数据标识id的位数 *&#x2F;</span><br><span class="line">    private final long datacenterIdBits &#x3D; 5L;</span><br><span class="line"></span><br><span class="line">    &#x2F;** 最大的机器id，结果是31 *&#x2F;</span><br><span class="line">    private final long maxWorkerId &#x3D; -1L ^ (-1L &lt;&lt; workerIdBits);</span><br><span class="line"></span><br><span class="line">    &#x2F;** 最大的数据标识id，结果是31 *&#x2F;</span><br><span class="line">    private final long maxDatacenterId &#x3D; -1L ^ (-1L &lt;&lt; datacenterIdBits);</span><br><span class="line"></span><br><span class="line">    &#x2F;** 序列的位数 *&#x2F;</span><br><span class="line">    private final long sequenceBits &#x3D; 12L;</span><br><span class="line"></span><br><span class="line">    &#x2F;** 机器ID向左移12位 *&#x2F;</span><br><span class="line">    private final long workerIdShift &#x3D; sequenceBits;</span><br><span class="line"></span><br><span class="line">    &#x2F;** 数据标识id向左移17位 *&#x2F;</span><br><span class="line">    private final long datacenterIdShift &#x3D; sequenceBits + workerIdBits;</span><br><span class="line"></span><br><span class="line">    &#x2F;** 时间截向左移22位*&#x2F;</span><br><span class="line">    private final long timestampLeftShift &#x3D; sequenceBits + workerIdBits + datacenterIdBits;</span><br><span class="line"></span><br><span class="line">    &#x2F;** 生成序列的掩码 *&#x2F;</span><br><span class="line">    private final long sequenceMask &#x3D; -1L ^ (-1L &lt;&lt; sequenceBits);</span><br><span class="line"></span><br><span class="line">    &#x2F;** 工作机器ID(0~31) *&#x2F;</span><br><span class="line">    private long workerId;</span><br><span class="line"></span><br><span class="line">    &#x2F;** 数据中心ID(0~31) *&#x2F;</span><br><span class="line">    private long datacenterId;</span><br><span class="line"></span><br><span class="line">    &#x2F;** 毫秒内序列(0~4095) *&#x2F;</span><br><span class="line">    private long sequence &#x3D; 0L;</span><br><span class="line"></span><br><span class="line">    &#x2F;** 上次生成ID的时间截 *&#x2F;</span><br><span class="line">    private long lastTimestamp &#x3D; -1L;</span><br><span class="line"></span><br><span class="line">    &#x2F;**</span><br><span class="line">     * 构造函数</span><br><span class="line">     * @param workerId 工作ID (0~31)</span><br><span class="line">     * @param datacenterId 数据中心ID (0~31)</span><br><span class="line">     *&#x2F;</span><br><span class="line">    public SnowflakeIdWorker(long workerId, long datacenterId) &#123;</span><br><span class="line">        if (workerId &gt; maxWorkerId || workerId &lt; 0) &#123;</span><br><span class="line">            throw new IllegalArgumentException(String.format(&quot;worker Id can&#39;t be greater than %d or less than 0&quot;, maxWorkerId));</span><br><span class="line">        &#125;</span><br><span class="line">        if (datacenterId &gt; maxDatacenterId || datacenterId &lt; 0) &#123;</span><br><span class="line">            throw new IllegalArgumentException(String.format(&quot;datacenter Id can&#39;t be greater than %d or less than 0&quot;, maxDatacenterId));</span><br><span class="line">        &#125;</span><br><span class="line">        this.workerId &#x3D; workerId;</span><br><span class="line">        this.datacenterId &#x3D; datacenterId;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    &#x2F;**</span><br><span class="line">     * 获得下一个ID (该方法是线程安全的)</span><br><span class="line">     * @return SnowflakeId</span><br><span class="line">     *&#x2F;</span><br><span class="line">    public synchronized long nextId() &#123;</span><br><span class="line">        long timestamp &#x3D; getCurrentTime();</span><br><span class="line"></span><br><span class="line">        &#x2F;&#x2F;如果当前时间小于上一次生成的时间戳，说明系统时钟回退过就抛出异常</span><br><span class="line">        if (timestamp &lt; lastTimestamp) &#123;</span><br><span class="line">            throw new BusinessionException(&quot;回拨的时间为：&quot;+lastTimestamp - timestamp);</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        &#x2F;&#x2F;如果是同一时间生成的，则进行毫秒内序列</span><br><span class="line">        if (lastTimestamp &#x3D;&#x3D; timestamp) &#123;</span><br><span class="line">            sequence &#x3D; (sequence + 1) &amp; sequenceMask;</span><br><span class="line">            &#x2F;&#x2F;毫秒内序列溢出</span><br><span class="line">            if (sequence &#x3D;&#x3D; 0) &#123;</span><br><span class="line">                &#x2F;&#x2F;获得新的时间戳</span><br><span class="line">                timestamp &#x3D; tilNextMillis(lastTimestamp);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125; else &#123;  &#x2F;&#x2F;时间戳改变，毫秒内序列重置</span><br><span class="line">            sequence &#x3D; 0L;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        &#x2F;&#x2F;上次生成ID的时间截</span><br><span class="line">        lastTimestamp &#x3D; timestamp;</span><br><span class="line"></span><br><span class="line">        &#x2F;&#x2F;移位并通过或运算拼到一起组成64位的ID</span><br><span class="line">        return ((timestamp - twepoch) &lt;&lt; timestampLeftShift) &#x2F;&#x2F; 计算时间戳</span><br><span class="line">                | (datacenterId &lt;&lt; datacenterIdShift) &#x2F;&#x2F; 计算数据中心</span><br><span class="line">                | (workerId &lt;&lt; workerIdShift) &#x2F;&#x2F; 计算机器ID</span><br><span class="line">                | sequence; &#x2F;&#x2F; 序列号</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    &#x2F;**</span><br><span class="line">     *获得新的时间戳</span><br><span class="line">     * @param lastTimestamp 上次生成ID的时间截</span><br><span class="line">     * @return 当前时间戳</span><br><span class="line">     *&#x2F;</span><br><span class="line">    protected long tilNextMillis(long lastTimestamp) &#123;</span><br><span class="line">        long timestamp &#x3D; getCurrentTime();</span><br><span class="line">        &#x2F;&#x2F; 若是当前时间等于上一次的1时间就一直阻塞，知道获取到最新的时间（回拨后的时间）</span><br><span class="line">        while (timestamp &lt;&#x3D; lastTimestamp) &#123;</span><br><span class="line">            timestamp &#x3D; getCurrentTime();</span><br><span class="line">        &#125;</span><br><span class="line">        return timestamp;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    &#x2F;**</span><br><span class="line">     * 获取当前时间</span><br><span class="line">     * @return 当前时间(毫秒)</span><br><span class="line">     *&#x2F;</span><br><span class="line">    protected long getCurrentTime() &#123;</span><br><span class="line">        return System.currentTimeMillis();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>为了给面试官留下个好印象，这下也写上了注解，免得他又说我，敲完我又把电脑移回给他，他快速的看了看，点了点头，嘴角露出思思的笑意。</p>
<p>面试官：嗯，你的底子还算比价扎实，面试之前早有准备吧，看了很多的面试资料。</p>
<p>我心想怎么是面试之前准备呢？我是一直再准备，从工作到现在都在总结自己的知识点，形成自己的知识体系，为了迎合他，也只能说是。</p>
<p>我：嗯嗯，是的，准备了很久，算是比较充分。</p>
<p>面试官：嗯，最后的两种算法，你还深入了解吗？</p>
<h2 id="UidGenerator和Leaf"><a href="#UidGenerator和Leaf" class="headerlink" title="UidGenerator和Leaf"></a>UidGenerator和Leaf</h2><p>我：最后两种确实没有深入了解，之前有看网上的资料说美团Leaf算法需要依赖于数据库，ZK，并且也能保证去全局ID的唯一性，单项递增。    </p>
<p>我：而百度UidGenerator算法是基于雪花算法进行实现的，也是需要借助于数据库，与雪花算法不同的是，<strong>UidGenerator支持自定义时间戳、主句中心ID和机器ID、序列号的位数</strong>。</p>
<p>面试官：嗯嗯，好的，小伙子今天的面试就到这里，下次我们再见吧。</p>
<p>得意洋洋中……</p>
</div><div class="index-category-tag">  <hr></div></article></div><!--!--><div class="card"><article class="card-content article" role="article"><div class="article-meta size-small is-uppercase level is-mobile"><div class="level-left"><i class="far fa-calendar-plus"> </i>2020-10-14  <a class="commentCountImg" href="/2020/10/14/%E5%AD%A6%E4%B9%A0Redis%E4%B8%80%E7%AF%87%E5%B0%B1%E5%A4%9F/#comment-container"><span class="display-none-class">d41d8cd98f00b204e9800998ecf8427e</span><i class="far fa-comment-dots"></i> <span class="commentCount" id="d41d8cd98f00b204e9800998ecf8427e">99+</span>  </a><span class="level-item"><i class="far fa-clock"> </i>4 h  <i class="fas fa-pencil-alt"> </i>33.7 k</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2020/10/14/%E5%AD%A6%E4%B9%A0Redis%E4%B8%80%E7%AF%87%E5%B0%B1%E5%A4%9F/"> </a></h1><div class="content"><h1 id="学习Redis一篇就够"><a href="#学习Redis一篇就够" class="headerlink" title="学习Redis一篇就够"></a>学习Redis一篇就够</h1><h1 id="本文脑图"><a href="#本文脑图" class="headerlink" title="本文脑图"></a>本文脑图</h1><p><img src="https://img-blog.csdnimg.cn/20200818225220354.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQzMjU1MDE3,size_16,color_FFFFFF,t_70#pic_center"></p>
<h1 id="redis基本数据结构"><a href="#redis基本数据结构" class="headerlink" title="redis基本数据结构"></a>redis基本数据结构</h1><h2 id="本文脑图-1"><a href="#本文脑图-1" class="headerlink" title="本文脑图"></a>本文脑图</h2><p><img src="https://img-blog.csdnimg.cn/20200614113047180.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQzMjU1MDE3,size_16,color_FFFFFF,t_70"></p>
<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>Redis是基于c语言编写的开源非关系型内存数据库，可以用作数据库、缓存、消息中间件，这么优秀的东西客定要一点一点的吃透它。</p>
<p>这是关于Redis五种数据结构详解，包括这五种的数据结构的底层原理实现。</p>
<p>理论肯定是要用于实践的，因此最重要的还是实战部分，也就是这里还会讲解五种数据结构的应用场景。</p>
<p>话不多说，我们直接进入主题，很多人都知道Redis的五种数据结构包括以下五种：</p>
<ol>
<li><code>String</code>：字符串类型</li>
<li><code>List</code>：列表类型</li>
<li><code>Set</code>：无序集合类型</li>
<li><code>ZSet</code>：有序集合类型</li>
<li><code>Hash</code>：哈希表类型</li>
</ol>
<p>但是作为一名优秀的程序员可能不能只停留在只会用着五种类型进行crud工作，还是得深入了解这五种数据结构的底层原理。</p>
<h2 id="Redis核心对象"><a href="#Redis核心对象" class="headerlink" title="Redis核心对象"></a>Redis核心对象</h2><p>在Redis中有一个<strong>核心的对象</strong>叫做<code>redisObject</code> ，是用来表示所有的key和value的，用redisObject结构体来表示<code>String、Hash、List、Set、ZSet</code>五种数据类型。</p>
<p><code>redisObject</code>的源代码在<code>redis.h</code>中，使用c语言写的，感兴趣的可以自行查看，关于redisObject我这里画了一张图，表示redisObject的结构如下所示：</p>
<p><img src="https://img-blog.csdnimg.cn/20200614104817292.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQzMjU1MDE3,size_16,color_FFFFFF,t_70" alt="闪瞎人的五颜六色图"></p>
<p>在redisObject中<strong>type表示属于哪种数据类型，encoding表示该数据的存储方式</strong>，也就是底层的实现的该数据类型的数据结构。因此这篇文章具体介绍的也是encoding对应的部分。</p>
<p>那么encoding中的存储类型又分别表示什么意思呢？具体数据类型所表示的含义，如下图所示：</p>
<p><img src="https://img-blog.csdnimg.cn/20200614111129928.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQzMjU1MDE3,size_16,color_FFFFFF,t_70#pic_center" alt="图片截图出自《Redis设计与实现第二版》"></p>
<p>可能看完这图，还是觉得一脸懵。不慌，会进行五种数据结构的详细介绍，这张图只是让你找到每种中数据结构对应的储存类型有哪些，大概脑子里有个印象。</p>
<p>举一个简单的例子，你在Redis中设置一个字符串<code>key 234</code>，然后查看这个字符串的存储类型就会看到为int类型，非整数型的使用的是embstr储存类型，具体操作如下图所示：</p>
<p><img src="https://img-blog.csdnimg.cn/20200614113522120.png"></p>
<h2 id="String类型"><a href="#String类型" class="headerlink" title="String类型"></a>String类型</h2><p>String是Redis最基本的数据类型，上面的简介中也说到Redis是用c语言开发的。但是Redis中的字符串和c语言中的字符串类型却是有明显的区别。</p>
<p>String类型的数据结构存储方式有三种<code>int、raw、embstr</code>。那么这三种存储方式有什么区别呢？</p>
<h3 id="int"><a href="#int" class="headerlink" title="int"></a>int</h3><p>Redis中规定假如存储的是<strong>整数型值</strong>，比如<code>set num 123</code>这样的类型，就会使用 int的存储方式进行存储，在redisObject的<strong>ptr属性</strong>中就会保存该值。</p>
<p><img src="https://img-blog.csdnimg.cn/20200614161909985.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQzMjU1MDE3,size_16,color_FFFFFF,t_70"></p>
<h3 id="SDS"><a href="#SDS" class="headerlink" title="SDS"></a>SDS</h3><p>假如存储的<strong>字符串是一个字符串值并且长度大于32个字节</strong>就会使用<code>SDS（simple dynamic string）</code>方式进行存储，并且encoding设置为raw；若是<strong>字符串长度小于等于32个字节</strong>就会将encoding改为embstr来保存字符串。</p>
<p>SDS称为<strong>简单动态字符串</strong>，对于SDS中的定义在Redis的源码中有的三个属性<code>int len、int free、char buf[]</code>。</p>
<p>len保存了字符串的长度，free表示buf数组中未使用的字节数量，buf数组则是保存字符串的每一个字符元素。</p>
<p>因此当你在Redsi中存储一个字符串Hello时，根据Redis的源代码的描述可以画出SDS的形式的redisObject结构图如下图所示：</p>
<p><img src="https://img-blog.csdnimg.cn/20200614165239167.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQzMjU1MDE3,size_16,color_FFFFFF,t_70"></p>
<h3 id="SDS与c语言字符串对比"><a href="#SDS与c语言字符串对比" class="headerlink" title="SDS与c语言字符串对比"></a>SDS与c语言字符串对比</h3><p>Redis使用SDS作为存储字符串的类型肯定是有自己的优势，SDS与c语言的字符串相比，SDS对c语言的字符串做了自己的设计和优化，具体优势有以下几点：</p>
<p>（1）c语言中的字符串并不会记录自己的长度，因此**每次获取字符串的长度都会遍历得到，时间的复杂度是O(n)**，而Redis中获取字符串只要读取len的值就可，时间复杂度变为O(1)。</p>
<p> （2）<strong>c语言</strong>中两个字符串拼接，若是没有分配足够长度的内存空间就<strong>会出现缓冲区溢出的情况</strong>；而<strong>SDS</strong>会先根据len属性判断空间是否满足要求，若是空间不够，就会进行相应的空间扩展，所以<strong>不会出现缓冲区溢出的情况</strong>。</p>
<p> （3）SDS还提供<strong>空间预分配</strong>和<strong>惰性空间释放</strong>两种策略。在为字符串分配空间时，分配的空间比实际要多，这样就能<strong>减少连续的执行字符串增长带来内存重新分配的次数</strong>。</p>
<p>当字符串被缩短的时候，SDS也不会立即回收不适用的空间，而是通过<code>free</code>属性将不使用的空间记录下来，等后面使用的时候再释放。</p>
<p>具体的空间预分配原则是：<strong>当修改字符串后的长度len小于1MB，就会预分配和len一样长度的空间，即len=free；若是len大于1MB，free分配的空间大小就为1MB</strong>。</p>
<p>（4）SDS是二进制安全的，除了可以储存字符串以外还可以储存二进制文件（如图片、音频，视频等文件的二进制数据）；而c语言中的字符串是以空字符串作为结束符，一些图片中含有结束符，因此不是二进制安全的。</p>
<p>为了方便易懂，做了一个c语言的字符串和SDS进行对比的表格，如下所示：<br>| c语言字符串 | SDS |<br>|–|–|<br>| 获取长度的时间复杂度为O(n) | 获取长度的时间复杂度为O(1) |<br>| 不是二进制安全的 | 是二进制安全的 |<br>| 只能保存字符串 | 还可以保存二进制数据 |<br>| n次增长字符串必然会带来n次的内存分配 | n次增长字符串内存分配的次数&lt;=n |</p>
<h3 id="String类型应用"><a href="#String类型应用" class="headerlink" title="String类型应用"></a>String类型应用</h3><p>说到这里我相信很多人可以说已经精通Redis的String类型了，但是纯理论的精通，理论还是得应用实践，上面说到String可以用来存储图片，现在就以图片存储作为案例实现。</p>
<p>（1）首先要把上传得图片进行编码，这里写了一个工具类把图片处理成了Base64得编码形式，具体得实现代码如下：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">&#x2F;**</span><br><span class="line">    * 将图片内容处理成Base64编码格式</span><br><span class="line">    * @param file</span><br><span class="line">    * @return</span><br><span class="line">    *&#x2F;</span><br><span class="line">   public static String encodeImg(MultipartFile file) &#123;</span><br><span class="line">       byte[] imgBytes &#x3D; null;</span><br><span class="line">       try &#123;</span><br><span class="line">           imgBytes &#x3D; file.getBytes();</span><br><span class="line">       &#125; catch (IOException e) &#123;</span><br><span class="line">           e.printStackTrace();</span><br><span class="line">       &#125;</span><br><span class="line">       BASE64Encoder encoder &#x3D; new BASE64Encoder();</span><br><span class="line">       return imgBytes&#x3D;&#x3D;null?null:encoder.encode(imgBytes );</span><br><span class="line">   &#125;</span><br></pre></td></tr></table></figure>
<p>（2）第二步就是把处理后的图片字符串格式存储进Redis中，实现得代码如下所示：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">&#x2F;**</span><br><span class="line"> * Redis存储图片</span><br><span class="line"> * @param file</span><br><span class="line"> * @return</span><br><span class="line"> *&#x2F;</span><br><span class="line">public void uploadImageServiceImpl(MultipartFile image) &#123;</span><br><span class="line">    String imgId &#x3D; UUID.randomUUID().toString();</span><br><span class="line">    String imgStr&#x3D; ImageUtils.encodeImg(image);</span><br><span class="line">    redisUtils.set(imgId , imgStr);</span><br><span class="line">    &#x2F;&#x2F; 后续操作可以把imgId存进数据库对应的字段，如果需要从redis中取出，只要获取到这个字段后从redis中取出即可。</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>这样就是实现了图片得二进制存储，当然String类型得数据结构得应用也还有常规计数：<strong>统计微博数、统计粉丝数</strong>等。</p>
<h2 id="Hash类型"><a href="#Hash类型" class="headerlink" title="Hash类型"></a>Hash类型</h2><p>Hash对象的实现方式有两种分别是<code>ziplist、hashtable</code>，其中hashtable的存储方式key是String类型的，value也是以<code>key value</code>的形式进行存储。</p>
<p>字典类型的底层就是hashtable实现的，明白了字典的底层实现原理也就是明白了hashtable的实现原理，hashtable的实现原理可以于HashMap的是底层原理相类比。</p>
<h3 id="字典"><a href="#字典" class="headerlink" title="字典"></a>字典</h3><p>两者在新增时都会通过key计算出数组下标，不同的是计算法方式不同，HashMap中是以hash函数的方式，而hashtable中计算出hash值后，还要通过sizemask 属性和哈希值再次得到数组下标。</p>
<p>我们知道hash表最大的问题就是hash冲突，为了解决hash冲突，假如hashtable中不同的key通过计算得到同一个index，就会形成单向链表（<strong>链地址法</strong>），如下图所示：</p>
<p><img src="https://img-blog.csdnimg.cn/20200614230029399.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQzMjU1MDE3,size_16,color_FFFFFF,t_70"></p>
<h4 id="rehash"><a href="#rehash" class="headerlink" title="rehash"></a>rehash</h4><p>在字典的底层实现中，value对象以每一个dictEntry的对象进行存储，当hash表中的存放的键值对不断的增加或者减少时，需要对hash表进行一个扩展或者收缩。</p>
<p>这里就会和HashMap一样也会就进行rehash操作，进行重新散列排布。从上图中可以看到有<code>ht[0]</code>和<code>ht[1]</code>两个对象，先来看看对象中的属性是干嘛用的。</p>
<p>在hash表结构定义中有四个属性分别是<code>dictEntry **table、unsigned long size、unsigned long sizemask、unsigned long used</code>，分别表示的含义就是<strong>哈希表数组、hash表大小、用于计算索引值，总是等于size-1、hash表中已有的节点数</strong>。</p>
<p>ht[0]是用来最开始存储数据的，当要进行扩展或者收缩时，ht[0]的大小就决定了ht[1]的大小，ht[0]中的所有的键值对就会重新散列到ht[1]中。</p>
<p>扩展操作：ht[1]扩展的大小是比当前 ht[0].used 值的二倍大的第一个 2 的整数幂；收缩操作：ht[0].used 的第一个大于等于的 2 的整数幂。</p>
<p>当ht[0]上的所有的键值对都rehash到ht[1]中，会重新计算所有的数组下标值，当数据迁移完后ht[0]就会被释放，然后将ht[1]改为ht[0]，并新创建ht[1]，为下一次的扩展和收缩做准备。</p>
<h4 id="渐进式rehash"><a href="#渐进式rehash" class="headerlink" title="渐进式rehash"></a>渐进式rehash</h4><p>假如在rehash的过程中数据量非常大，Redis不是一次性把全部数据rehash成功，这样会导致Redis对外服务停止，Redis内部为了处理这种情况采用<strong>渐进式的rehash</strong>。</p>
<p>Redis将所有的rehash的操作分成多步进行，直到都rehash完成，具体的实现与对象中的<code>rehashindex</code>属性相关，<strong>若是rehashindex 表示为-1表示没有rehash操作</strong>。</p>
<p>当rehash操作开始时会将该值改成0，在渐进式rehash的过程<strong>更新、删除、查询会在ht[0]和ht[1]中都进行</strong>，比如更新一个值先更新ht[0]，然后再更新ht[1]。</p>
<p>而新增操作直接就新增到ht[1]表中，ht[0]不会新增任何的数据，这样保证<strong>ht[0]只减不增，直到最后的某一个时刻变成空表</strong>，这样rehash操作完成。</p>
<p>上面就是字典的底层hashtable的实现原理，说完了hashtable的实现原理，我们再来看看Hash数据结构的两一种存储方式<strong>ziplist（压缩列表）</strong></p>
<h3 id="ziplist"><a href="#ziplist" class="headerlink" title="ziplist"></a>ziplist</h3><p>压缩列表<code>（ziplist）</code>是一组连续内存块组成的顺序的数据结构，压缩列表能够节省空间，压缩列表中使用多个节点来存储数据。</p>
<p>压缩列表是列表键和哈希键底层实现的原理之一，<strong>压缩列表并不是以某种压缩算法进行压缩存储数据，而是它表示一组连续的内存空间的使用，节省空间</strong>，压缩列表的内存结构图如下：</p>
<p><img src="https://img-blog.csdnimg.cn/20200615073948813.png"></p>
<p>压缩列表中每一个节点表示的含义如下所示：</p>
<ol>
<li><code>zlbytes</code>：4个字节的大小，记录压缩列表占用内存的字节数。</li>
<li><code>zltail</code>：4个字节大小，记录表尾节点距离起始地址的偏移量，用于快速定位到尾节点的地址。</li>
<li><code>zllen</code>：2个字节的大小，记录压缩列表中的节点数。</li>
<li><code>entry</code>：表示列表中的每一个节点。</li>
<li><code>zlend</code>：表示压缩列表的特殊结束符号<code>&#39;0xFF&#39;</code>。</li>
</ol>
<p>再压缩列表中每一个entry节点又有三部分组成，包括<code>previous_entry_ength、encoding、content</code>。</p>
<ol>
<li><code>previous_entry_ength</code>表示前一个节点entry的长度，可用于计算前一个节点的其实地址，因为他们的地址是连续的。</li>
<li>encoding：这里保存的是content的内容类型和长度。</li>
<li>content：content保存的是每一个节点的内容。</li>
</ol>
<p><img src="https://img-blog.csdnimg.cn/20200615080410692.png"></p>
<p>说到这里相信大家已经都hash这种数据结构已经非常了解，若是第一次接触Redis五种基本数据结构的底层实现的话，建议多看几遍，下面来说一说hash的应用场景。</p>
<h3 id="应用场景"><a href="#应用场景" class="headerlink" title="应用场景"></a>应用场景</h3><p>哈希表相对于String类型存储信息更加直观，擦欧总更加方便，经常会用来做用户数据的管理，存储用户的信息。</p>
<p>hash也可以用作高并发场景下使用Redis生成唯一的id。下面我们就以这两种场景用作案例编码实现。</p>
<h4 id="存储用户数据"><a href="#存储用户数据" class="headerlink" title="存储用户数据"></a>存储用户数据</h4><p>第一个场景比如我们要储存用户信息，一般使用用户的ID作为key值，保持唯一性，用户的其他信息（地址、年龄、生日、电话号码等）作为value值存储。</p>
<p>若是传统的实现就是将用户的信息封装成为一个对象，通过序列化存储数据，当需要获取用户信息的时候，就会通过反序列化得到用户信息。</p>
<p><img src="https://img-blog.csdnimg.cn/20200615194704412.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQzMjU1MDE3,size_16,color_FFFFFF,t_70"></p>
<p>但是这样必然会造成序列化和反序列化的性能的开销，并且若是只修改其中的一个属性值，就需要把整个对象序列化出来，操作的动作太大，造成不必要的性能开销。</p>
<p>若是使用Redis的hash来存储用户数据，就会将原来的value值又看成了一个k v形式的存储容器，这样就不会带来序列化的性能开销的问题。</p>
<p><img src="https://img-blog.csdnimg.cn/20200615195616246.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQzMjU1MDE3,size_16,color_FFFFFF,t_70"></p>
<h4 id="分布式生成唯一ID"><a href="#分布式生成唯一ID" class="headerlink" title="分布式生成唯一ID"></a>分布式生成唯一ID</h4><p>第二个场景就是生成分布式的唯一ID，这个场景下就是把redis封装成了一个工具类进行实现，实现的代码如下：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">&#x2F;&#x2F; offset表示的是id的递增梯度值</span><br><span class="line">public Long getId(String key,String hashKey,Long offset) throws BusinessException&#123;</span><br><span class="line">    try &#123;</span><br><span class="line">        if (null &#x3D;&#x3D; offset) &#123;</span><br><span class="line">            offset&#x3D;1L;</span><br><span class="line">        &#125;</span><br><span class="line">        &#x2F;&#x2F; 生成唯一id</span><br><span class="line">        return redisUtil.increment(key, hashKey, offset);</span><br><span class="line">    &#125; catch (Exception e) &#123;</span><br><span class="line">        &#x2F;&#x2F;若是出现异常就是用uuid来生成唯一的id值</span><br><span class="line">        int randNo&#x3D;UUID.randomUUID().toString().hashCode();</span><br><span class="line">        if (randNo &lt; 0) &#123;</span><br><span class="line">            randNo&#x3D;-randNo;</span><br><span class="line">        &#125;</span><br><span class="line">        return Long.valueOf(String.format(&quot;%16d&quot;, randNo));</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h2 id="List类型"><a href="#List类型" class="headerlink" title="List类型"></a>List类型</h2><p>Redis中的列表在3.2之前的版本是使用<code>ziplist</code>和<code>linkedlist</code>进行实现的。在3.2之后的版本就是引入了<code>quicklist</code>。</p>
<p>ziplist压缩列表上面已经讲过了，我们来看看linkedlist和quicklist的结构是怎么样的。</p>
<p>linkedlist是一个双向链表，他和普通的链表一样都是由指向前后节点的指针。插入、修改、更新的时间复杂度尾O(1)，但是查询的时间复杂度确实O(n)。</p>
<p>linkedlist和quicklist的底层实现是采用链表进行实现，在c语言中并没有内置的链表这种数据结构，Redis实现了自己的链表结构。</p>
<p><img src="https://img-blog.csdnimg.cn/20200615202451471.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQzMjU1MDE3,size_16,color_FFFFFF,t_70"></p>
<p>Redis中链表的特性：</p>
<ol>
<li>每一个节点都有指向前一个节点和后一个节点的指针。</li>
<li>头节点和尾节点的prev和next指针指向为null，所以链表是无环的。</li>
<li>链表有自己长度的信息，获取长度的时间复杂度为O(1)。</li>
</ol>
<p>Redis中List的实现比较简单，下面我们就来看看它的应用场景。</p>
<h3 id="应用场景-1"><a href="#应用场景-1" class="headerlink" title="应用场景"></a>应用场景</h3><p>Redis中的列表可以实现<strong>阻塞队列</strong>，结合lpush和brpop命令就可以实现。生产者使用lupsh从列表的左侧插入元素，消费者使用brpop命令从队列的右侧获取元素进行消费。</p>
<p>（1）首先配置redis的配置，为了方便我就直接放在<code>application.yml</code>配置文件中，实际中可以把redis的配置文件放在一个<code>redis.properties</code>文件单独放置，具体配置如下：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">spring</span><br><span class="line">	redis:</span><br><span class="line">		host: 127.0.0.1</span><br><span class="line">		port: 6379</span><br><span class="line">		password: user</span><br><span class="line">		timeout: 0</span><br><span class="line">		database: 2</span><br><span class="line">		pool:</span><br><span class="line">			max-active: 100</span><br><span class="line">			max-idle: 10</span><br><span class="line">			min-idle: 0</span><br><span class="line">			max-wait: 100000</span><br></pre></td></tr></table></figure>
<p>（2）第二步创建redis的配置类，叫做<code>RedisConfig</code>，并标注上<code>@Configuration</code>注解，表明他是一个配置类。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br></pre></td><td class="code"><pre><span class="line">@Configuration</span><br><span class="line">public class RedisConfiguration &#123;</span><br><span class="line"></span><br><span class="line">@Value(&quot;$&#123;spring.redis.host&#125;&quot;)</span><br><span class="line">private String host;</span><br><span class="line">@Value(&quot;$&#123;spring.redis.port&#125;&quot;)</span><br><span class="line">private int port;</span><br><span class="line">@Value(&quot;$&#123;spring.redis.password&#125;&quot;)</span><br><span class="line">private String password;</span><br><span class="line">@Value(&quot;$&#123;spring.redis.pool.max-active&#125;&quot;)</span><br><span class="line">private int maxActive;</span><br><span class="line">@Value(&quot;$&#123;spring.redis.pool.max-idle&#125;&quot;)</span><br><span class="line">private int maxIdle;</span><br><span class="line">@Value(&quot;$&#123;spring.redis.pool.min-idle&#125;&quot;)</span><br><span class="line">private int minIdle;</span><br><span class="line">@Value(&quot;$&#123;spring.redis.pool.max-wait&#125;&quot;)</span><br><span class="line">private int maxWait;</span><br><span class="line">@Value(&quot;$&#123;spring.redis.database&#125;&quot;)</span><br><span class="line">private int database;</span><br><span class="line">@Value(&quot;$&#123;spring.redis.timeout&#125;&quot;)</span><br><span class="line">private int timeout;</span><br><span class="line"></span><br><span class="line">@Bean</span><br><span class="line">public JedisPoolConfig getRedisConfiguration()&#123;</span><br><span class="line">	JedisPoolConfig jedisPoolConfig&#x3D; new JedisPoolConfig();</span><br><span class="line">	jedisPoolConfig.setMaxTotal(maxActive);</span><br><span class="line">	jedisPoolConfig.setMaxIdle(maxIdle);</span><br><span class="line">	jedisPoolConfig.setMinIdle(minIdle);</span><br><span class="line">	jedisPoolConfig.setMaxWaitMillis(maxWait);</span><br><span class="line">	return jedisPoolConfig;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">@Bean</span><br><span class="line">public JedisConnectionFactory getConnectionFactory() &#123;</span><br><span class="line">	JedisConnectionFactory factory &#x3D; new JedisConnectionFactory();</span><br><span class="line">	factory.setHostName(host);</span><br><span class="line">	factory.setPort(port);</span><br><span class="line">	factory.setPassword(password);</span><br><span class="line">	factory.setDatabase(database);</span><br><span class="line">	JedisPoolConfig jedisPoolConfig&#x3D; getRedisConfiguration();</span><br><span class="line">	factory.setPoolConfig(jedisPoolConfig);</span><br><span class="line">	return factory;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">@Bean</span><br><span class="line">public RedisTemplate&lt;?, ?&gt; getRedisTemplate() &#123;</span><br><span class="line">	JedisConnectionFactory factory &#x3D; getConnectionFactory();</span><br><span class="line">	RedisTemplate&lt;?, ?&gt; redisTemplate &#x3D; new StringRedisTemplate(factory);</span><br><span class="line">	return redisTemplate;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>（3）第三步就是创建Redis的工具类RedisUtil，自从学了面向对象后，就喜欢把一些通用的东西拆成工具类，好像一个一个零件，需要的时候，就把它组装起来。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br></pre></td><td class="code"><pre><span class="line">@Component</span><br><span class="line">public class RedisUtil &#123;</span><br><span class="line"></span><br><span class="line">@Autowired</span><br><span class="line">private RedisTemplate&lt;String, Object&gt; redisTemplate;</span><br><span class="line">&#x2F;**</span><br><span class="line">* 存消息到消息队列中</span><br><span class="line">* @param key 键</span><br><span class="line">* @param value 值</span><br><span class="line">* @return</span><br><span class="line">*&#x2F;</span><br><span class="line">public boolean lPushMessage(String key, Object value) &#123;</span><br><span class="line">	try &#123;</span><br><span class="line">			redisTemplate.opsForList().leftPush(key, value);</span><br><span class="line">			return true;</span><br><span class="line">	&#125; catch (Exception e) &#123;</span><br><span class="line">			e.printStackTrace();</span><br><span class="line">			return false;</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">&#x2F;**</span><br><span class="line">* 从消息队列中弹出消息 - &lt;rpop：非阻塞式&gt;</span><br><span class="line">* @param key 键</span><br><span class="line">* @return</span><br><span class="line">*&#x2F;</span><br><span class="line">public Object rPopMessage(String key) &#123;</span><br><span class="line">	try &#123;</span><br><span class="line">			return redisTemplate.opsForList().rightPop(key);</span><br><span class="line">	&#125; catch (Exception e) &#123;</span><br><span class="line">			e.printStackTrace();</span><br><span class="line">			return null;</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">&#x2F;**</span><br><span class="line">* 查看消息</span><br><span class="line">* @param key 键</span><br><span class="line">* @param start 开始</span><br><span class="line">* @param end 结束 0 到 -1代表所有值</span><br><span class="line">* @return</span><br><span class="line">*&#x2F;</span><br><span class="line">public List&lt;Object&gt; getMessage(String key, long start, long end) &#123;</span><br><span class="line">	try &#123;</span><br><span class="line">			return redisTemplate.opsForList().range(key, start, end);</span><br><span class="line">	&#125; catch (Exception e) &#123;</span><br><span class="line">			e.printStackTrace();</span><br><span class="line">			return null;</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>这样就完成了Redis消息队列工具类的创建，在后面的代码中就可以直接使用。</p>
<h2 id="Set集合"><a href="#Set集合" class="headerlink" title="Set集合"></a>Set集合</h2><p>Redis中列表和集合都可以用来存储字符串，但是<strong>Set是不可重复的集合，而List列表可以存储相同的字符串</strong>，Set集合是无序的这个和后面讲的ZSet有序集合相对。</p>
<p>Set的底层实现是<strong>ht和intset</strong>，ht（哈希表）前面已经详细了解过，下面我们来看看inset类型的存储结构。</p>
<p>inset也叫做整数集合，用于保存整数值的数据结构类型，它可以保存<code>int16_t</code>、<code>int32_t</code> 或者<code>int64_t</code> 的整数值。</p>
<p>在整数集合中，有三个属性值<code>encoding、length、contents[]</code>，分别表示编码方式、整数集合的长度、以及元素内容，length就是记录contents里面的大小。</p>
<p>在整数集合新增元素的时候，若是超出了原集合的长度大小，就会对集合进行升级，具体的升级过程如下：</p>
<ol>
<li>首先扩展底层数组的大小，并且数组的类型为新元素的类型。</li>
<li>然后将原来的数组中的元素转为新元素的类型，并放到扩展后数组对应的位置。</li>
<li>整数集合升级后就不会再降级，编码会一直保持升级后的状态。</li>
</ol>
<h3 id="应用场景-2"><a href="#应用场景-2" class="headerlink" title="应用场景"></a>应用场景</h3><p>Set集合的应用场景可以用来<strong>去重、抽奖、共同好友、二度好友</strong>等业务类型。接下来模拟一个添加好友的案例实现：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">@RequestMapping(value &#x3D; &quot;&#x2F;addFriend&quot;, method &#x3D; RequestMethod.POST)</span><br><span class="line">public Long addFriend(User user, String friend) &#123;</span><br><span class="line">    String currentKey &#x3D; null;</span><br><span class="line">    &#x2F;&#x2F; 判断是否是当前用户的好友</span><br><span class="line">    if (AppContext.getCurrentUser().getId().equals(user.getId)) &#123;</span><br><span class="line">        currentKey &#x3D; user.getId.toString();</span><br><span class="line">    &#125;</span><br><span class="line">    &#x2F;&#x2F;若是返回0则表示不是该用户好友</span><br><span class="line">    return currentKey&#x3D;&#x3D;null?0l:setOperations.add(currentKey, friend);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>假如两个用户A和B都是用上上面的这个接口添加了很多的自己的好友，那么有一个需求就是要实现获取A和B的共同好友，那么可以进行如下操作：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">public Set intersectFriend(User userA, User userB) &#123;</span><br><span class="line">    return setOperations.intersect(userA.getId.toString(), userB.getId.toString());</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>举一反三，还可以实现A用户自己的好友，或者B用户自己的好友等，都可以进行实现。</p>
<h2 id="ZSet集合"><a href="#ZSet集合" class="headerlink" title="ZSet集合"></a>ZSet集合</h2><p>ZSet是有序集合，从上面的图中可以看到ZSet的底层实现是<code>ziplist</code>和<code>skiplist</code>实现的，ziplist上面已经详细讲过，这里来讲解skiplist的结构实现。</p>
<p><code>skiplist</code>也叫做<strong>跳跃表</strong>，跳跃表是一种有序的数据结构，它通过每一个节点维持多个指向其它节点的指针，从而达到快速访问的目的。</p>
<p>skiplist由如下几个特点：</p>
<ol>
<li>有很多层组成，由上到下节点数逐渐密集，最上层的节点最稀疏，跨度也最大。</li>
<li>每一层都是一个有序链表，只扫包含两个节点，头节点和尾节点。</li>
<li>每一层的每一个每一个节点都含有指向同一层下一个节点和下一层同一个位置节点的指针。</li>
<li>如果一个节点在某一层出现，那么该以下的所有链表同一个位置都会出现该节点。</li>
</ol>
<p>具体实现的结构图如下所示：</p>
<p><img src="https://img-blog.csdnimg.cn/20200615220409163.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQzMjU1MDE3,size_16,color_FFFFFF,t_70"></p>
<p>在跳跃表的结构中有head和tail表示指向头节点和尾节点的指针，能后快速的实现定位。level表示层数，len表示跳跃表的长度，BW表示后退指针，在从尾向前遍历的时候使用。</p>
<p>BW下面还有两个值分别表示分值（score）和成员对象（各个节点保存的成员对象）。</p>
<p>跳跃表的实现中，除了最底层的一层保存的是原始链表的完整数据，上层的节点数会越来越少，并且跨度会越来越大。</p>
<p>跳跃表的上面层就相当于索引层，都是为了找到最后的数据而服务的，数据量越大，条表所体现的查询的效率就越高，和平衡树的查询效率相差无几。</p>
<h3 id="应用场景-3"><a href="#应用场景-3" class="headerlink" title="应用场景"></a>应用场景</h3><p>因为ZSet是有序的集合，因此ZSet在实现排序类型的业务是比较常见的，比如在首页推荐10个最热门的帖子，也就是阅读量由高到低，排行榜的实现等业务。</p>
<p>下面就选用获取排行榜前前10名的选手作为案例实现，实现的代码如下所示：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line">@Autowired</span><br><span class="line">private RedisTemplate redisTemplate;</span><br><span class="line">	&#x2F;**</span><br><span class="line">	 * 获取前10排名</span><br><span class="line">	 * @return</span><br><span class="line">	 *&#x2F;</span><br><span class="line">    public static List&lt;levelVO &gt; getZset(String key, long baseNum, LevelService levelService)&#123;</span><br><span class="line">        ZSetOperations&lt;Serializable, Object&gt; operations &#x3D; redisTemplate.opsForZSet();</span><br><span class="line">        &#x2F;&#x2F; 根据score分数值获取前10名的数据</span><br><span class="line">        Set&lt;ZSetOperations.TypedTuple&lt;Object&gt;&gt; set &#x3D; operations.reverseRangeWithScores(key,0,9);</span><br><span class="line">        List&lt;LevelVO&gt; list&#x3D; new ArrayList&lt;LevelVO&gt;();</span><br><span class="line">        int i&#x3D;1;</span><br><span class="line">        for (ZSetOperations.TypedTuple&lt;Object&gt; o:set)&#123;</span><br><span class="line">            int uid &#x3D; (int) o.getValue();</span><br><span class="line">            LevelCache levelCache &#x3D; levelService.getLevelCache(uid);</span><br><span class="line">            LevelVO levelVO &#x3D; levelCache.getLevelVO();</span><br><span class="line">            long score &#x3D; (o.getScore().longValue() - baseNum + levelVO .getCtime())&#x2F;CommonUtil.multiplier;</span><br><span class="line">            levelVO .setScore(score);</span><br><span class="line">            levelVO .setRank(i);</span><br><span class="line">            list.add( levelVO );</span><br><span class="line">            i++;</span><br><span class="line">        &#125;</span><br><span class="line">        return list;</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure>
<p>以上的代码实现大致逻辑就是根据score分数值获取前10名的数据，然后封装成lawyerVO对象的列表进行返回。</p>
<p>到这里我们已经精通Redis的五种基本数据类型了，又可以去和面试官扯皮了，扯不过就跑路吧，或者这篇文章多看几遍，相信对你总是有好处的。</p>
<h1 id="Redis内存分配策略"><a href="#Redis内存分配策略" class="headerlink" title="Redis内存分配策略"></a>Redis内存分配策略</h1><h2 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h2><p>今天就带来了一个面试常问的一个问题：<strong>假如你的Redis内存满了怎么办？</strong> 长期的把Redis作为缓存使用，总有一天会存满的时候对吧。</p>
<p>这个面试题不慌呀，在Redis中有配置参数<code>maxmemory</code>可以<strong>设置Redis内存的大小</strong>。</p>
<p>在Redis的配置文件<code>redis.conf</code>文件中，配置<code>maxmemory</code>的大小参数如下所示：</p>
<p><img src="https://img-blog.csdnimg.cn/20200519220333869.png"></p>
<p>实际生产中肯定不是<code>100mb</code>的大小哈，不要给误导了，这里我只是让大家认识这个参数，一般小的公司都是设置为<code>3G</code>左右的大小。</p>
<p>除了在配置文件中配置生效外，还可以通过命令行参数的形式，进行配置，具体的配置命令行如下所示：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">&#x2F;&#x2F;获取maxmemory配置参数的大小</span><br><span class="line">127.0.0.1:6379&gt; config get maxmemory</span><br><span class="line">&#x2F;&#x2F;设置maxmemory参数为100mb</span><br><span class="line">127.0.0.1:6379&gt; config set maxmemory 100mb</span><br></pre></td></tr></table></figure>

<p>倘若实际的存储中超出了Redis的配置参数的大小时，Redis中有<strong>淘汰策略</strong>，把<strong>需要淘汰的key给淘汰掉，整理出干净的一块内存给新的key值使用</strong>。</p>
<p>接下来我们就详细的聊一聊Redis中的淘汰策略，并且深入的理解每个淘汰策略的原理和应用的场景。</p>
<h2 id="淘汰策略"><a href="#淘汰策略" class="headerlink" title="淘汰策略"></a>淘汰策略</h2><p>Redis提供了<strong>6种的淘汰策略</strong>，其中默认的是<code>noeviction</code>，这6中淘汰策略如下：</p>
<ol>
<li><code>noeviction</code>(<strong>默认策略</strong>)：若是内存的大小达到阀值的时候，所有申请内存的指令都会报错。</li>
<li><code>allkeys-lru</code>：所有key都是使用<strong>LRU算法</strong>进行淘汰。</li>
<li><code>volatile-lru</code>：所有<strong>设置了过期时间的key使用LRU算法</strong>进行淘汰。</li>
<li><code>allkeys-random</code>：所有的key使用<strong>随机淘汰</strong>的方式进行淘汰。</li>
<li><code>volatile-random</code>：所有<strong>设置了过期时间的key使用随机淘汰</strong>的方式进行淘汰。</li>
<li><code>volatile-ttl</code>：所有设置了过期时间的key<strong>根据过期时间进行淘汰，越早过期就越快被淘汰</strong>。</li>
</ol>
<p>假如在Redis中的数据有<strong>一部分是热点数据，而剩下的数据是冷门数据</strong>，或者<strong>我们不太清楚我们应用的缓存访问分布状况</strong>，这时可以使用<code>allkeys-lru</code>。</p>
<p>假如所有的数据访问的频率大概一样，就可以使用<code>allkeys-random</code>的淘汰策略。</p>
<p>假如要配置具体的淘汰策略，可以在<code>redis.conf</code>配置文件中配置，具体配置如下所示：</p>
<p><img src="https://img-blog.csdnimg.cn/20200519225413746.png"></p>
<p>这只需要把注释给打开就可以，并且配置指定的策略方式，另一种的配置方式就是命令的方式进行配置，具体的执行命令如下所示：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">&#x2F;&#x2F; 获取maxmemory-policy配置</span><br><span class="line">127.0.0.1:6379&gt; config get maxmemory-policy</span><br><span class="line">&#x2F;&#x2F; 设置maxmemory-policy配置为allkeys-lru</span><br><span class="line">127.0.0.1:6379&gt; config set maxmemory-policy allkeys-lru</span><br></pre></td></tr></table></figure>
<p>在介绍6种的淘汰策略方式的时候，说到了LRU算法，<strong>那么什么是LRU算法呢？</strong></p>
<h2 id="LRU算法"><a href="#LRU算法" class="headerlink" title="LRU算法"></a>LRU算法</h2><p><code>LRU(Least Recently Used)</code>即表示最近最少使用，也就是在最近的时间内最少被访问的key，算法根据数据的历史访问记录来进行淘汰数据。</p>
<p>它的核心的思想就是：<strong>假如一个key值在最近很少被使用到，那么在将来也很少会被访问</strong>。</p>
<p>实际上Redis实现的LRU并不是真正的LRU算法，也就是名义上我们使用LRU算法淘汰键，但是实际上被淘汰的键并不一定是真正的最久没用的。</p>
<p>Redis使用的是近似的LRU算法，<strong>通过随机采集法淘汰key，每次都会随机选出5个key，然后淘汰里面最近最少使用的key</strong>。</p>
<p>这里的5个key只是默认的个数，具体的个数也可以在配置文件中进行配置，在配置文件中的配置如下图所示：</p>
<p><img src="https://img-blog.csdnimg.cn/20200519231937596.png"></p>
<p>当近似LRU算法取值越大的时候就会越接近真实的LRU算法，可以这样理解，因为<strong>取值越大那么获取的数据就越全，淘汰中的数据的就越接近最近最少使用的数据</strong>。</p>
<p>那么为了实现根据时间实现LRU算法，Redis必须为每个key中额外的增加一个内存空间用于存储每个key的时间，大小是3字节。</p>
<p>在Redis 3.0中对近似的LRU算法做了一些优化，Redis中会维护大小是<code>16</code>的一个候选池的内存。</p>
<p>当第一次随机选取的采样数据，数据都会被放进候选池中，并且候选池中的数据会根据时间进行排序。</p>
<p>当第二次以后选取的数据，只有<strong>小于候选池内的最小时间</strong>的才会被放进候选池中。</p>
<p>当某一时刻候选池的数据满了，那么时间最大的key就会被挤出候选池。当执行淘汰时，直接从候选池中选取最近访问时间最小的key进行淘汰。</p>
<p>这样做的目的就是选取出最近似符合最近最少被访问的key值，能够正确的淘汰key值，因为随机选取的样本中的最小时间可能不是真正意义上的最小时间。</p>
<p>但是LRU算法有一个弊端：就是假如一个key值在以前都没有被访问到，然而最近一次被访问到了，那么就会认为它是热点数据，不会被淘汰。</p>
<p>然而有些数据以前经常被访问到，只是最近的时间内没有被访问到，这样就导致这些数据很可能被淘汰掉，这样一来就会出现误判而淘汰热点数据。</p>
<p>于是在Redis 4.0的时候除了LRU算法，新加了一种LFU算法，<strong>那么什么是LFU算法算法呢？</strong></p>
<h2 id="LFU算法"><a href="#LFU算法" class="headerlink" title="LFU算法"></a>LFU算法</h2><p><code>LFU(Least Frequently Used)</code>即表示最近频繁被使用，也就是最近的时间段内，频繁被访问的key，它以最近的时间段的被访问次数的频率作为一种判断标准。</p>
<p>它的核心思想就是：根据key最近被访问的频率进行淘汰，比较少被访问的key优先淘汰，反之则优先保留。</p>
<p>LFU算法反映了一个key的热度情况，不会因为LRU算法的偶尔一次被访问被认为是热点数据。</p>
<p>在LFU算法中支持<code>volatile-lfu</code>策略和<code>allkeys-lfu</code>策略。</p>
<p>以上介绍了Redis的6种淘汰策略，这6种淘汰策略旨在告诉我们怎么做，但是什么时候做？这个还没说，下面我们就来详细的了解Redis什么时候执行淘汰策略。</p>
<h2 id="删除过期键策略"><a href="#删除过期键策略" class="headerlink" title="删除过期键策略"></a>删除过期键策略</h2><p>在Redis种有三种删除的操作此策略，分别是：</p>
<ol>
<li><strong>定时删除</strong>：创建一个定时器，定时的执行对key的删除操作。</li>
<li><strong>惰性删除</strong>：每次只有再访问key的时候，才会检查key的过期时间，若是已经过期了就执行删除。</li>
<li><strong>定期删除</strong>：每隔一段时间，就会检查删除掉过期的key。</li>
</ol>
<p><strong>定时删除</strong>对于<strong>内存来说是友好的</strong>，定时清理出干净的空间，但是对于<strong>cpu来说并不是友好的</strong>，程序需要维护一个定时器，这就会占用cpu资源。</p>
<p><strong>惰性的删除</strong>对于<strong>cpu来说是友好的</strong>，cpu不需要维护其它额外的操作，但是对于<strong>内存来说是不友好的</strong>，因为要是有些key一直没有被访问到，就会一直占用着内存。</p>
<p>定期删除是上面两种方案的折中方案<strong>，每隔一段时间删除过期的key，也就是根据具体的业务，合理的取一个时间定期的删除key</strong>。</p>
<p>通过<strong>最合理控制删除的时间间隔</strong>来删除key，减<strong>少对cpu的资源的占用消耗</strong>，使删除操作合理化。</p>
<h2 id="RDB和AOF-的淘汰处理"><a href="#RDB和AOF-的淘汰处理" class="headerlink" title="RDB和AOF 的淘汰处理"></a>RDB和AOF 的淘汰处理</h2><p>在Redis中持久化的方式有两种<code>RDB</code>和<code>AOF</code>，具体这两种详细的持久化介绍，可以参考这一篇文章[]。</p>
<p>在RDB中是以快照的形式获取内存中某一时间点的数据副本，在创建RDB文件的时候可以通过<code>save</code>和<code>bgsave</code>命令执行创建RDB文件。</p>
<p><strong>这两个命令都不会把过期的key保存到RDB文件中</strong>，这样也能达到删除过期key的效果。</p>
<p>当在启动Redis载入RDB文件的时候，<code>Master</code>不会把过期的key载入，而<code>Slave</code>会把过期的key载入。</p>
<p>在AOF模式下，Redis提供了Rewite的优化措施，执行的命令分别是<code>REWRITEAOF</code>和<code>BGREWRITEAOF</code>，<strong>这两个命令都不会把过期的key写入到AOF文件中，也能删除过期key</strong>。</p>
<h1 id="Redis缓存三大问题"><a href="#Redis缓存三大问题" class="headerlink" title="Redis缓存三大问题"></a>Redis缓存三大问题</h1><h2 id="前言-1"><a href="#前言-1" class="headerlink" title="前言"></a>前言</h2><p>日常的开发中，无不都是使用数据库来进行数据的存储，由于一般的系统任务中通常不会存在高并发的情况，所以这样看起来并没有什么问题。</p>
<p>一旦涉及大数据量的需求，如一些<strong>商品抢购</strong>的情景，或者<strong>主页访问量</strong>瞬间较大的时候，单一使用数据库来保存数据的系统会因为<strong>面向磁盘</strong>，<strong>磁盘读/写</strong>速度问题有严重的性能弊端，详细的<strong>磁盘读写原理</strong>请参考这一片[]。</p>
<p>在这一瞬间成千上万的请求到来，需要系统在<strong>极短的时间</strong>内完成成<strong>千上万</strong>次的<strong>读/写操作</strong>，这个时候往往不是数据库能够承受的，极其容易造成数据库系统瘫痪，最终导致服务宕机的严重生产问题。</p>
<p>为了克服上述的问题，项目通常会引入<strong>NoSQL</strong>技术，这是一种<strong>基于内存</strong>的<strong>数据库</strong>，并且提供一定的<strong>持久化</strong>功能。</p>
<p><code>Redis</code>技术就是<code>NoSQL</code>技术中的一种。<code>Redis</code>缓存的使用，极大的提升了应用程序的性能和效率，特别是<strong>数据查询</strong>方面。</p>
<p>但同时，它也带来了一些问题。其中，最要害的问题，就是数据的一致性问题，从严格意义上讲，这个问题无解。如果对<strong>数据的一致性</strong>要求很高，那么就不能使用<strong>缓存</strong>。</p>
<p>另外的一些典型问题就是，<strong>缓存穿透</strong>、<strong>缓存击穿</strong>和<strong>缓存雪崩</strong>。本篇文章从实际代码操作，来提出解决这三个缓存问题的方案，毕竟Redis的缓存问题是实际面试中高频问点，理论和实操要兼得。</p>
<h2 id="缓存穿透"><a href="#缓存穿透" class="headerlink" title="缓存穿透"></a>缓存穿透</h2><p>缓存穿透是指查询一条数据库和缓存都没有的一条数据，就会一直查询数据库，对数据库的访问压力就会增大，缓存穿透的解决方案，有以下两种：</p>
<ol>
<li><strong>缓存空对象</strong>：代码维护较简单，但是效果不好。</li>
<li><strong>布隆过滤器</strong>：代码维护复杂，效果很好。</li>
</ol>
<h3 id="缓存空对象"><a href="#缓存空对象" class="headerlink" title="缓存空对象"></a>缓存空对象</h3><p>缓存空对象是指当一个请求过来缓存中和数据库中都不存在该请求的数据，第一次请求就会跳过缓存进行数据库的访问，并且访问数据库后返回为空，此时也将该空对象进行缓存。</p>
<p>若是再次进行访问该空对象的时候，就会直接<strong>击中缓存</strong>，而不是再次<strong>数据库</strong>，缓存空对象实现的原理图如下：</p>
<p><img src="https://img-blog.csdnimg.cn/20200411100759260.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQzMjU1MDE3,size_16,color_FFFFFF,t_70"></p>
<p>缓存空对象的实现代码如下：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line">public class UserServiceImpl &#123;</span><br><span class="line">     @Autowired</span><br><span class="line">     UserDAO userDAO;</span><br><span class="line">     @Autowired</span><br><span class="line">     RedisCache redisCache;</span><br><span class="line"> </span><br><span class="line">     public User findUser(Integer id) &#123;</span><br><span class="line">          Object object &#x3D; redisCache.get(Integer.toString(id));</span><br><span class="line">          &#x2F;&#x2F; 缓存中存在，直接返回</span><br><span class="line">          if(object !&#x3D; null) &#123;</span><br><span class="line">               &#x2F;&#x2F; 检验该对象是否为缓存空对象，是则直接返回null</span><br><span class="line">               if(object instanceof NullValueResultDO) &#123;</span><br><span class="line">                    return null;</span><br><span class="line">               &#125;</span><br><span class="line">               return (User)object;</span><br><span class="line">          &#125; else &#123;  </span><br><span class="line">               &#x2F;&#x2F; 缓存中不存在，查询数据库</span><br><span class="line">               User user &#x3D; userDAO.getUser(id);</span><br><span class="line">               &#x2F;&#x2F; 存入缓存</span><br><span class="line">               if(user !&#x3D; null) &#123;</span><br><span class="line">                    redisCache.put(Integer.toString(id),user);</span><br><span class="line">               &#125; else &#123;</span><br><span class="line">                    &#x2F;&#x2F; 将空对象存进缓存</span><br><span class="line">                    redisCache.put(Integer.toString(id), new NullValueResultDO());</span><br><span class="line">               &#125;</span><br><span class="line">               return user;</span><br><span class="line">          &#125;</span><br><span class="line">     &#125;          </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>缓存空对象的实现代码很简单，但是缓存空对象会带来比较大的问题，就是缓存中会存在很多空对象，占用<strong>内存的空间</strong>，浪费资源，一个解决的办法就是设置空对象的<strong>较短的过期时间</strong>，代码如下：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">&#x2F;&#x2F; 再缓存的时候，添加多一个该空对象的过期时间60秒</span><br><span class="line">redisCache.put(Integer.toString(id), new NullValueResultDO(),60);</span><br></pre></td></tr></table></figure>
<h3 id="布隆过滤器"><a href="#布隆过滤器" class="headerlink" title="布隆过滤器"></a>布隆过滤器</h3><p>布隆过滤器是一种基于<strong>概率</strong>的<strong>数据结构</strong>，主要用来判断某个元素是否在集合内，它具有<strong>运行速度快</strong>（时间效率），<strong>占用内存小</strong>的优点（空间效率），但是有一定的<strong>误识别率</strong>和<strong>删除困难</strong>的问题。它只能告诉你某个元素一定不在集合内或可能在集合内。</p>
<p>在计算机科学中有一种思想：<strong>空间换时间，时间换空间</strong>。一般两者是不可兼得，而布隆过滤器运行效率和空间大小都兼得，它是怎么做到的呢？</p>
<p>在布隆过滤器中引用了一个<strong>误判率</strong>的概念，即它可能会把不属于这个集合的元素认为可能属于这个集合，但是不会把属于这个集合的认为不属于这个集合，布隆过滤器的特点如下：</p>
<ol>
<li>一个非常大<strong>的二进制位数组</strong> （数组里只有0和1）</li>
<li>若干个<strong>哈希函数</strong></li>
<li><strong>空间效率</strong>和<strong>查询效率高</strong></li>
<li>不存在<strong>漏报</strong>（False Negative）：某个元素在某个集合中，肯定能报出来。</li>
<li>可能存在<strong>误报</strong>（False Positive）：某个元素不在某个集合中，可能也被爆出来。</li>
<li>不提供删除方法，代码维护困难。</li>
<li>位数组初始化都为0，它不存元素的具体值，当元素经过哈希函数哈希后的值（也就是数组下标）对应的数组位置值改为1。</li>
</ol>
<p>实际布隆过滤器存储数据和查询数据的原理图如下：</p>
<p><img src="https://img-blog.csdnimg.cn/20200411110041782.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQzMjU1MDE3,size_16,color_FFFFFF,t_70"></p>
<p>可能很多读者看完上面的特点和原理图，还是看不懂，别急下面通过图解一步一步的讲解布隆过滤器，总而言之一句简单的话概括就是布隆过滤器是一个<strong>很大二进制</strong>的<strong>位数组</strong>，数组里面<strong>只存0和1</strong>。</p>
<p>初始化的布隆过滤器的结构图如下：</p>
<p><img src="https://img-blog.csdnimg.cn/20200411110343825.png"></p>
<p>以上只是画了布隆过滤器的很小很小的一部分，实际布隆过滤器是非常大的数组（这里的大是指它的<strong>长度大</strong>，并不是指它所占的<strong>内存空间大</strong>）。</p>
<p><strong>那么一个数据是怎么存进布隆过滤器的呢？</strong></p>
<p>当一个数据进行存入布隆过滤器的时候，会经过如干个哈希函数进行哈希（若是对哈希函数还不懂的请参考这一片[]），得到对应的哈希值作为数组的下标，然后将初始化的位数组对应的下标的值修改为1，结果图如下：</p>
<p><img src="https://img-blog.csdnimg.cn/20200411110444296.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQzMjU1MDE3,size_16,color_FFFFFF,t_70"></p>
<p>当再次进行存入第二个值的时候，修改后的结果的原理图如下：</p>
<p><img src="https://img-blog.csdnimg.cn/20200411110640460.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQzMjU1MDE3,size_16,color_FFFFFF,t_70"></p>
<p>所以每次存入一个数据，就会哈希函数的计算，计算的结果就会作为下标，在布隆过滤器中有多少个哈希函数就会计算出多少个下标，布隆过滤器插入的流程如下：</p>
<ol>
<li>将要添加的元素给m个哈希函数</li>
<li>得到对应于位数组上的m个位置</li>
<li>将这m个位置设为1</li>
</ol>
<p><strong>那么为什么会有误判率呢？</strong></p>
<p>假设在我们多次存入值后，在布隆过滤器中存在x、y、z这三个值，布隆过滤器的存储结构图如下所示：</p>
<p><img src="https://img-blog.csdnimg.cn/20200411111551119.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQzMjU1MDE3,size_16,color_FFFFFF,t_70"></p>
<p>当我们要查询的时候，比如查询a这个数，实际中a这个数是不存在布隆过滤器中的，经过2哥哈希函数计算后得到a的哈希值分别为2和13，结构原理图如下：</p>
<p><img src="https://img-blog.csdnimg.cn/20200411112038115.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQzMjU1MDE3,size_16,color_FFFFFF,t_70"></p>
<p>经过查询后，发现2和13位置所存储的值都为1，但是2和13的下标分别是x和z经过计算后的下标位置的修改，该布隆过滤器中实际不存在a，那么布隆过滤器就会误判改值可能存在，因为布隆过滤器不存<strong>元素值</strong>，所以存在<strong>误判率</strong>。</p>
<p>那么具体布隆过布隆过滤的判断的准确率和一下<strong>两个因素</strong>有关：</p>
<ol>
<li><strong>布隆过滤器大小</strong>：越大，误判率就越小，所以说布隆过滤器一般长度都是非常大的。</li>
<li><strong>哈希函数的个数</strong>：哈希函数的个数越多，那么误判率就越小。</li>
</ol>
<p><strong>那么为什么不能删除元素呢？</strong></p>
<p>原因很简单，因为删除元素后，将对应元素的下标设置为零，可能别的元素的下标也引用改下标，这样别的元素的判断就会收到影响，原理图如下：</p>
<p><img src="https://img-blog.csdnimg.cn/20200411113051903.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQzMjU1MDE3,size_16,color_FFFFFF,t_70"></p>
<p>当你删除z元素之后，将对应的下标10和13设置为0，这样导致x和y元素的下标受到影响，导致数据的判断不准确，所以直接不提供删除元素的api。</p>
<p>以上说的都是布隆过滤器的原理，只有理解了原理，在实际的运用才能如鱼得水，下面就来实操代码，手写一个简单的布隆过滤器。</p>
<p>对于要手写一个布隆过滤器，首先要明确布隆过滤器的核心：</p>
<ul>
<li>若干哈希函数</li>
<li>存值得Api</li>
<li>判断值得Api</li>
</ul>
<p>实现得代码如下：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line">public class MyBloomFilter &#123;</span><br><span class="line">    &#x2F;&#x2F; 布隆过滤器长度</span><br><span class="line">    private static final int SIZE &#x3D; 2 &lt;&lt; 10;</span><br><span class="line">    &#x2F;&#x2F; 模拟实现不同的哈希函数</span><br><span class="line">    private static final int[] num&#x3D; new int[] &#123;5, 19, 23, 31,47, 71&#125;;   </span><br><span class="line">    &#x2F;&#x2F; 初始化位数组</span><br><span class="line">    private BitSet bits &#x3D; new BitSet(SIZE);</span><br><span class="line">    &#x2F;&#x2F; 用于存储哈希函数</span><br><span class="line">    private MyHash[] function &#x3D; new MyHash[num.length];</span><br><span class="line">    </span><br><span class="line">    &#x2F;&#x2F; 初始化哈希函数</span><br><span class="line">    public MyBloomFilter() &#123;</span><br><span class="line">        for (int i &#x3D; 0; i &lt; num.length; i++) &#123;</span><br><span class="line">            function [i] &#x3D; new MyHash(SIZE, num[i]);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">   </span><br><span class="line">    &#x2F;&#x2F; 存值Api </span><br><span class="line">    public void add(String value) &#123;</span><br><span class="line">        &#x2F;&#x2F; 对存入得值进行哈希计算</span><br><span class="line">        for (MyHash f: function) &#123;</span><br><span class="line">            &#x2F;&#x2F; 将为数组对应的哈希下标得位置得值改为1</span><br><span class="line">            bits.set(f.hash(value), true);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">   </span><br><span class="line">    &#x2F;&#x2F; 判断是否存在该值得Api </span><br><span class="line">    public boolean contains(String value) &#123;</span><br><span class="line">        if (value &#x3D;&#x3D; null) &#123;</span><br><span class="line">            return false;</span><br><span class="line">        &#125;</span><br><span class="line">        boolean result&#x3D; true;</span><br><span class="line">        for (MyHash f : func) &#123;</span><br><span class="line">            result&#x3D; result&amp;&amp; bits.get(f.hash(value));</span><br><span class="line">        &#125;</span><br><span class="line">        return result;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>哈希函数代码如下：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">public static class MyHash &#123;</span><br><span class="line">        private int cap;</span><br><span class="line">        private int seed;</span><br><span class="line">        &#x2F;&#x2F; 初始化数据</span><br><span class="line">        public MyHash(int cap, int seed) &#123;</span><br><span class="line">            this.cap &#x3D; cap;</span><br><span class="line">            this.seed &#x3D; seed;</span><br><span class="line">        &#125;</span><br><span class="line">        &#x2F;&#x2F; 哈希函数</span><br><span class="line">        public int hash(String value) &#123;</span><br><span class="line">            int result &#x3D; 0;</span><br><span class="line">            int len &#x3D; value.length();</span><br><span class="line">            for (int i &#x3D; 0; i &lt; len; i++) &#123;</span><br><span class="line">                result &#x3D; seed * result + value.charAt(i);</span><br><span class="line">            &#125;</span><br><span class="line">            return (cap - 1) &amp; result;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure>

<p>布隆过滤器测试代码如下：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">public static void test &#123;</span><br><span class="line">    String value &#x3D; &quot;4243212355312&quot;;</span><br><span class="line">    MyBloomFilter filter &#x3D; new MyBloomFilter();</span><br><span class="line">    System.out.println(filter.contains(value));</span><br><span class="line">    filter.add(value);</span><br><span class="line">    System.out.println(filter.contains(value));</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>以上就是手写了一个非常简单得布隆过滤器，但是实际项目中可能事由牛人或者大公司已经帮你写好的，如谷歌的<code>Google Guava</code>，只需要在项目中引入一下依赖：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">&lt;dependency&gt;</span><br><span class="line">    &lt;groupId&gt;com.google.guava&lt;&#x2F;groupId&gt;</span><br><span class="line">    &lt;artifactId&gt;guava&lt;&#x2F;artifactId&gt;</span><br><span class="line">    &lt;version&gt;27.0.1-jre&lt;&#x2F;version&gt;</span><br><span class="line">&lt;&#x2F;dependency&gt;</span><br></pre></td></tr></table></figure>
<p>实际项目中具体的操作代码如下：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">public static void MyBloomFilterSysConfig &#123;</span><br><span class="line"></span><br><span class="line">     @Autowired</span><br><span class="line">     OrderMapper orderMapper</span><br><span class="line">     </span><br><span class="line">    &#x2F;&#x2F; 1.创建布隆过滤器  第二个参数为预期数据量10000000，第三个参数为错误率0.00001</span><br><span class="line">    BloomFilter&lt;CharSequence&gt; bloomFilter &#x3D;  BloomFilter.create(Funnels.stringFunnel(Charset.forName(&quot;utf-8&quot;)),10000000, 0.00001);</span><br><span class="line">    &#x2F;&#x2F; 2.获取所有的订单，并将订单的id放进布隆过滤器里面</span><br><span class="line">    List&lt;Order&gt; orderList &#x3D; orderMapper.findAll()</span><br><span class="line">    for (Order order;orderList ) &#123;</span><br><span class="line">        Long id &#x3D; order.getId();</span><br><span class="line">        bloomFilter.put(&quot;&quot; + id);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>在实际项目中会启动一个<strong>系统任务</strong>或者<strong>定时任务</strong>，来初始化布隆过滤器，将热点查询数据的id放进布隆过滤器里面，当用户再次请求的时候，使用布隆过滤器进行判断，改订单的id是否在布隆过滤器中存在，不存在直接返回null，具体操作代码：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">&#x2F;&#x2F; 判断订单id是否在布隆过滤器中存在</span><br><span class="line">bloomFilter.mightContain(&quot;&quot; + id)</span><br></pre></td></tr></table></figure>
<p>布隆过滤器的缺点就是要维持容器中的数据，因为订单数据肯定是频繁变化的，实时的要更新布隆过滤器中的数据为最新。</p>
<h2 id="缓存击穿"><a href="#缓存击穿" class="headerlink" title="缓存击穿"></a>缓存击穿</h2><p><strong>缓存击穿</strong>是指一个<code>key</code>非常热点，在不停的扛着大并发，<strong>大并发</strong>集中对这一个点进行访问，当这个key在失效的瞬间，持续的<strong>大并发</strong>就穿破缓存，直接请求数据库，瞬间对数据库的访问压力增大。</p>
<p>缓存击穿这里强调的是<strong>并发</strong>，造成缓存击穿的原因有以下两个：</p>
<ol>
<li>该数据没有人查询过 ，第一次就大并发的访问。（冷门数据）</li>
<li>添加到了缓存，reids有设置数据失效的时间 ，这条数据刚好失效，大并发访问（热点数据）</li>
</ol>
<p>对于缓存击穿的解决方案就是加锁，具体实现的原理图如下：</p>
<p><img src="https://img-blog.csdnimg.cn/20200411153315173.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQzMjU1MDE3,size_16,color_FFFFFF,t_70"></p>
<p>当用户出现<strong>大并发</strong>访问的时候，在查询缓存的时候和查询数据库的过程加锁，只能第一个进来的请求进行执行，当第一个请求把该数据放进缓存中，接下来的访问就会直接集中缓存，防止了<strong>缓存击穿</strong>。</p>
<p>业界比价普遍的一种做法，即根据key获取value值为空时，锁上，从数据库中<code>load</code>数据后再释放锁。若其它线程获取锁失败，则等待一段时间后重试。这里要注意，分布式环境中要使用<strong>分布式锁</strong>，<strong>单机</strong>的话用普通的锁（<code>synchronized</code>、<code>Lock</code>）就够了。</p>
<p>下面以一个获取商品库存的案例进行代码的演示，<strong>单机版</strong>的锁实现具体实现的代码如下：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">&#x2F;&#x2F; 获取库存数量</span><br><span class="line">public String getProduceNum(String key) &#123;</span><br><span class="line">    try &#123;</span><br><span class="line">        synchronized (this) &#123;   &#x2F;&#x2F;加锁</span><br><span class="line">            &#x2F;&#x2F; 缓存中取数据，并存入缓存中</span><br><span class="line">            int num&#x3D; Integer.parseInt(redisTemplate.opsForValue().get(key));</span><br><span class="line">            </span><br><span class="line">            if (num&gt; 0) &#123;</span><br><span class="line">                &#x2F;&#x2F;没查一次库存-1</span><br><span class="line">                redisTemplate.opsForValue().set(key, (num- 1) + &quot;&quot;);</span><br><span class="line">                System.out.println(&quot;剩余的库存为num：&quot; + (num- 1));</span><br><span class="line">            &#125; else &#123;</span><br><span class="line">                System.out.println(&quot;库存为0&quot;);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125; catch (NumberFormatException e) &#123;</span><br><span class="line">        e.printStackTrace();</span><br><span class="line">    &#125; finally &#123;</span><br><span class="line">    &#125;</span><br><span class="line">    return &quot;OK&quot;;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p><strong>分布式</strong>的锁实现具体实现的代码如下：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">public String getProduceNum(String key) &#123;</span><br><span class="line">    &#x2F;&#x2F; 获取分布式锁</span><br><span class="line">    RLock lock &#x3D; redissonClient.getLock(key);</span><br><span class="line">    try &#123;</span><br><span class="line">        &#x2F;&#x2F; 获取库存数</span><br><span class="line">        int num&#x3D; Integer.parseInt(redisTemplate.opsForValue().get(key));  </span><br><span class="line">        &#x2F;&#x2F; 上锁           </span><br><span class="line">        lock.lock();</span><br><span class="line">        if (num&gt; 0) &#123;</span><br><span class="line">            &#x2F;&#x2F;减少库存，并存入缓存中</span><br><span class="line">            redisTemplate.opsForValue().set(key, (num - 1) + &quot;&quot;);</span><br><span class="line">            System.out.println(&quot;剩余库存为num：&quot; + (num- 1));</span><br><span class="line">        &#125; else &#123;</span><br><span class="line">            System.out.println(&quot;库存已经为0&quot;);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125; catch (NumberFormatException e) &#123;</span><br><span class="line">        e.printStackTrace();</span><br><span class="line">    &#125; finally &#123;</span><br><span class="line">        &#x2F;&#x2F;解锁</span><br><span class="line">        lock.unlock();</span><br><span class="line">    &#125;</span><br><span class="line">    return &quot;OK&quot;;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h2 id="缓存雪崩"><a href="#缓存雪崩" class="headerlink" title="缓存雪崩"></a>缓存雪崩</h2><p>缓存雪崩 是指在某一个时间段，缓存集中过期失效。此刻无数的请求直接绕开缓存，直接请求数据库。</p>
<p>造成缓存雪崩的原因，有以下两种：</p>
<ol>
<li>reids宕机</li>
<li>大部分数据失效</li>
</ol>
<p>比如天猫双11，马上就要到双11零点，很快就会迎来一波抢购，这波商品在23点集中的放入了缓存，假设缓存一个小时，那么到了凌晨24点的时候，这批商品的缓存就都过期了。</p>
<p>而对这批商品的访问查询，都落到了数据库上，对于数据库而言，就会产生周期性的压力波峰，对数据库造成压力，甚至压垮数据库。</p>
<p>缓存雪崩的原理图如下，当正常的情况下，key没有大量失效的用户访问原理图如下：</p>
<p><img src="https://img-blog.csdnimg.cn/20200411160745295.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQzMjU1MDE3,size_16,color_FFFFFF,t_70"></p>
<p>当某一时间点，key大量失效，造成的缓存雪崩的原理图如下：</p>
<p><img src="https://img-blog.csdnimg.cn/20200411161306232.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQzMjU1MDE3,size_16,color_FFFFFF,t_70"></p>
<p>对于缓存雪崩的解决方案有以下两种：</p>
<ol>
<li>搭建高可用的集群，防止单机的redis宕机。</li>
<li>设置不同的过期时间，防止同意之间内大量的key失效。</li>
</ol>
<blockquote>
<p>针对业务系统，永远都是具体情况具体分析，没有最好，只有最合适。于缓存其它问题，缓存满了和数据丢失等问题，我们后面继续深入的学习。最后也提一下三个词LRU、RDB、AOF，通常我们采用LRU策略处理溢出，Redis的RDB和AOF持久化策略来保证一定情况下的数据安全。</p>
</blockquote>
<h1 id="redis持久化"><a href="#redis持久化" class="headerlink" title="redis持久化"></a>redis持久化</h1><h4 id="本文脑图-2"><a href="#本文脑图-2" class="headerlink" title="本文脑图"></a>本文脑图</h4><p><img src="https://img-blog.csdnimg.cn/20200505232201367.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQzMjU1MDE3,size_16,color_FFFFFF,t_70"></p>
<p><code>Redis</code>是一个基于内存的非关系型的数据库，数据保存在内存中，但是内存中的数据也容易发生丢失。这里Redis就为我们提供了持久化的机制，分别是<code>RDB(Redis DataBase)</code>和<code>AOF(Append Only File)</code>。</p>
<p>Redis在以前的版本中是单线程的，而在6.0后对Redis的io模型做了优化，<code>io Thread</code>为多线程的，但是<code>worker Thread</code>仍然是单线程。</p>
<p>在Redis启动的时候就会去加载持久化的文件，如果没有就直接启动，在启动后的某一时刻由继续持久化内存中产生的数据。</p>
<p>接下来我们就来详细了解Redis的两种持久化机制<code>RDB(Redis DataBase)</code>和<code>AOF(Append Only File)</code>。</p>
<h4 id="RDB持久化机制"><a href="#RDB持久化机制" class="headerlink" title="RDB持久化机制"></a>RDB持久化机制</h4><p>什么是RDB持久化呢？RDB持久化就是将当前进程的数据以生成快照的形式持久化到磁盘中。对于快照的理解，我们可以理解为将当前线程的数据以拍照的形式保存下来。</p>
<p>RDB持久化的时候会单独fork一个与当前进程一摸一样的子进程来进行持久化，因此RDB持久化有如下特点：</p>
<ol>
<li>开机恢复数据快。</li>
<li>写入持久化文件快。</li>
</ol>
<p>RDB的持久化也是Redis默认的持久化机制，它会把内存中的数据以快照的形式写入默认文件名为<code>dump.rdb</code>中保存。</p>
<p>在安装后的Redis中，Redis的配置都在<code>redis.conf</code>文件中，如下图所示，<code>dbfilename</code>就是配置RDB的持久化文件名。</p>
<p><img src="https://img-blog.csdnimg.cn/20200506232121606.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQzMjU1MDE3,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p>
<h5 id="持久化触发时机"><a href="#持久化触发时机" class="headerlink" title="持久化触发时机"></a>持久化触发时机</h5><p>在RDB机制中触发内存中的数据进行持久化，有以下三种方式：</p>
<p>（1）<strong>save命令：</strong> </p>
<p>save命令不会fork子进程，通过阻塞当前Redis服务器，直到RDB完成为止，所以该命令在生产中一般不会使用。save命令执行原理图如下:</p>
<p><img src="https://img-blog.csdnimg.cn/20200507073951298.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQzMjU1MDE3,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p>
<p>在redis.conf的配置中<code>dir</code>的配置就是RDB持久化后生成rdb二进制文件所在的位置，默认的位置是<code>./</code>，表示当前位置，哪里启动redis，就会在哪里生成持久化文件，如下图所示：</p>
<p><img src="https://img-blog.csdnimg.cn/20200507074629992.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQzMjU1MDE3,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p>
<p>下面我们进行一下实操，演示一下二进制文件生成的过程，在我本机的电脑虚拟机中，我所在的位置如下，该文件夹是新创建的redis的数据存储文件夹。</p>
<p><img src="https://img-blog.csdnimg.cn/20200507080808985.png" alt="在这里插入图片描述"></p>
<p>然后我们直接在该位置启动我们的Redis服务，启动的命令如下：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&#x2F;root&#x2F;redis-4.0.6&#x2F;src&#x2F;redis-server &#x2F;root&#x2F;redis-4.0.6&#x2F;redis.conf</span><br></pre></td></tr></table></figure>
<p>接着通过该命令：<code>ps -aux | grep redis</code>，查看我们的redis服务是否正常启动，若是显示如下图所示，则表示Redis是正常启动的：</p>
<p><img src="https://img-blog.csdnimg.cn/20200507081644202.png" alt="在这里插入图片描述"></p>
<p>正常启动后，直接登陆Redis，可以通过以下命令登陆Redis，如下图所示：</p>
<p><img src="https://img-blog.csdnimg.cn/20200507081855530.png" alt="在这里插入图片描述"></p>
<p>因为当前中Redis是新安装的，数据都是为空，什么都没有，然后通过下图的命令随意向Redis中输入几条命令，最后执行<code>save</code>命令，在该文件夹下就会出现<code>dump.rdb</code>持久化的数据文件。</p>
<p><img src="https://img-blog.csdnimg.cn/20200507082105977.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQzMjU1MDE3,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p>
<p>当然上面说到，在新安装的Redis中默认的RDB数据持久化位置为<code>./</code>文件，一般我们会把它改成服务器自己的特定位置下，原理都是一样的，可以自己进行尝试，这里不再进行演示。</p>
<p> （2）<strong>bgsave命令：</strong></p>
<p><code>bgsave</code>命令会在后台fork一个与Redis主线程一摸一样的子线程，由子线程负责内存中的数据持久化。</p>
<p>这样fork与主线程一样的子线程消耗了内存，但是不会阻塞主线程处理客户端请求，是以空间换时间的方式快照内存中的数据到到文件中。</p>
<p><code>bgsave</code>命令阻塞只会发生在fork子线程的时候，这段时间发生的非常短，可以忽略不计，如下图是 bgsave执行的流程图：</p>
<p> <img src="https://img-blog.csdnimg.cn/20200507191631279.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQzMjU1MDE3,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p>
<p>上面说到redis.conf中的<code>dir</code>配置是配置持久化文件生成的指定的目录，<code>dbfilename</code>是配置生成的文件名，也可以通过命令行使用命令来动态的设置这两个配置，命令如下：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">config set dir&#123;newDir&#125;</span><br><span class="line">config set dbfilename&#123;newFileName&#125;</span><br></pre></td></tr></table></figure>

<p> （3）<strong>自动化</strong></p>
<p>除了上面在命令行使用save和bgsave命令触发持久化，也可以在<code>redis.conf</code>配置文件中，完成配置，如下图所示：</p>
<p><img src="https://img-blog.csdnimg.cn/20200507192828457.png" alt="在这里插入图片描述"></p>
<p>在新安装的redis中由默认的以上三个save配置，<code>save 900 1</code>表示900秒内如果至少有1个key值变化，则进行持久化保存数据；</p>
<p><code>save 300 10</code>则表示300秒内如果至少有10个key值发生变化，则进行持久化，<code>save 60 10000</code>以此类推。</p>
<p>通过以上的分析可以得出以下save和bgsave的对比区别：</p>
<ol>
<li>save是<strong>同步</strong>持久化数据，而bgsave是<strong>异步</strong>持久化数据。</li>
<li><code>save</code>不会fork子进程，通过<strong>主进程</strong>持久化数据，会<strong>阻塞</strong>处理客户端的请求，而<code>bdsave</code>会<code>fork</code>子进程持久化数据，同时还可以处理客户端请求，高效。</li>
<li>save<strong>不会消耗内存</strong>，而bgsave<strong>会消耗内存</strong>。</li>
</ol>
<h5 id="RDB的优缺点"><a href="#RDB的优缺点" class="headerlink" title="RDB的优缺点"></a>RDB的优缺点</h5><p><strong>缺点：</strong> RDB持久化后的文件是紧凑的二进制文件，适合于备份、全量复制、大规模数据恢复的场景，对数据完整性和一致性要求不高，RDB会丢失最后一次快照的数据。</p>
<p><strong>优点：</strong> 开机的恢复数据快，写入持久化文件快。</p>
<h4 id="AOF持久化机制"><a href="#AOF持久化机制" class="headerlink" title="AOF持久化机制"></a>AOF持久化机制</h4><p>AOF持久化机制是以日志的形式记录Redis中的每一次的增删改操作，不会记录查询操作，以文本的形式记录，打开记录的日志文件就可以查看操作记录。</p>
<p>AOF是默认不开启的，若是像开启AOF，在如下图的配置修改即可：</p>
<p><img src="https://img-blog.csdnimg.cn/20200507200033143.png" alt="在这里插入图片描述"></p>
<p>只需要把<code>appendonly no</code>修改为<code>appendonly yes</code>即可开启，在AOF中通过<code>appendfilename</code>配置生成的文件名，该文件名默认为<code>appendonly.aof</code>，路径也是通过dir配置的，这个于RDB的一样，具体的配置信息如下图所示：</p>
<p><img src="https://img-blog.csdnimg.cn/2020050720034171.png" alt="在这里插入图片描述"></p>
<h5 id="AOF触发机制"><a href="#AOF触发机制" class="headerlink" title="AOF触发机制"></a>AOF触发机制</h5><p>AOF带来的持久化更加安全可靠，默认提供<strong>三种</strong>触发机制，如下所示：</p>
<ol>
<li><code>no</code>：表示等操作系统等数据缓存同步到磁盘中（快、持久化没保证）。</li>
<li><code>always</code>：同步持久化，每次发生数据变更时，就会立即记录到磁盘中（慢，安全）。</li>
<li><code>everysec</code>：表示每秒同步一次（默认值，很快，但是会丢失一秒内的数据）。</li>
</ol>
<p>AOF中每秒同步也是异步完成的，<strong>效率是非常高</strong>的，由于该机制对日志文件的写入操作是采用<code>append</code>的形式。</p>
<p>因此在写入的过程即使宕机，也不会丢失已经存入日志文件的数据，数据的完整性是非常高的。</p>
<p>在新安装的Redis的配置文件中，AOF的配置如下所示：</p>
<p><img src="https://img-blog.csdnimg.cn/20200507201238235.png" alt="在这里插入图片描述"></p>
<h5 id="AOF重写机制"><a href="#AOF重写机制" class="headerlink" title="AOF重写机制"></a>AOF重写机制</h5><p>但是，在写入所有的操作到日志文件中时，就会出现日志文件很多重复的操作，甚至是无效的操作，导致日志文件越来越大。</p>
<p>所谓的无效的的操作，举个例子，比如某一时刻对一个k++，然后后面的某一时刻k–，这样k的值是保持不变的，那么这两次的操作就是无效的。</p>
<p>如果像这样的无效操作很多，记录的文件臃肿，就浪费了资源空间，所以在Redis中出现了<code>rewrite</code>机制。</p>
<p>redis提供了bgrewriteaof命令。将内存中的数据以命令的方式保存到临时文件中，同时会fork出一条新进程来将文件重写。</p>
<p>重写AOF的日志文件不是读取旧的日志文件瘦身，而是将内存中的数据用命令的方式重写一个AOF文件，重新保存替换原来旧的日志文件，因此内存中的数据才是最新的。</p>
<p>重写操作也会<code>fork</code>一个子进程来处理重写操作，重写以内存中的数据作为重写的源，避免了操作的冗余性，保证了数据的最新。</p>
<p>在Redis以append的形式将修改的数据写入老的磁盘中    ，同时Redis也会创建一个新的文件用于记录此期间有哪些命令被执行。</p>
<p>下面进行演示一下AOF的操作，首先先打开AOF机制，修改配置文件中的<code>appendonly no</code>为<code>appendonly yes</code>，然后执行如下图的操作：</p>
<p><img src="https://img-blog.csdnimg.cn/20200507202541200.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQzMjU1MDE3,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p>
<p>都显示执行成功，ls以下查看此时当前的文件夹终究会出现<code>appendonly.aof</code><br>，AOF的数据持久化文件，通过cat命令查看内容：</p>
<p><img src="https://img-blog.csdnimg.cn/20200507202738498.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQzMjU1MDE3,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p>
<p>从上面的存储的文件中可以看出，每一个命令是非常有规律的，比如第一次执行<code>key *</code>映射到该配置文件中的命令如下：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">*2 &#x2F;&#x2F;表示该命令两组key 为一组 * 为一组</span><br><span class="line">$6 &#x2F;&#x2F;表示SELECT有6字符</span><br><span class="line">SELECT</span><br><span class="line">$1 &#x2F;&#x2F;表示下面的0一个字符</span><br><span class="line">0</span><br></pre></td></tr></table></figure>
<p>然后执行<code>set k1 1</code>的命令，此命令映射到文件中的命令如下：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">*3 &#x2F;&#x2F;表示该命令有三组set为一组 k1为一组 1为一组</span><br><span class="line">$3 &#x2F;&#x2F; 表示set有三个字符</span><br><span class="line">set &#x2F;&#x2F; 表示执行了set命令</span><br><span class="line">$2 &#x2F;&#x2F; 表示k1有两个字符</span><br><span class="line">k1 &#x2F;&#x2F; key值</span><br><span class="line">$1 &#x2F;&#x2F; 便是value值的字符长度为1</span><br><span class="line">1  &#x2F;&#x2F; value值</span><br></pre></td></tr></table></figure>
<p>当AOF的日志文件增长到一定大小的时候Redis就能够bgrewriteaof对日志文件进行重写瘦身。当AOF配置文件大于改配置项时自动开启重写（这里指超过原大小的100%）。</p>
<p>该配置可以通过如下的配置项进行配置：</p>
<p><img src="https://img-blog.csdnimg.cn/20200507204110866.png" alt="在这里插入图片描述"></p>
<h5 id="AOF的优缺点"><a href="#AOF的优缺点" class="headerlink" title="AOF的优缺点"></a>AOF的优缺点</h5><p><strong>优点：</strong> AOF更好保证数据不会被丢失，最多只丢失一秒内的数据，通过foek一个子进程处理持久化操作，保证了主进程不会进程io操作，能高效的处理客户端的请求。</p>
<p>另外重写操作保证了数据的有效性，即使日志文件过大也会进行重写。</p>
<p>AOF的日志文件的记录可读性非常的高，即使某一时刻有人执行<code>flushall</code>清空了所有数据，只需要拿到aof的日志文件，然后把最后一条的flushall给删除掉，就可以恢复数据。</p>
<p><strong>缺点：</strong>  对于相同数量的数据集而言，AOF文件通常要大于RDB文件。RDB 在恢复大数据集时的速度比 AOF 的恢复速度要快。AOF在运行效率上往往会慢于RDB。 </p>
<h4 id="混合持久化"><a href="#混合持久化" class="headerlink" title="混合持久化"></a>混合持久化</h4><p>在redis4.0后混合持久化（RDB+AOF）对重写的优化，4.0版本的混合持久化默认是关闭的，可以通过以下的配置开启混合持久化：</p>
<p><img src="https://img-blog.csdnimg.cn/20200507205817706.png" alt="在这里插入图片描述"></p>
<p>混合持久化也是通过<code>bgrewriteaof</code>来完成的，不同的是当开启混合持久化时，fork出的子进程先将共享内存的数据以RDB方式写入aof文件中，然后再将重写缓冲区的增量命令以AOF方式写入文件中。</p>
<p>写入完成后通知主进程统计信息，并将新的含有RDB格式和AOF格式的AOF文件替换旧的AOF文件。简单的说：新的AOF文件前半段是以RDB格式的全量数据后半段是AOF格式的增量数据。</p>
<p><strong>优点：</strong> 混合持久化结合<strong>RDB持久化</strong>和<strong>AOF持久化</strong>的优点，由于绝大部分的格式是RDB格式，加载速度快，增量数据以AOF方式保存，数据更少的丢失。</p>
<h4 id="RDB和AOF优势和劣势"><a href="#RDB和AOF优势和劣势" class="headerlink" title="RDB和AOF优势和劣势"></a>RDB和AOF优势和劣势</h4><p>rdb适合大规模的数据恢复，由于rdb时异快照的形式持久化数据，恢复的数据快，在一定的时间备份一次，而aof的保证数据更加完整，损失的数据只在秒内。</p>
<p>具体哪种更适合生产，在官方的建议中两种持久化机制同时开启，如果两种机制同时开启，优先使用aof持久化机制。</p>
<h1 id="redis事务"><a href="#redis事务" class="headerlink" title="redis事务"></a>redis事务</h1><h2 id="前言-2"><a href="#前言-2" class="headerlink" title="前言"></a>前言</h2><p>前几天有读者说自己面试被问到Redis的事务，虽然不常用，但是面试竟然被问到，平时自己没有注意Redis的事务这一块，面试的时候被问到非常不好受。</p>
<p>虽然，这位读者面试最后算是过了，但是薪资方面没有拿到自己理想的薪资。</p>
<p>其实这个也是正常的，一般面试被问到烂大街的，谁还问你啊，专门挑一些不常见的来问你，就是为了压你的薪资。</p>
<p>所以在这里写一篇文章对Redis的事务进行详细的讲解，估计对Redis事务从理解到原理深入这一篇就够了。</p>
<p>以后面试都不用担心了再被问道Redis的事务了，这一篇主要讲解Redis事务原理和实操的演练，理解理论的同时也通过实操来证实理论。</p>
<h2 id="事务介绍"><a href="#事务介绍" class="headerlink" title="事务介绍"></a>事务介绍</h2><p>Redis事务是一组命令的集合，将多个命令进行打包，然后这些命令会被顺序的添加到队列中，并且按顺序的执行这些命令。</p>
<p><strong>Redis事务中没有像Mysql关系型数据库事务隔离级别的概念，不能保证原子性操作，也没有像Mysql那样执行事务失败会进行回滚操作</strong>。</p>
<p>这个与Redis的特点：<strong>快速、高效</strong>有着密切的关联，<strong>因为一些列回滚操作、像事务隔离级别那这样加锁、解锁，是非常消耗性能的</strong>。所以，Redis中执行事务的流程只需要简单的下面三个步骤：</p>
<ol>
<li>开始事务（MULTI）</li>
<li>命令入队</li>
<li>执行事务（EXEC）、撤销事务（DISCARD ）</li>
</ol>
<p>在Redis中事务的实现主要是通过如下的命令实现的：<br>| 命令 | 功能描述 |<br>|–|–|<br>| MULTI |  <strong>事务开始的命令</strong>，执行该命令后，后面执行的对Redis数据类型的<strong>操作命令都会顺序的放进队列中</strong>，等待执行EXEC命令后队列中的命令才会被执行 |<br>| DISCARD | <strong>放弃执行队列中的命令</strong>，你可以理解为Mysql的回滚操作，<strong>并且将当前的状态从事务状态改为非事务状态</strong>。 |<br>| EXEC | 执行该命令后<strong>表示顺序执行队列中的命令</strong>，执行完后并将结果显示在客户端，<strong>将当前状态从事务状态改为非事务状态</strong>。若是执行该命令之前有key被执行WATCH命令并且又被其它客户端修改，那么就会放弃执行队列中的所有命令，在客户端显示报错信息，若是没有修改就会执行队列中的所有命令。 |<br>| WATCH key | 表示指定监视某个key，<strong>该命令只能在MULTI命令之前执行</strong>，如果监视的key被其他客户端修改，<strong>EXEC将会放弃执行队列中的所有命令</strong> |<br>| UNWATCH | <strong>取消监视之前通过WATCH 命令监视的key</strong>，通过执行EXEC 、DISCARD 两个命令之前监视的key也会被取消监视 |</p>
<p>以上就是一个Redis事务的执行过程包含的命令，下面就来详细的围绕着这几个命令进行讲解。</p>
<h2 id="开始事务"><a href="#开始事务" class="headerlink" title="开始事务"></a>开始事务</h2><p><code>MULTI</code> 命令表示事务的开始，当看到OK表示已经进入事务的状态：<br><img src="https://img-blog.csdnimg.cn/20200703073228192.png"><br>该命令执行后客户端会将<strong>当前的状态从非事务状态修改为事务状态</strong>，这一状态的切换是将客户端的<code>flags</code>属性中打开<code>REDIS_MULTI</code>来完成的，该命令可以理解关系型数据库Mysql的<code>BEGIN TRANCATION</code>语句：<br><img src="https://img-blog.csdnimg.cn/20200703074516186.png"></p>
<h2 id="命令入队"><a href="#命令入队" class="headerlink" title="命令入队"></a>命令入队</h2><p>执行完MULTI命令后，后面执行的操作Redis五种类型的命令都会按顺序的进入命令队列中，该部分也是真正的业务逻辑的部分。</p>
<p>Redis客户端的命令执行后若是当前状态处于事务状态命令就会进入队列中，并且返回<code>QUEUED</code>字符串，表示该命令已经进入了命令队列中，并且<strong>事务队列是以先进先出（FIFO）的方式保存入队的命令</strong>的。<br><img src="https://img-blog.csdnimg.cn/20200703080352386.png"><br>若是当前状态是非事务状态就会立即执行命令，并将结果返回客户端。在事务状态<strong>执行操作事务的命令就会被立即执行</strong>，如<code>EXEC、DISCARD、UNWATCH</code>。<br><img src="https://img-blog.csdnimg.cn/20200703080802488.png"><br>结合上面的分析，Redis执行命令的流程如下图所示：<br><img src="https://img-blog.csdnimg.cn/20200703215457160.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQzMjU1MDE3,size_16,color_FFFFFF,t_70"><br>事务的命令队列中有三个参数分别是：<strong>要执行的命令</strong>、<strong>命令的参数</strong>、<strong>参数的个数</strong>。例如：通过执行如下的命令：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">redis&gt; MULTI</span><br><span class="line">OK</span><br><span class="line">redis&gt; SET name &quot;黎杜&quot;</span><br><span class="line">QUEUED</span><br><span class="line">redis&gt; GET name</span><br><span class="line">QUEUED</span><br></pre></td></tr></table></figure>
<p>那么对应上面的队列中三个参数如下表格所示：<br>| 执行的命令 | 命令的参数 | 参数的个数|<br>|–|–| –|<br>| SET |     [“name”, “黎杜”] | 2 |<br>| GET |     [“name”] | 1 |</p>
<h2 id="执行事务"><a href="#执行事务" class="headerlink" title="执行事务"></a>执行事务</h2><p>当客户端执行EXEC命令的时候，上面的命令队列就会被按照先进先出的顺序被执行，当然执行的结果有成功有失败，这个后面分析。</p>
<p>上面说到当客户端处于非事务的状态命令发送到服务端会被立即执行，若是客户端处于事务状态命令就会被放进命令队列。</p>
<p>命令入队的时候，会按照顺序进入队列，队列以先进先出的特点来执行队列中的命令。</p>
<p>若是客户端处于事务状态，执行的是<code>EXEC、DISCARD、UNWATCH</code>这些操作事务的命令，也会被立即执行。<br><img src="https://img-blog.csdnimg.cn/20200703215457160.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQzMjU1MDE3,size_16,color_FFFFFF,t_70"><br><strong>（1）正常执行</strong></p>
<p>还是上面的例子，执行如下的代码：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">redis&gt; MULTI</span><br><span class="line">OK</span><br><span class="line">redis&gt; SET name &quot;黎杜&quot;</span><br><span class="line">QUEUED</span><br><span class="line">redis&gt; GET name</span><br><span class="line">QUEUED</span><br></pre></td></tr></table></figure>
<p>所有的命令进入了队列，当最后执行EXEC，首先会执行SET命令，然后执行GET命令，并且执行后的结果也会进入一个队列中保存，最后返回给客户端：<br>| 回复的类型 | 回复的内容 |<br>|–|–| –|<br>| status code reply | OK |<br>| bulk reply | “黎杜” | </p>
<p>所以最后你会在客户端看到<strong>OK、黎杜</strong>，这样的结果显示，这个也就是一个事务成功执行的过程。</p>
<p>至此一个事务就完整的执行完成，并且此时客户端也从事务状态更改为非事务状态。<br><img src="https://img-blog.csdnimg.cn/20200703223053698.png"></p>
<p><strong>（2）放弃事务</strong></p>
<p>当然你也可以放弃执行该事务，只要你再次执行DISCARD操作就会放弃执行此次的事务。具体代码如下所示：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">redis&gt; MULTI</span><br><span class="line">OK</span><br><span class="line">redis&gt; SET name &quot;黎杜&quot;</span><br><span class="line">QUEUED</span><br><span class="line">redis&gt; GET name</span><br><span class="line">QUEUED</span><br><span class="line">redis&gt; DISCARD    &#x2F;&#x2F; 放弃执行事务</span><br><span class="line">OK</span><br></pre></td></tr></table></figure>
<p>DISCARD命令取消一个事务的时候，就会将命令队列清空，并且将客户端的状态从事务状态修改为非事务的状态。</p>
<p><strong>Redis的事务是不可重复的</strong>，当客户端处于事务状态的时候，再次向服务端发送MULTI命令时，直接就会向客户端返回错误。</p>
<h2 id="WATCH-命令"><a href="#WATCH-命令" class="headerlink" title="WATCH 命令"></a>WATCH 命令</h2><p><code>WATCH</code>命令是在MULTI命令之前执行的，表示监视任意数量的key，与它对应的命令就是<code>UNWATCH</code>命令，取消监视的key。</p>
<p><code>WATCH</code>命令有点<strong>类似于乐观锁机制</strong>，在事务执行的时候，若是被监视的任意一个key被更改，则队列中的命令不会被执行，直接向客户端返回(nil)表示事务执行失败。</p>
<p>下面我们来演示一下WATCH命令的操作流程，具体实现代码如下：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">redis&gt; WATCH num</span><br><span class="line">OK</span><br><span class="line">redis&gt; MULTI</span><br><span class="line">OK</span><br><span class="line">redis&gt; incrby num 10</span><br><span class="line">QUEUED</span><br><span class="line">redis&gt; decrby num 1</span><br><span class="line">QUEUED</span><br><span class="line">redis&gt; EXEC   &#x2F;&#x2F; 执行成功</span><br></pre></td></tr></table></figure>
<p>这个是<code>WATCH</code>命令的正常的操作流程，若是在其它的客户端，修改了被监视的任意key，就会放弃执行该事务，如下图所示：<br>| 客户端一 | 客户端二 |<br>|–|–|<br>| WATCH num |  |<br>| MULTI |  |<br>| incrby num 10 | get num |<br>|  | decrby num 1 |<br>| EXEC |  |<br>| 执行失败，返回(nil) |  |</p>
<p>WATCH命令的底层实现中保存了<code>watched_keys</code> 字典，<strong>字典的键保存的是监视的key，值是一个链表，链表中的每个节点值保存的是监视该key的客户端</strong>。<br><img src="https://img-blog.csdnimg.cn/20200703232716480.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQzMjU1MDE3,size_16,color_FFFFFF,t_70"><br>若是某个客户端不再监视某个key，该客户端就会从链表中脱离。如client3，通过执行UNWATCH命令，不再监视key1：<br><img src="https://img-blog.csdnimg.cn/20200703232916783.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQzMjU1MDE3,size_16,color_FFFFFF,t_70"></p>
<h2 id="错误处理"><a href="#错误处理" class="headerlink" title="错误处理"></a>错误处理</h2><p>上面说到Redis是没有回滚机制的，那么执行的过程，若是不小心敲错命令，Redis的命令发送到服务端没有被立即执行，所以是暂时发现不到该错误。</p>
<p>那么在Redis中的错误处理主要分为两类：<strong>语法错误</strong>、<strong>运行错误</strong>。下面主要来讲解一下这两类错误的区别。</p>
<p><strong>（1）语法错误</strong></p>
<p>比如执行命令的时候，命令的不存在或者错误的敲错命令、参数的个数不对等都会导致语法错误。</p>
<p>下面来演示一下，执行下面的四个命令，前后的两个命令是正确的，中间的两个命令是错误的，如下所示：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">127.0.0.1:6379&gt; multi</span><br><span class="line">OK</span><br><span class="line">127.0.0.1:6379&gt; set num 1</span><br><span class="line">QUEUED</span><br><span class="line">127.0.0.1:6379&gt; set num</span><br><span class="line">(error) ERR wrong number of arguments for &#39;set&#39; command</span><br><span class="line">127.0.0.1:6379&gt; ssset num 3</span><br><span class="line">(error) ERR unknown command &#39;ssset&#39;</span><br><span class="line">127.0.0.1:6379&gt; set num 2</span><br><span class="line">QUEUED</span><br><span class="line">127.0.0.1:6379&gt; exec</span><br><span class="line">(error) EXECABORT Transaction discarded because of previous errors.</span><br></pre></td></tr></table></figure>

<p>语法错误是在Redis语法检测的时候就能发现的，所以当你执行错误命令的时候，也会即使的返回错误的提示。</p>
<p>最后，即使命令进入队列，只要存在语法错误，该队列中的命令都不会被执行，会直接向客户端返回事务执行失败的提示。</p>
<p><strong>（2）运行错误</strong></p>
<p>执行时使用不同类型的操作命令操作不同数据类型就会出现运行时错误，这种错误时Redis在不执行命令的情况下，是无法发现的。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">127.0.0.1:6379&gt; multi</span><br><span class="line">OK</span><br><span class="line">127.0.0.1:6379&gt; set num 3</span><br><span class="line">QUEUED</span><br><span class="line">127.0.0.1:6379&gt; sadd num 4</span><br><span class="line">QUEUED</span><br><span class="line">127.0.0.1:6379&gt; set num 6</span><br><span class="line">QUEUED</span><br><span class="line">127.0.0.1:6379&gt; exec</span><br><span class="line">1) OK</span><br><span class="line">2) (error) WRONGTYPE Operation against a key holding the wrong kind of value</span><br><span class="line">3) OK</span><br><span class="line">127.0.0.1:6379&gt; get key</span><br><span class="line">&quot;6&quot;</span><br></pre></td></tr></table></figure>
<p>这样就会导致，正确的命令被执行，而错误的命令不会不执行，这也显示出Redis的事务并不能保证数据的一致性，因为中间出现了错误，有些语句还是被执行了。</p>
<p>这样的结果只能程序员自己根据之前执行的命令，自己一步一步正确的回退，所谓自己的烂摊子，自己收拾。</p>
<h2 id="Redis事务与Mysql事务"><a href="#Redis事务与Mysql事务" class="headerlink" title="Redis事务与Mysql事务"></a>Redis事务与Mysql事务</h2><p>我们知道关系性数据库Mysql中具有事务的四大特性：<strong>原子性（Atomicity）、一致性（Consistency）、隔离性（Isolation）、持久性（Durability）</strong>。</p>
<p>但是Redis的事务为了保证Redis除了客户端的请求高效，去除了传统关系型数据库的<strong>事务回滚、加锁、解锁</strong>这些消耗性能的操作，Redis的事务实现简单。</p>
<p>原子性中Redis的事务只能保证单个命令的原子性，多个命令就无法保证，如上面索道的运行时错误，即使中间有运行时错误出现也会正确的执行后面正确的命令，不具有回滚操作。</p>
<p>既然没有了原子性，数据的一致性也就无法保证，这些都需要程序员自己手动去实现。</p>
<p>Reids在进行事务的时候，不会被中断知道事务的运行结束，也具有一定的隔离性，并且Redis也能持久化数据。</p>
<h1 id="集群"><a href="#集群" class="headerlink" title="集群"></a>集群</h1><h2 id="集群概述"><a href="#集群概述" class="headerlink" title="集群概述"></a>集群概述</h2><p>Redis作为缓存的高效中间件，在我们日常的开发中被频繁的使用，今天就来说一说Redis的四种模式，分别是<strong>单机版、主从复制、哨兵、以及集群模式</strong>。</p>
<p>可能，在一般公司的程序员使用单机版基本都能解决问题，在Redis的官网给出的数据是<code>10W QPS</code>，这对于应付一般的公司绰绰有余了，再不行就来个主从模式，实现都写分离，性能又大大提高。</p>
<p>但是，我们作为有抱负的程序员，仅限于单机版和主从模式的crud是不行的，至少也要了解<strong>哨兵</strong>和<strong>集群模式</strong>的原理，这样面试的时候才能和面试官扯皮啊。</p>
<h2 id="单机"><a href="#单机" class="headerlink" title="单机"></a>单机</h2><p>单机版的Redis就比较简单了，基本90%的程序员都是用过，官网推荐操作Redis的第三方依赖库是Jedis，在SpringBoot项目中，引入下面依赖就可以直接使用了：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">&lt;dependency&gt;</span><br><span class="line">	  &lt;groupId&gt;redis.clients&lt;&#x2F;groupId&gt;</span><br><span class="line">	  &lt;artifactId&gt;jedis&lt;&#x2F;artifactId&gt;</span><br><span class="line">	  &lt;version&gt;$&#123;jedis.version&#125;&lt;&#x2F;version&gt;</span><br><span class="line">&lt;&#x2F;dependency&gt;</span><br></pre></td></tr></table></figure>
<h3 id="优点"><a href="#优点" class="headerlink" title="优点"></a>优点</h3><p>单机版的Redis也有很多优点，比如实现实现简单、维护简单、部署简单、维护成本非常低，不需要其它额外的开支。</p>
<h3 id="缺点"><a href="#缺点" class="headerlink" title="缺点"></a>缺点</h3><p>但是，因为是单机版的Redis所以也存在很多的问题，比如最明显的单点故障问题，一个Redis挂了，所有的请求就会直接打在了DB上。</p>
<p>并且一个Redis抗并发数量也是有限的，同时要兼顾读写两种请求，只要访问量一上来，Redis就受不了了，另一方面单机版的Redis数据量存储也是有限的，数据量一大，再重启Redis的时候，就会非常的慢，所以局限性也是比较大的。</p>
<h3 id="实操搭建"><a href="#实操搭建" class="headerlink" title="实操搭建"></a>实操搭建</h3><p>单机版的搭建教程，在网上有非常多的全面的教程，基本就是傻瓜式操作，特别是在本地搭建的话，基本使用yum快捷方便，几句命令就搞定了，这里推荐一个搭建教程：<a target="_blank" rel="noopener" href="https://www.cnblogs.com/">https://www.cnblogs.com/</a><br>zuidongfeng/p/8032505.html。</p>
<p>上面这个教程讲的非常的详细，环境的搭建本来是运维的工作，但是作为程序员尝试自己去搭建环境还是有必要的，而且搭建环境这种东西，基本就是一劳永逸，搭建一次，可能下次换电脑或者重装虚拟机才会再次搭建。</p>
<p>这里也放出redis常用的<code>redis.conf</code>的配置项，并且附带注释，看我是不是很暖男：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br></pre></td><td class="code"><pre><span class="line">daemonize yes  &#x2F;&#x2F; 设置后台启动，一般设置yes</span><br><span class="line">pidfile &#x2F;var&#x2F;run&#x2F;redis.pid &#x2F;&#x2F; edis以守护进程方式运行时,redis默认会把pid写入&#x2F;var&#x2F;run&#x2F;redis.pid文件</span><br><span class="line">port 6379 &#x2F;&#x2F; 默认端口为6379</span><br><span class="line">bind 127.0.0.1 &#x2F;&#x2F;主机地址，设置未0.0.0.0表示都可以访问。127.0.0.1表示只允许本机访问</span><br><span class="line">timeout 900  &#x2F;&#x2F; 客户端闲置多长时间后关闭连接，如果指定为0，表示关闭该功能</span><br><span class="line">logfile stdout &#x2F;&#x2F; 日志记录方式，默认为标准输出</span><br><span class="line">logfile &quot;.&#x2F;redis7001.log&quot;  # 指明日志文件名</span><br><span class="line">databases 16 &#x2F;&#x2F; 设置数据库的数量，默认数据库为0</span><br><span class="line">save  &#x2F;&#x2F;有多少次更新操作，就将数据同步到数据文件</span><br><span class="line">	Redis默认配置文件中提供了三个条件：</span><br><span class="line">	save 900 1 &#x2F;&#x2F;900秒（15分钟）内有1个更改</span><br><span class="line">	save 300 10 &#x2F;&#x2F;300秒（5分钟）内有10个更改</span><br><span class="line">	save 60 10000  &#x2F;&#x2F; 60秒内有10000个更改</span><br><span class="line">rdbcompression yes &#x2F;&#x2F; 指定存储至本地数据库时是否压缩数据</span><br><span class="line">dbfilename dump.rdb &#x2F;&#x2F;指定本地数据库文件名</span><br><span class="line">dir .&#x2F;    &#x2F;&#x2F;指定本地数据库存放目录</span><br><span class="line">slaveof  &#x2F;&#x2F; 主从同步设置，设置主数据库的ip和端口</span><br><span class="line"># 如果非零，则设置SO_KEEPALIVE选项来向空闲连接的客户端发送ACK</span><br><span class="line">tcp-keepalive 60</span><br><span class="line"># 默认如果开启RDB快照(至少一条save指令)并且最新的后台保存失败，Redis将会停止接受写操作</span><br><span class="line"># 这将使用户知道数据没有正确的持久化到硬盘，否则可能没人注意到并且造成一些灾难</span><br><span class="line">stop-writes-on-bgsave-error yes</span><br><span class="line"># 默认如果开启RDB快照(至少一条save指令)并且最新的后台保存失败，Redis将会停止接受写操作。</span><br><span class="line">stop-writes-on-bgsave-error yes</span><br><span class="line"># 当导出到 .rdb 数据库时是否用LZF压缩字符串对象</span><br><span class="line">rdbcompression yes</span><br><span class="line"># 版本5的RDB有一个CRC64算法的校验和放在了文件的最后。这将使文件格式更加可靠。</span><br><span class="line">rdbchecksum yes</span><br><span class="line"># 持久化数据库的文件名</span><br><span class="line">dbfilename dump-master.rdb</span><br><span class="line"># 工作目录</span><br><span class="line">dir &#x2F;usr&#x2F;local&#x2F;redis-4.0.8&#x2F;redis_master&#x2F;</span><br><span class="line"># slav服务连接master的密码</span><br><span class="line">masterauth testmaster123</span><br><span class="line"># 当一个slave失去和master的连接，或者同步正在进行中，slave的行为可以有两种：</span><br><span class="line">#1) 如果 slave-serve-stale-data 设置为 &quot;yes&quot; (默认值)，slave会继续响应客户端请求，可能是正常数据，或者是过时了的数据，也可能是还没获得值的空数据。</span><br><span class="line"># 2) 如果 slave-serve-stale-data 设置为 &quot;no&quot;，slave会回复&quot;正在从master同步</span><br><span class="line"># （SYNC with master in progress）&quot;来处理各种请求，除了 INFO 和 SLAVEOF 命令。</span><br><span class="line">slave-serve-stale-data yes</span><br><span class="line"># 配置是否仅读</span><br><span class="line">slave-read-only yes</span><br><span class="line"># 如果你选择“yes”Redis将使用更少的TCP包和带宽来向slaves发送数据。但是这将使数据传输到slave上有延迟，Linux内核的默认配置会达到40毫秒</span><br><span class="line"># 如果你选择了 &quot;no&quot; 数据传输到salve的延迟将会减少但要使用更多的带宽</span><br><span class="line">repl-disable-tcp-nodelay no</span><br><span class="line"># slave的优先级，优先级数字小的salve会优先考虑提升为master</span><br><span class="line">slave-priority 100</span><br><span class="line"># 密码验证</span><br><span class="line">requirepass testmaster123</span><br><span class="line"># redis实例最大占用内存，一旦内存使用达到上限，Redis会根据选定的回收策略（参见：</span><br><span class="line"># maxmemmory-policy）删除key</span><br><span class="line">maxmemory 3gb</span><br><span class="line"># 最大内存策略：如果达到内存限制了，Redis如何选择删除key。</span><br><span class="line"># volatile-lru -&gt; 根据LRU算法删除带有过期时间的key。</span><br><span class="line"># allkeys-lru -&gt; 根据LRU算法删除任何key。</span><br><span class="line"># volatile-random -&gt; 根据过期设置来随机删除key, 具备过期时间的key。 </span><br><span class="line"># allkeys-&gt;random -&gt; 无差别随机删, 任何一个key。 </span><br><span class="line"># volatile-ttl -&gt; 根据最近过期时间来删除（辅以TTL）, 这是对于有过期时间的key </span><br><span class="line"># noeviction -&gt; 谁也不删，直接在写操作时返回错误。</span><br><span class="line">maxmemory-policy volatile-lru</span><br><span class="line"># AOF开启</span><br><span class="line">appendonly no</span><br><span class="line"># aof文件名</span><br><span class="line">appendfilename &quot;appendonly.aof&quot;</span><br><span class="line"># fsync() 系统调用告诉操作系统把数据写到磁盘上，而不是等更多的数据进入输出缓冲区。</span><br><span class="line"># 有些操作系统会真的把数据马上刷到磁盘上；有些则会尽快去尝试这么做。</span><br><span class="line"># Redis支持三种不同的模式：</span><br><span class="line"># no：不要立刻刷，只有在操作系统需要刷的时候再刷。比较快。</span><br><span class="line"># always：每次写操作都立刻写入到aof文件。慢，但是最安全。</span><br><span class="line"># everysec：每秒写一次。折中方案。 </span><br><span class="line">appendfsync everysec</span><br><span class="line"># 如果AOF的同步策略设置成 &quot;always&quot; 或者 &quot;everysec&quot;，并且后台的存储进程（后台存储或写入AOF</span><br><span class="line"># 日志）会产生很多磁盘I&#x2F;O开销。某些Linux的配置下会使Redis因为 fsync()系统调用而阻塞很久。</span><br><span class="line"># 注意，目前对这个情况还没有完美修正，甚至不同线程的 fsync() 会阻塞我们同步的write(2)调用。</span><br><span class="line"># 为了缓解这个问题，可以用下面这个选项。它可以在 BGSAVE 或 BGREWRITEAOF 处理时阻止主进程进行fsync()。</span><br><span class="line"># 这就意味着如果有子进程在进行保存操作，那么Redis就处于&quot;不可同步&quot;的状态。</span><br><span class="line"># 这实际上是说，在最差的情况下可能会丢掉30秒钟的日志数据。（默认Linux设定）</span><br><span class="line"># 如果你有延时问题把这个设置成&quot;yes&quot;，否则就保持&quot;no&quot;，这是保存持久数据的最安全的方式。</span><br><span class="line">no-appendfsync-on-rewrite yes</span><br><span class="line"># 自动重写AOF文件</span><br><span class="line">auto-aof-rewrite-percentage 100</span><br><span class="line">auto-aof-rewrite-min-size 64mb</span><br><span class="line"># AOF文件可能在尾部是不完整的（这跟system关闭有问题，尤其是mount ext4文件系统时</span><br><span class="line"># 没有加上data&#x3D;ordered选项。只会发生在os死时，redis自己死不会不完整）。</span><br><span class="line"># 那redis重启时load进内存的时候就有问题了。</span><br><span class="line"># 发生的时候，可以选择redis启动报错，并且通知用户和写日志，或者load尽量多正常的数据。</span><br><span class="line"># 如果aof-load-truncated是yes，会自动发布一个log给客户端然后load（默认）。</span><br><span class="line"># 如果是no，用户必须手动redis-check-aof修复AOF文件才可以。</span><br><span class="line"># 注意，如果在读取的过程中，发现这个aof是损坏的，服务器也是会退出的，</span><br><span class="line"># 这个选项仅仅用于当服务器尝试读取更多的数据但又找不到相应的数据时。</span><br><span class="line">aof-load-truncated yes</span><br><span class="line"># Lua 脚本的最大执行时间，毫秒为单位</span><br><span class="line">lua-time-limit 5000</span><br><span class="line"># Redis慢查询日志可以记录超过指定时间的查询</span><br><span class="line">slowlog-log-slower-than 10000</span><br><span class="line"># 这个长度没有限制。只是要主要会消耗内存。你可以通过 SLOWLOG RESET 来回收内存。</span><br><span class="line">slowlog-max-len 128</span><br><span class="line"># 客户端的输出缓冲区的限制，可用于强制断开那些因为某种原因从服务器读取数据的速度不够快的客户端</span><br><span class="line">client-output-buffer-limit normal 0 0 0</span><br><span class="line">client-output-buffer-limit slave 256mb 64mb 60</span><br><span class="line">client-output-buffer-limit pubsub 32mb 8mb 60</span><br><span class="line"># 当一个子进程重写AOF文件时，文件每生成32M数据会被同步</span><br><span class="line">aof-rewrite-incremental-fsync yes</span><br></pre></td></tr></table></figure>
<p>由于，单机版的Redis在并发量比较大的时候，并且需要较高性能和可靠性的时候，单机版基本就不适合了，于是就出现了<strong>主从模式</strong>。</p>
<h2 id="主从模式"><a href="#主从模式" class="headerlink" title="主从模式"></a>主从模式</h2><h3 id="原理"><a href="#原理" class="headerlink" title="原理"></a>原理</h3><p>主从的原理还算是比较简单的，一主多从，<strong>主数据库（master）可以读也可以写（read/write），从数据库仅读（only read）</strong>。</p>
<p>但是，主从模式一般实现<strong>读写分离</strong>，<strong>主数据库仅写（only write）</strong>，减轻主数据库的压力，下面一张图搞懂主从模式的原理：</p>
<p><img src="https://img-blog.csdnimg.cn/20200819225047906.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQzMjU1MDE3,size_16,color_FFFFFF,t_70#pic_center"></p>
<p>主从模式原理就是那么简单，那他执行的过程（工作机制）又是怎么样的呢？再来一张图：</p>
<p><img src="https://img-blog.csdnimg.cn/20200819225904123.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQzMjU1MDE3,size_16,color_FFFFFF,t_70#pic_center"><br>当开启主从模式的时候，他的具体工作机制如下：</p>
<ol>
<li>当slave启动后会向master发送<code>SYNC</code>命令，master节后到从数据库的命令后通过<code>bgsave</code>保存快照（<strong>RDB持久化</strong>），并且期间的执行的些命令会被缓存起来。</li>
<li>然后master会将保存的快照发送给slave，并且继续缓存期间的写命令。</li>
<li>slave收到主数据库发送过来的快照就会加载到自己的数据库中。</li>
<li>最后master讲缓存的命令同步给slave，slave收到命令后执行一遍，这样master与slave数据就保持一致了。</li>
</ol>
<h3 id="优点-1"><a href="#优点-1" class="headerlink" title="优点"></a>优点</h3><p>之所以运用主从，是因为主从一定程度上解决了单机版并发量大，导致请求延迟或者redis宕机服务停止的问题。</p>
<p>从数据库分担主数据库的读压力，若是主数据库是只写模式，那么实现读写分离，主数据库就没有了读压力了。</p>
<p>另一方面解决了单机版单点故障的问题，若是主数据库挂了，那么从数据库可以随时顶上来，综上来说，主从模式一定程度上提高了系统的可用性和性能，是实现哨兵和集群的基础。</p>
<p>主从同步以异步方式进行同步，期间Redis仍然可以响应客户端提交的查询和更新的请求。</p>
<h3 id="缺点-1"><a href="#缺点-1" class="headerlink" title="缺点"></a>缺点</h3><p>主从模式好是好，他也有自己的缺点，比如数据的一致性问题，假如主数据库写操作完成，那么他的数据会被复制到从数据库，若是还没有即使复制到从数据库，读请求又来了，此时读取的数据就不是最新的数据。</p>
<p>若是从主同步的过程网络出故障了，导致主从同步失败，也会出现问题数据一致性的问题。</p>
<p>主从模式不具备自动容错和恢复的功能，一旦主数据库，从节点晋升未主数据库的过程需要人为操作，维护的成本就会升高，并且主节点的写能力、存储能力都会受到限制。</p>
<h3 id="实操搭建-1"><a href="#实操搭建-1" class="headerlink" title="实操搭建"></a>实操搭建</h3><p>下面的我们来实操搭建一下主从模式，主从模式的搭建还是比较简单的，我这里一台centos 7虚拟机，使用开启redis多实例的方法搭建主从。</p>
<p>redis中开启多实例的方法，首先创建一个文件夹，用于存放redis集群的配置文件：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mkdir redis</span><br></pre></td></tr></table></figure>
<p>然后粘贴复制<code>redis.conf</code>配置文件：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">cp &#x2F;root&#x2F;redis-4.0.6&#x2F;redis.conf &#x2F;root&#x2F;redis&#x2F;redis-6379.conf</span><br><span class="line">cp &#x2F;root&#x2F;redis-4.0.6&#x2F;redis.conf &#x2F;root&#x2F;redis&#x2F;redis-6380.conf</span><br><span class="line">cp &#x2F;root&#x2F;redis-4.0.6&#x2F;redis.conf &#x2F;root&#x2F;redis&#x2F;redis-6381.conf</span><br></pre></td></tr></table></figure>
<p>复制三份配置文件，一主两从，6379端口作为主数据库（master），6380、6381作为从数据库（slave）。</p>
<p>首先是配置主数据库的配置文件：<code>vi redis-6379.conf</code>：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">bind 0.0.0.0 # 注释掉或配置成0.0.0.0表示任意IP均可访问。</span><br><span class="line">protected-mode no # 关闭保护模式，使用密码访问。</span><br><span class="line">port 6379  # 设置端口，6380、6381依次为6380、6381。</span><br><span class="line">timeout 30 # 客户端连接空闲多久后断开连接，单位秒，0表示禁用</span><br><span class="line">daemonize yes # 在后台运行</span><br><span class="line">pidfile &#x2F;var&#x2F;run&#x2F;redis_6379.pid  # pid进程文件名，6380、6381依次为redis_6380.pid、redis_6381.pid</span><br><span class="line">logfile &#x2F;root&#x2F;reids&#x2F;log&#x2F;6379.log # 日志文件，6380、6381依次为6380.log、6381.log</span><br><span class="line">save 900 1 # 900s内至少一次写操作则执行bgsave进行RDB持久化</span><br><span class="line">save 300 10</span><br><span class="line">save 60 10000 </span><br><span class="line">rdbcompression yes #是否对RDB文件进行压缩，建议设置为no，以（磁盘）空间换（CPU）时间</span><br><span class="line">dbfilename dump.rdb # RDB文件名称</span><br><span class="line">dir &#x2F;root&#x2F;redis&#x2F;datas # RDB文件保存路径，AOF文件也保存在这里</span><br><span class="line">appendonly yes # 表示使用AOF增量持久化的方式</span><br><span class="line">appendfsync everysec # 可选值 always， everysec，no，建议设置为everysec</span><br><span class="line">requirepass 123456 # 设置密码</span><br></pre></td></tr></table></figure>
<p>然后，就是修改从数据库的配置文件，在从数据库的配置文件中假如以下的配置信息：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">slaveof 127.0.0.1 6379 # 配置master的ip，port</span><br><span class="line">masterauth 123456 # 配置访问master的密码</span><br><span class="line">slaveof-serve-stale-data no </span><br></pre></td></tr></table></figure>
<p>接下来就是启动三个redis实例，启动的命令，先cd到redis的src目录下，然后执行：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">.&#x2F;redis-server &#x2F;root&#x2F;redis&#x2F;6379.conf</span><br><span class="line">.&#x2F;redis-server &#x2F;root&#x2F;redis&#x2F;6380.conf</span><br><span class="line">.&#x2F;redis-server &#x2F;root&#x2F;redis&#x2F;6381.conf</span><br></pre></td></tr></table></figure>
<p>通过命令<code>ps -aux | grep redis</code>，查看启动的redis进程：<br><img src="https://img-blog.csdnimg.cn/20200820204333336.png#pic_center"><br>如上图所示，表示启动成功，下面就开始进入测试阶段。</p>
<h3 id="测试"><a href="#测试" class="headerlink" title="测试"></a>测试</h3><p>我这里使用SecureCRT作为redis连接的客户端，同时启动三个SecureCRT，分别连接redis1的三个实例，启动时指定端口以及密码：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">.&#x2F;redis-cli -p 6379 -a 123456</span><br></pre></td></tr></table></figure>
<p><img src="https://img-blog.csdnimg.cn/20200820204731199.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQzMjU1MDE3,size_16,color_FFFFFF,t_70#pic_center"><br>启动后，在master（6379），输入：set name ‘ldc’，在slave中通过get name，可以查看：</p>
<p><img src="https://img-blog.csdnimg.cn/20200820205001147.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQzMjU1MDE3,size_16,color_FFFFFF,t_70#pic_center"><br>数据同步成功，这有几个坑一个是redis.conf中没有设置对bind，会导致非本机的ip被过滤掉，一般配置0.0.0.0就可以了。</p>
<p>另一个是没有配置密码requirepass 123456，会导致IO一直连接异常，这个是我遇到的坑，后面配置密码后就成功了。</p>
<p>还有，就是查看redis的启动日志可以发现有两个warning，虽然不影响搭建主从同步，看着挺烦人的，但是有些人会遇到，有些人不会遇到。</p>
<p>但是，我这个人比较有强迫症，百度也是有解决方案的，这里就不讲了，交给你们自己解决，这里只是告诉你有这个问题，有些人看都不看日志的，看到启动成功就认为万事大吉了，也不看日志，这习惯并不好。</p>
<p><img src="https://img-blog.csdnimg.cn/20200820205612260.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQzMjU1MDE3,size_16,color_FFFFFF,t_70#pic_center"></p>
<h2 id="哨兵模式"><a href="#哨兵模式" class="headerlink" title="哨兵模式"></a>哨兵模式</h2><h3 id="原理-1"><a href="#原理-1" class="headerlink" title="原理"></a>原理</h3><p>哨兵模式是主从的升级版，因为主从的出现故障后，不会自动恢复，需要人为干预，这就很蛋疼啊。</p>
<p>在主从的基础上，实现哨兵模式就是为了监控主从的运行状况，对主从的健壮进行监控，就好像哨兵一样，只要有异常就发出警告，对异常状况进行处理。</p>
<p><img src="https://img-blog.csdnimg.cn/20200820210040554.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQzMjU1MDE3,size_16,color_FFFFFF,t_70#pic_center"><br>所以，总的概括来说，哨兵模式有以下的优点（功能点）：</p>
<ol>
<li><strong>监控</strong>：监控master和slave是否正常运行，以及哨兵之间也会相互监控</li>
<li><strong>自动故障恢复</strong>：当master出现故障的时候，会自动选举一个slave作为master顶上去。</li>
</ol>
<p>哨兵模式的监控配置信息，是通过配置从数据库的<code>sentinel monitor &lt;master-name&gt; &lt;ip&gt; &lt;redis-port&gt; &lt;quorum&gt;</code> 来指定的，比如：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">&#x2F;&#x2F; mymaster 表示给master数据库定义了一个名字，后面的是master的ip和端口，1表示至少需要一个Sentinel进程同意才能将master判断为失效，如果不满足这个条件，则自动故障转移（failover）不会执行</span><br><span class="line">sentinel monitor mymaster 127.0.0.1 6379 1</span><br></pre></td></tr></table></figure>
<h3 id="节点通信"><a href="#节点通信" class="headerlink" title="节点通信"></a>节点通信</h3><p>当然还有其它的配置信息，其它配置信息，在环境搭建的时候再说。当哨兵启动后，会与master建立一条连接，用于订阅master的<code>_sentinel_:hello</code>频道。</p>
<p>该频道用于获取监控该master的其它哨兵的信息。并且还会建立一条定时向master发送INFO命令获取master信息的连接。</p>
<p><strong>当哨兵与master建立连接后，定期会向（10秒一次）master和slave发送INFO命令，若是master被标记为主观下线，频率就会变为1秒一次。</strong></p>
<p>并且，定期向<code>_sentinel_:hello</code>频道发送自己的信息，以便其它的哨兵能够订阅获取自己的信息，发送的内容包含<strong>哨兵的ip和端口、运行id、配置版本、master名字、master的ip端口还有master的配置版本</strong>等信息。</p>
<p>以及，<strong>定期的向master、slave和其它哨兵发送PING命令（每秒一次），以便检测对象是否存活</strong>，若是对方接收到了PING命令，无故障情况下，会回复PONG命令。</p>
<p>所以，哨兵通过建立这两条连接、通过定期发送INFO、PING命令来实现哨兵与哨兵、哨兵与master之间的通信。</p>
<p>这里涉及到一些概念需要理解，INFO、PING、PONG等命令，后面还会有MEET、FAIL命令，以及主观下线，当然还会有客观下线，这里主要说一下这几个概念的理解：</p>
<ol>
<li>INFO：该命令可以获取主从数据库的最新信息，可以实现新结点的发现</li>
<li>PING：该命令被使用最频繁，该命令封装了自身节点和其它节点的状态数据。</li>
<li>PONG：当节点收到MEET和PING，会回复PONG命令，也把自己的状态发送给对方。</li>
<li>MEET：该命令在新结点加入集群的时候，会向老节点发送该命令，表示自己是个新人</li>
<li>FAIL：当节点下线，会向集群中广播该消息。</li>
</ol>
<h3 id="上线和下线"><a href="#上线和下线" class="headerlink" title="上线和下线"></a>上线和下线</h3><p>当哨兵与master相同之后就会定期一直保持联系，若是某一时刻哨兵发送的PING在指定时间内没有收到回复（<code>sentinel down-after-milliseconds master-name milliseconds</code> 配置），那么发送PING命令的哨兵就会认为该master<strong>主观下线</strong>（<code>Subjectively Down</code>）。</p>
<p>因为有可能是哨兵与该master之间的网络问题造成的，而不是master本身的原因，所以哨兵同时会询问其它的哨兵是否也认为该master下线，若是认为该节点下线的哨兵达到一定的数量（<strong>前面的quorum字段配置</strong>），就会认为该节点<strong>客观下线</strong>（<code>Objectively  Down</code>）。</p>
<p>若是没有足够数量的sentinel同意该master下线，则该master客观下线的标识会被移除；若是master重新向哨兵的PING命令回复了客观下线的标识也会被移除。</p>
<h3 id="选举算法"><a href="#选举算法" class="headerlink" title="选举算法"></a>选举算法</h3><p>当master被认为客观下线后，又是怎么进行故障恢复的呢？原来哨兵中首先选举出一个老大哨兵来进行故障恢复，选举老大哨兵的算法叫做<strong>Raft算法</strong>：</p>
<ol>
<li>发现master下线的哨兵（sentinelA）会向其它的哨兵发送命令进行拉票，要求选择自己为哨兵大佬。</li>
<li>若是目标哨兵没有选择其它的哨兵，就会选择该哨兵（sentinelA）为大佬。</li>
<li>若是选择sentinelA的哨兵超过半数（半数原则），该大佬非sentinelA莫属。</li>
<li>如果有多个哨兵同时竞选，并且可能存在票数一致的情况，就会等待下次的一个随机时间再次发起竞选请求，进行新的一轮投票，直到大佬被选出来。</li>
</ol>
<p>选出大佬哨兵后，大佬哨兵就会对故障进行自动回复，从slave中选出一名slave作为主数据库，选举的规则如下所示：</p>
<ol>
<li>所有的slave中<code>slave-priority</code>优先级最高的会被选中。</li>
<li>若是优先级相同，会选择偏移量最大的，因为偏移量记录着数据的复制的增量，越大表示数据越完整。</li>
<li>若是以上两者都相同，选择ID最小的。</li>
</ol>
<p>通过以上的层层筛选最终实现故障恢复，当选的slave晋升为master，其它的slave会向新的master复制数据，若是down掉的master重新上线，会被当作slave角色运行。</p>
<h3 id="优点-2"><a href="#优点-2" class="headerlink" title="优点"></a>优点</h3><p>哨兵模式是主从模式的升级版，所以在系统层面提高了系统的可用性和性能、稳定性。当master宕机的时候，能够自动进行故障恢复，需不要人为的干预。</p>
<p>哨兵于哨兵之间、哨兵与master之间能够进行及时的监控，心跳检测，及时发现系统的问题，这都是弥补了主从的缺点。</p>
<h3 id="缺点-2"><a href="#缺点-2" class="headerlink" title="缺点"></a>缺点</h3><p>哨兵一主多从的模式同样也会遇到写的瓶颈，已经存储瓶颈，若是master宕机了，故障恢复的时间比较长，写的业务就会受到影响。</p>
<p>增加了哨兵也增加了系统的复杂度，需要同时维护哨兵模式。</p>
<h3 id="实操搭建-2"><a href="#实操搭建-2" class="headerlink" title="实操搭建"></a>实操搭建</h3><p>最后，我们进行一下哨兵模式的搭建，配置哨兵模式还是比较简单的，在上面配置的主从模式的基础上，同时创建一个文件夹用于存放三个哨兵的配置文件：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">mkdir &#x2F;root&#x2F;redis-4.0.6&#x2F;sentinel.conf  &#x2F;root&#x2F;redis&#x2F;sentinel&#x2F;sentinel1.conf </span><br><span class="line">mkdir &#x2F;root&#x2F;redis-4.0.6&#x2F;sentinel.conf  &#x2F;root&#x2F;redis&#x2F;sentinel&#x2F;sentinel2.conf </span><br><span class="line">mkdir &#x2F;root&#x2F;redis-4.0.6&#x2F;sentinel.conf  &#x2F;root&#x2F;redis&#x2F;sentinel&#x2F;sentinel3.conf </span><br></pre></td></tr></table></figure>
<p>分别在这三个文件中添加如下配置：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">daemonize yes # 在后台运行</span><br><span class="line">sentinel monitor mymaster 127.0.0.1 6379 1 # 给master起一个名字mymaster，并且配置master的ip和端口</span><br><span class="line">sentinel auth-pass mymaster 123456 # master的密码</span><br><span class="line">port 26379 #另外两个配置36379,46379端口</span><br><span class="line">sentinel down-after-milliseconds mymaster 3000 # 3s未回复PING就认为master主观下线</span><br><span class="line">sentinel parallel-syncs mymaster 2  # 执行故障转移时，最多可以有2个slave实例在同步新的master实例</span><br><span class="line">sentinel failover-timeout mymaster 100000 # 如果在10s内未能完成故障转移操作认为故障转移失败</span><br></pre></td></tr></table></figure>
<p>配置完后分别启动三台哨兵：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">.&#x2F;redis-server sentinel1.conf --sentinel</span><br><span class="line">.&#x2F;redis-server sentinel2.conf --sentinel</span><br><span class="line">.&#x2F;redis-server sentinel3.conf --sentinel</span><br></pre></td></tr></table></figure>
<p>然后通过：<code>ps -aux|grep redis</code>进行查看：<br><img src="https://img-blog.csdnimg.cn/2020082122573158.png#pic_center"><br>可以看到三台redis实例以及三个哨兵都已经正常启动，现登陆6379，通过INFO Repliaction查看master信息：</p>
<p><img src="https://img-blog.csdnimg.cn/20200821225948963.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQzMjU1MDE3,size_16,color_FFFFFF,t_70#pic_center"><br>当前master为6379，然后我们来测试一下哨兵的自动故障恢复，直接kill掉6379进程，然后通过登陆6380再次查看master的信息：</p>
<p><img src="https://img-blog.csdnimg.cn/20200821230311905.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQzMjU1MDE3,size_16,color_FFFFFF,t_70#pic_center"><br>可以看到当前的6380角色是master，并且6380可读可写，而不是只读模式，这说明我们的哨兵是起作用了，搭建成功，感兴趣的可以自行搭建，也有可能你会踩一堆的坑。</p>
<h2 id="Cluster模式"><a href="#Cluster模式" class="headerlink" title="Cluster模式"></a>Cluster模式</h2><p>最后，Cluster是真正的集群模式了，哨兵解决和主从不能自动故障恢复的问题，但是同时也存在难以扩容以及单机存储、读写能力受限的问题，并且集群之前都是一台redis都是全量的数据，这样所有的redis都冗余一份，就会大大消耗内存空间。</p>
<p>集群模式实现了Redis数据的分布式存储，实现数据的分片，每个redis节点存储不同的内容，并且解决了在线的节点收缩（下线）和扩容（上线）问题。</p>
<p>集群模式真正意义上实现了系统的高可用和高性能，但是集群同时进一步使系统变得越来越复杂，接下来我们来详细的了解集群的运作原理。</p>
<h3 id="数据分区原理"><a href="#数据分区原理" class="headerlink" title="数据分区原理"></a>数据分区原理</h3><p>集群的原理图还是很好理解的，在Redis集群中采用的使虚拟槽分区算法，会把redis集群分成16384 个槽（0 -16383）。</p>
<p>比如：下图所示三个master，会把0 -16383范围的槽可能分成三部分（0-5000）、（5001-11000）、（11001-16383）分别数据三个缓存节点的槽范围。</p>
<p><img src="https://img-blog.csdnimg.cn/20200821231740363.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQzMjU1MDE3,size_16,color_FFFFFF,t_70#pic_center"><br>当客户端请求过来，会首先通过对key进行CRC16 校验并对 16384 取模（CRC16(key)%16383）计算出key所在的槽，然后再到对应的槽上进行取数据或者存数据，这样就实现了数据的访问更新。</p>
<p><img src="https://img-blog.csdnimg.cn/2020082209480475.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQzMjU1MDE3,size_16,color_FFFFFF,t_70#pic_center"></p>
<p>之所以进行分槽存储，是将一整堆的数据进行分片，防止单台的redis数据量过大，影响性能的问题。</p>
<h3 id="节点通信-1"><a href="#节点通信-1" class="headerlink" title="节点通信"></a>节点通信</h3><p>节点之间实现了将数据进行分片存储，那么节点之间又是怎么通信的呢？这个和前面哨兵模式讲的命令基本一样。</p>
<p>首先新上线的节点，会通过 Gossip 协议向老成员发送Meet消息，表示自己是新加入的成员。</p>
<p>老成员收到Meet消息后，在没有故障的情况下会恢复PONG消息，表示欢迎新结点的加入，除了第一次发送Meet消息后，之后都会发送定期PING消息，实现节点之间的通信。</p>
<p><img src="https://img-blog.csdnimg.cn/20200822094911166.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQzMjU1MDE3,size_16,color_FFFFFF,t_70#pic_center"></p>
<p>通信的过程中会为每一个通信的节点开通一条tcp通道，之后就是定时任务，不断的向其它节点发送PING消息，这样做的目的就是为了了解节点之间的元数据存储情况，以及健康状况，以便即使发现问题。</p>
<h3 id="数据请求"><a href="#数据请求" class="headerlink" title="数据请求"></a>数据请求</h3><p>上面说到了槽信息，在Redis的底层维护了<code>unsigned char myslots[CLUSTER_SLOTS/8]</code> 一个数组存放每个节点的槽信息。</p>
<p>因为他是一个二进制数组，只有存储0和1值，如下图所示：</p>
<p><img src="https://img-blog.csdnimg.cn/20200822095444284.png#pic_center"></p>
<p>这样数组只表示自己是否存储对应的槽数据，若是1表示存在该数据，0表示不存在该数据，这样查询的效率就会非常的高，类似于布隆过滤器，二进制存储。    </p>
<p>比如：集群节点1负责存储0-5000的槽数据，但是此时只有0、1、2存储有数据，其它的槽还没有存数据，所以0、1、2对应的值为1。</p>
<p>并且，每个redis底层还维护了一个clusterNode数组，大小也是16384，用于储存负责对应槽的节点的ip、端口等信息，这样每一个节点就维护了其它节点的元数据信息，便于及时的找到对应的节点。</p>
<p>当新结点加入或者节点收缩，通过PING命令通信，及时的更新自己clusterNode数组中的元数据信息，这样有请求过来也就能及时的找到对应的节点。</p>
<p><img src="https://img-blog.csdnimg.cn/20200822100050154.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQzMjU1MDE3,size_16,color_FFFFFF,t_70#pic_center"><br>有两种其它的情况就是，若是请求过来发现，数据发生了迁移，比如新节点加入，会使旧的缓存节点数据迁移到新结点。</p>
<p>请求过来发现旧节点已经发生了数据迁移并且数据被迁移到新结点，由于每个节点都有clusterNode信息，通过该信息的ip和端口。此时旧节点就会向客户端发一个MOVED 的重定向请求，表示数据已经迁移到新结点上，你要访问这个新结点的ip和端口就能拿到数据，这样就能重新获取到数据。</p>
<p>倘若正在发正数据迁移呢？旧节点就会向客户端发送一个ASK 重定向请求，并返回给客户端迁移的目标节点的ip和端口，这样也能获取到数据。</p>
<h3 id="扩容和收缩"><a href="#扩容和收缩" class="headerlink" title="扩容和收缩"></a>扩容和收缩</h3><p>扩容和收缩也就是节点的上线和下线，可能节点发生故障了，故障自动回复的过程（节点收缩）。</p>
<p>节点的收缩和扩容时，会重新计算每一个节点负责的槽范围，并发根据虚拟槽算法，将对应的数据更新到对应的节点。</p>
<p>还有前面的讲的新加入的节点会首先发送Meet消息，详细可以查看前面讲的内容，基本一样的模式。</p>
<p>以及发生故障后，哨兵老大节点的选举，master节点的重新选举，slave怎样晋升为master节点，可以查看前面哨兵模式选举过程。</p>
<h3 id="优点-3"><a href="#优点-3" class="headerlink" title="优点"></a>优点</h3><p>集群模式时一个无中心的架构模式，将数据进行分片，分不到对应的槽中，每个节点存储不同的数据内容，通过路由能够找到对应的节点负责存储的槽，能够实现高效率的查询。</p>
<p>并且集群模式增加了横向和纵向的扩展能力，实现节点加入和收缩，集群模式时哨兵的升级版，哨兵的优点集群都有。</p>
<h3 id="缺点-3"><a href="#缺点-3" class="headerlink" title="缺点"></a>缺点</h3><p>缓存的最大问题就是带来数据一致性问题，在平衡数据一致性的问题时，兼顾性能与业务要求，大多数都是以最终一致性的方案进行解决，而不是强一致性。</p>
<p>并且集群模式带来节点数量的剧增，一个集群模式最少要6台机，因为要满足半数原则的选举方式，所以也带来了架构的复杂性。</p>
<p>slave只充当冷备，并不能缓解master的读的压力。</p>
<h3 id="实操搭建-3"><a href="#实操搭建-3" class="headerlink" title="实操搭建"></a>实操搭建</h3><p>集群模式的部署比较简单，只要在redis.conf加入下面的配置信息即可：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">port 6379# 本示例6个节点端口分别为6379、6380、6381、6382、6383、6384</span><br><span class="line">daemonize yes # r后台运行 </span><br><span class="line">pidfile &#x2F;var&#x2F;run&#x2F;redis_6379.pid # 分别对应6379、6380、6381、6382、6383、6384</span><br><span class="line">cluster-enabled yes # 开启集群模式 </span><br><span class="line">masterauth 123456# 如果设置了密码，需要指定master密码</span><br><span class="line">cluster-config-file nodes_6379.conf # 集群的配置文件，同样对应6379、6380、6381、6382、6383、6384六个节点</span><br><span class="line">cluster-node-timeout 10000 # 请求超时时间</span><br></pre></td></tr></table></figure>
<p>同时开启这六个实例，通过下面的命令将这六个实例以集群的方式运行</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">.&#x2F;redis-cli --cluster create --cluster-replicas 1 127.0.0.1:6379 127.0.0.1:6380 127.0.0.1:6381  127.0.0.1:6382  127.0.0.1:6383  127.0.0.1:6384  -a 123456</span><br></pre></td></tr></table></figure>
<p>这样就实现了集群的搭建，好了这一期就完成了，看了一下字数一共1.7W字，原创不易，看完点个在看和分享，不要白嫖我，传承中华民族的良好美德。</p>
<h1 id="应用"><a href="#应用" class="headerlink" title="应用"></a>应用</h1><h2 id="1-订阅与发布简介"><a href="#1-订阅与发布简介" class="headerlink" title="1.订阅与发布简介"></a>1.订阅与发布简介</h2><p>Redis发布与发布功能（<code>Pub/Sub</code>）是基于事件座位基本的通信机制，是目前应用比较普遍的通信模型，它的目的主要是<strong>解除消息的发布者与订阅者之间的耦合关系</strong>。</p>
<p>Redis作为消息发布和订阅之间的服务器，起到桥梁的作用，在Redis里面有一个<code>channel</code>的概念，也就是频道，发布者通过指定发布到某个频道，然后只要有订阅者订阅了该频道，该消息就会发送给订阅者，原理图如下所示：<br><img src="https://img-blog.csdnimg.cn/20200804214323283.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQzMjU1MDE3,size_16,color_FFFFFF,t_70"><br>Redis同时也可以使用list类型实现消息队列（消息队列的实现以及应用场景会在下一篇文章继续讲解）。</p>
<p>Redis的发布与订阅的功能应用还是比较广泛的，它的应用场景有很多。比如：最常见的就是实现实时聊天的功能，还是有就是博客的粉丝文章的推送，当博主推送原创文章的时候，就会将文章实时推送给博主的粉丝。</p>
<p>简介完Redis的发布于订阅功能，下面就要来实操一下，包括linux命令的实操和java代码的实现。</p>
<h2 id="命令实操"><a href="#命令实操" class="headerlink" title="命令实操"></a>命令实操</h2><p>这里就假设各位读者都已经安装好自己的虚拟机环境和Redis了，若是没有安装好的，可以参考这一篇博文：<a target="_blank" rel="noopener" href="https://www.cnblogs.com/">https://www.cnblogs.com/</a><br>zuidongfeng/p/8032505.html</p>
<p>我这里是已经安装好了Redis了，直接启动我们的Redis，我已经设置好了开机启动，上面的那篇博文有讲解怎么设置开机启动。</p>
<p><img src="https://img-blog.csdnimg.cn/20200804215725794.png"></p>
<h3 id="发布消息"><a href="#发布消息" class="headerlink" title="发布消息"></a>发布消息</h3><p>Redis中发布消息的命令是publish，具体使用如下所示：</p>
<p><img src="https://img-blog.csdnimg.cn/20200804215924682.png"><br>PUBLISH test “haha”：<code>test</code>表示频道的名称，<code>haha</code>表示发布的内容，这样就完成了一个一个消息的发布，后面的返回<code>（integer）0</code>表示0人订阅。</p>
<h3 id="订阅频道"><a href="#订阅频道" class="headerlink" title="订阅频道"></a>订阅频道</h3><p>于此同时再启动一个窗口，这个窗口作为订阅者，订阅者的命令<code>subscribe</code>，使用SUBSCRIBE test就表示订阅了test这个频道<br><img src="https://img-blog.csdnimg.cn/20200804220959106.png"><br>订阅后返回的结果中由三条信息，<strong>第一个表示类型、第二个表示订阅的频道，第三个表示订阅的数量</strong>。接着在第一个窗口进行发布消息：</p>
<p><img src="https://img-blog.csdnimg.cn/20200804221522352.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQzMjU1MDE3,size_16,color_FFFFFF,t_70"><br>可以看到发布者发布的消息，订阅者都会实时的接收到，并发订阅者收到的信息中也会出现三条信息，分别表示：<strong>返回值的类型、频道名称、消息内容</strong>。</p>
<h3 id="取消订阅"><a href="#取消订阅" class="headerlink" title="取消订阅"></a>取消订阅</h3><p>若是想取消之前的订阅可以使用unsubscribe命令，格式为：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">unsubscribe  频道名称</span><br><span class="line">&#x2F;&#x2F; 取消之前订阅的test频道</span><br><span class="line">unsubscribe  test</span><br></pre></td></tr></table></figure>
<p>输入命令后，返回以下结果：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">[root@pinyoyougou-docker src]# .&#x2F;redis-cli </span><br><span class="line">127.0.0.1:6379&gt; UNSUBSCRIBE test</span><br><span class="line">1) &quot;unsubscribe&quot;</span><br><span class="line">2) &quot;test&quot;</span><br><span class="line">3) (integer) 0</span><br></pre></td></tr></table></figure>
<p>它分别表示：<strong>返回值的类型、频道的名称、该频道订阅的数量</strong>。</p>
<h3 id="按模式订阅"><a href="#按模式订阅" class="headerlink" title="按模式订阅"></a>按模式订阅</h3><p>除了直接以特定的名城进行订阅，还可以按照模式进行订阅，模式的方式进行订阅可以一次订阅多个频道，按照模式进行订阅的命令为<code>psubscribe</code>，具体格式如下：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">psubscribe  模式</span><br><span class="line">&#x2F;&#x2F; 表示订阅名称以ldc开头的频道</span><br><span class="line">psubscribe  ldc*</span><br></pre></td></tr></table></figure>
<p>输入上面的命令后，返回如下结果：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">127.0.0.1:6379&gt; PSUBSCRIBE ldc*</span><br><span class="line">Reading messages... (press Ctrl-C to quit)</span><br><span class="line">1) &quot;psubscribe&quot;</span><br><span class="line">2) &quot;ldc*&quot;</span><br><span class="line">3) (integer) 1</span><br></pre></td></tr></table></figure>
<p>这个也是非常简单，分别表示：<strong>返回的类型（表示按模式订阅类型）、订阅的模式、订阅数</strong>。</p>
<h3 id="取消按模式订阅"><a href="#取消按模式订阅" class="headerlink" title="取消按模式订阅"></a>取消按模式订阅</h3><p>假如你想取消之前的按模式订阅，可以使用<code>punsubscribe</code>来取消，具体格式：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">punsubscribe 模式</span><br><span class="line">&#x2F;&#x2F; 取消频道名称按照ldc开头的频道</span><br><span class="line">punsubscribe ldc*</span><br></pre></td></tr></table></figure>
<p>他的返回值，如下所示：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">127.0.0.1:6379&gt; PUNSUBSCRIBE ldc*</span><br><span class="line">1) &quot;punsubscribe&quot;</span><br><span class="line">2) &quot;ldc*&quot;</span><br><span class="line">3) (integer) 0</span><br></pre></td></tr></table></figure>
<p>这个就不多说了，表示的意思和上面的一样，可以看到上面的命令都是有规律的订阅SUBSCRIBE，取消就是UNSUBSCRIBE，前面加前缀UN，按模式订阅也是。</p>
<h3 id="查看订阅消息"><a href="#查看订阅消息" class="headerlink" title="查看订阅消息"></a>查看订阅消息</h3><p>（1）你想查看某一个模式下订阅数是大于零的频道，可以使用如下格式的命令进行操作：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">pubsub channels 模式</span><br><span class="line">&#x2F;&#x2F; 查看频道名称以ldc模式开头的订阅数大于零的频道</span><br><span class="line">pubsub channels ldc*</span><br></pre></td></tr></table></figure>
<p>（2）假如你想查看某一个频道的订阅数，可以使用如下命令：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pubsub numsub 频道名称</span><br></pre></td></tr></table></figure>
<p>（3）查看按照模式的订阅数，可以使用如下命令进行操作：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pubsub numpat</span><br></pre></td></tr></table></figure>
<p>到这里以上的命令操作就基本结束了，下面就来代码实战。</p>
<h2 id="代码实练"><a href="#代码实练" class="headerlink" title="代码实练"></a>代码实练</h2><p>（1）首先第一步想要操作Redis，再SpringBoot项目中引入jedis的依赖，毕竟jedis是官方推荐使用操作Redis的工具。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">&lt;dependency&gt;</span><br><span class="line">    &lt;groupId&gt;redis.clients&lt;&#x2F;groupId&gt;</span><br><span class="line">    &lt;artifactId&gt;jedis&lt;&#x2F;artifactId&gt;</span><br><span class="line">    &lt;version&gt;2.9.0&lt;&#x2F;version&gt;</span><br><span class="line">&lt;&#x2F;dependency&gt;</span><br></pre></td></tr></table></figure>
<p>（2）然后创建发布者<code>Publisher</code>，用于消息的发布，具体代码如下：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br></pre></td><td class="code"><pre><span class="line">package com.ldc.org.myproject.demo.redis;</span><br><span class="line"></span><br><span class="line">import java.io.BufferedReader;</span><br><span class="line">import java.io.IOException;</span><br><span class="line">import java.io.InputStreamReader;</span><br><span class="line">import redis.clients.jedis.Jedis;</span><br><span class="line">import redis.clients.jedis.JedisPool;</span><br><span class="line"></span><br><span class="line">&#x2F;**</span><br><span class="line"> * 发布者</span><br><span class="line"> * @author liduchang</span><br><span class="line"> *</span><br><span class="line"> *&#x2F;</span><br><span class="line">public class Publisher extends Thread&#123;</span><br><span class="line">	&#x2F;&#x2F; 连接池	</span><br><span class="line">	private final JedisPool jedisPool;</span><br><span class="line">	&#x2F;&#x2F; 发布频道名称</span><br><span class="line">	private String name;</span><br><span class="line">	</span><br><span class="line">	public Publisher(JedisPool jedisPool, String name) &#123;</span><br><span class="line">		super();</span><br><span class="line">		this.jedisPool &#x3D; jedisPool;</span><br><span class="line">		this.name &#x3D; name;</span><br><span class="line">	&#125;</span><br><span class="line">	</span><br><span class="line">	@Override</span><br><span class="line">	public void run() &#123;</span><br><span class="line">		&#x2F;&#x2F; 获取要发布的消息</span><br><span class="line">		BufferedReader reader &#x3D; new BufferedReader(new InputStreamReader(System.in));</span><br><span class="line">		&#x2F;&#x2F; 获取连接</span><br><span class="line">		Jedis resource &#x3D; jedisPool.getResource();</span><br><span class="line">		while (true) &#123;</span><br><span class="line">			String message &#x3D; null;</span><br><span class="line">			try &#123;</span><br><span class="line">				message &#x3D; reader.readLine();</span><br><span class="line">				if (!&quot;exit&quot;.equals(message)) &#123;</span><br><span class="line">					&#x2F;&#x2F; 发布消息</span><br><span class="line">					resource.publish(name, &quot;发布者:&quot;+Thread.currentThread().getName()+&quot;发布消息：&quot;+message);</span><br><span class="line">				&#125; else &#123;</span><br><span class="line">					break;</span><br><span class="line">				&#125;</span><br><span class="line">			&#125; catch (IOException e) &#123;</span><br><span class="line">				e.printStackTrace();</span><br><span class="line">			&#125;</span><br><span class="line">		&#125;</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>（3）接着创建订阅类<code>Subscriber</code>，并且继承<code>JedisPubSub</code> 类，重写<code>onMessage、onSubscribe、onUnsubscribe</code>三个方法，这三个方法的调用时机在注释上都有说明，具体的实现代码如下：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br></pre></td><td class="code"><pre><span class="line">package com.ldc.org.myproject.demo.redis;</span><br><span class="line"></span><br><span class="line">import com.fasterxml.jackson.core.sym.Name;</span><br><span class="line">import redis.clients.jedis.JedisPubSub;</span><br><span class="line"></span><br><span class="line">&#x2F;**</span><br><span class="line"> * 订阅者</span><br><span class="line"> * @author liduchang</span><br><span class="line"> *&#x2F;</span><br><span class="line">public class Subscriber extends JedisPubSub &#123;</span><br><span class="line">	&#x2F;&#x2F;订阅频道名称</span><br><span class="line">	private String name;</span><br><span class="line">	</span><br><span class="line">	public Subscriber(String name) &#123;</span><br><span class="line">		this.name &#x3D; name;</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	&#x2F;**</span><br><span class="line">	 * 订阅者收到消息时会调用</span><br><span class="line">	 *&#x2F;</span><br><span class="line">	@Override</span><br><span class="line">	public void onMessage(String channel, String message) &#123;</span><br><span class="line">		&#x2F;&#x2F; TODO Auto-generated method stub</span><br><span class="line">		super.onMessage(channel, message);</span><br><span class="line">		System.out.println(&quot;频道：&quot;+channel+&quot;  接受的消息为：&quot;+message);</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	&#x2F;**</span><br><span class="line">	 * 订阅了频道会被调用</span><br><span class="line">	 *&#x2F;</span><br><span class="line">	@Override</span><br><span class="line">	public void onSubscribe(String channel, int subscribedChannels) &#123;</span><br><span class="line">		System.out.println(&quot;订阅了频道:&quot;+channel+&quot;  订阅数为：&quot;+subscribedChannels);</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	&#x2F;**</span><br><span class="line">	 * 取消订阅频道会被调用</span><br><span class="line">	 *&#x2F;</span><br><span class="line">	@Override</span><br><span class="line">	public void onUnsubscribe(String channel, int subscribedChannels) &#123;</span><br><span class="line">		System.out.println(&quot;取消订阅的频道：&quot;+channel+&quot;  订阅的频道数量为：&quot;+subscribedChannels);</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>（4）这次创建的才是真正的订阅者<code>SubThread</code>，上面的Subscriber是指为了测试实订阅的时候或者发布消息，能够有信息输出：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br></pre></td><td class="code"><pre><span class="line">package com.ldc.org.myproject.demo.redis;</span><br><span class="line"></span><br><span class="line">import redis.clients.jedis.Jedis;</span><br><span class="line">import redis.clients.jedis.JedisPool;</span><br><span class="line"></span><br><span class="line">&#x2F;**</span><br><span class="line"> * 订阅者线程</span><br><span class="line"> * @author liduchang</span><br><span class="line"> *</span><br><span class="line"> *&#x2F;</span><br><span class="line">public class SubThread extends Thread &#123;</span><br><span class="line">	</span><br><span class="line">	private final JedisPool jedisPool;</span><br><span class="line">	</span><br><span class="line">	private final Subscriber subscriber;</span><br><span class="line">	</span><br><span class="line">	private String name;</span><br><span class="line">	</span><br><span class="line">	public SubThread(JedisPool jedisPool,Subscriber subscriber,String name) &#123;</span><br><span class="line">		super();</span><br><span class="line">		this.jedisPool &#x3D; jedisPool;</span><br><span class="line">		this.subscriber &#x3D; subscriber;</span><br><span class="line">		this.name &#x3D; name;</span><br><span class="line">	&#125;</span><br><span class="line">	</span><br><span class="line">	@Override</span><br><span class="line">	public void run() &#123;</span><br><span class="line">		Jedis jedis &#x3D; null;</span><br><span class="line">		try &#123;</span><br><span class="line">			jedis &#x3D; jedisPool.getResource();</span><br><span class="line">			&#x2F;&#x2F; 订阅频道为name</span><br><span class="line">			jedis.subscribe(subscriber, name);</span><br><span class="line">		&#125; catch (Exception e) &#123;</span><br><span class="line">			System.err.println(&quot;订阅失败&quot;);</span><br><span class="line">		    e.printStackTrace();</span><br><span class="line">		&#125; finally &#123;</span><br><span class="line">			if (jedis!&#x3D;null) &#123;</span><br><span class="line">				 &#x2F;&#x2F; jedis.close();</span><br><span class="line">				 &#x2F;&#x2F;归还连接到redis池中</span><br><span class="line">				jedisPool.returnResource(jedis);</span><br><span class="line">			&#125;</span><br><span class="line">		&#125;</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>（5）后面就是测试了，分别测试发布与订阅的测试，发布者为<code>TestPublisher</code>，订阅者为<code>TestSubscriber</code>：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">package com.ldc.org.myproject.demo.redis;</span><br><span class="line"></span><br><span class="line">import java.util.concurrent.ExecutorService;</span><br><span class="line">import java.util.concurrent.Executors;</span><br><span class="line">import java.util.concurrent.TimeUnit;</span><br><span class="line">import redis.clients.jedis.JedisPool;</span><br><span class="line"></span><br><span class="line">public class TestPublisher &#123;</span><br><span class="line">	</span><br><span class="line">	public static void main(String[] args) throws InterruptedException &#123;</span><br><span class="line">		JedisPool jedisPool &#x3D; new JedisPool(&quot;192.168.163.155&quot;);</span><br><span class="line">		&#x2F;&#x2F; 向ldc频道发布消息</span><br><span class="line">		Publisher publisher &#x3D; new Publisher(jedisPool, &quot;ldc&quot;);</span><br><span class="line">		publisher.start();</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>订阅者</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">package com.ldc.org.myproject.demo.redis;</span><br><span class="line"></span><br><span class="line">import java.util.concurrent.ExecutorService;</span><br><span class="line">import java.util.concurrent.Executors;</span><br><span class="line">import java.util.concurrent.TimeUnit;</span><br><span class="line"></span><br><span class="line">import redis.clients.jedis.JedisPool;</span><br><span class="line"></span><br><span class="line">public class TestSubscriber1 &#123;</span><br><span class="line">	</span><br><span class="line">	public static void main(String[] args) throws InterruptedException &#123;</span><br><span class="line">		JedisPool jedisPool &#x3D; new JedisPool(&quot;192.168.163.155&quot;,6379);</span><br><span class="line">		Subscriber subscriber &#x3D; new Subscriber(&quot;黎杜&quot;);</span><br><span class="line">		&#x2F;&#x2F; 订阅ldc频道</span><br><span class="line">		SubThread thread&#x3D; new SubThread(jedisPool, subscriber, &quot;ldc&quot;);</span><br><span class="line">		thread.start();</span><br><span class="line">		Thread.sleep(600000);</span><br><span class="line">		&#x2F;&#x2F; 取消订阅</span><br><span class="line">		subscriber.unsubscribe(&quot;ldc&quot;);</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>这里为了测试方便就直接创建线程的方式，更好的话可以使用线程池的方式通过线程池的<code>submit</code>方法来执行线程，若是不用了可以使用<code>shutdown</code>方式关闭。</p>
<p>好了这一期的Redis的实现订阅与发布的讲解就说完了，我们下一期在讲解Redis的集群的知识，下期再见。</p>
<h2 id="2-Redis实现的分布式锁"><a href="#2-Redis实现的分布式锁" class="headerlink" title="2.Redis实现的分布式锁"></a>2.Redis实现的分布式锁</h2><p>之前讲了一片Redis事务的文章，很多读者Redis事务有啥用，主要是因为Redis的事务并没有Mysql的事务那么强大，所以一般的公司一般确实是用不到。</p>
<p>这里就来说一说Redis事务的一个实际用途，它可以用来实现一个简单的秒杀系统的库存扣减，下面我们就来进行代码的实现。</p>
<p>（1）首先使用线程池初始化5000个客户端。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">public static void intitClients() &#123;</span><br><span class="line">	ExecutorService threadPool&#x3D; Executors.newCachedThreadPool();</span><br><span class="line">	for (int i &#x3D; 0; i &lt; 5000; i++) &#123;</span><br><span class="line">		threadPool.execute(new Client(i));</span><br><span class="line">	&#125;</span><br><span class="line">	threadPool.shutdown();</span><br><span class="line">	</span><br><span class="line">	while(true)&#123; </span><br><span class="line">         if(threadPool.isTerminated())&#123;  </span><br><span class="line">             break;  </span><br><span class="line">         &#125;  </span><br><span class="line">     &#125;  </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>（2）接着初始化商品的库存数为1000。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">public static void initPrductNum() &#123;</span><br><span class="line">		Jedis jedis &#x3D; RedisUtil.getInstance().getJedis();</span><br><span class="line">		jedisUtils.set(&quot;produce&quot;, &quot;1000&quot;);&#x2F;&#x2F; 初始化商品库存数</span><br><span class="line">		RedisUtil.returnResource(jedis);&#x2F;&#x2F; 返还数据库连接</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>（3）最后是库存扣减的每条线程的处理逻辑。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br></pre></td><td class="code"><pre><span class="line">&#x2F;**</span><br><span class="line"> * 顾客线程</span><br><span class="line"> * </span><br><span class="line"> * @author linbingwen</span><br><span class="line"> *</span><br><span class="line"> *&#x2F;</span><br><span class="line">class client implements Runnable &#123;</span><br><span class="line">	Jedis jedis &#x3D; null;</span><br><span class="line">	String key &#x3D; &quot;produce&quot;; &#x2F;&#x2F; 商品数量的主键</span><br><span class="line">	String name;</span><br><span class="line"> </span><br><span class="line">	public ClientThread(int num) &#123;</span><br><span class="line">		name&#x3D; &quot;编号&#x3D;&quot; + num;</span><br><span class="line">	&#125;</span><br><span class="line"> </span><br><span class="line">	public void run() &#123;</span><br><span class="line">	</span><br><span class="line">		while (true) &#123;</span><br><span class="line">			jedis &#x3D; RedisUtil.getInstance().getJedis();</span><br><span class="line">			try &#123;</span><br><span class="line">				jedis.watch(key);</span><br><span class="line">				int num&#x3D; Integer.parseInt(jedis.get(key));&#x2F;&#x2F; 当前商品个数</span><br><span class="line">				if (num&gt; 0) &#123;</span><br><span class="line">					Transaction ts&#x3D; jedis.multi(); &#x2F;&#x2F; 开始事务</span><br><span class="line">					ts.set(key, String.valueOf(num - 1)); &#x2F;&#x2F; 库存扣减</span><br><span class="line">					List&lt;Object&gt; result &#x3D; ts.exec(); &#x2F;&#x2F; 执行事务</span><br><span class="line">					if (result &#x3D;&#x3D; null || result.isEmpty()) &#123;</span><br><span class="line">						System.out.println(&quot;抱歉，您抢购失败，请再次重试&quot;);</span><br><span class="line">					&#125; else &#123;</span><br><span class="line">						System.out.println(&quot;恭喜您，抢购成功&quot;);</span><br><span class="line">						break;</span><br><span class="line">					&#125;</span><br><span class="line">				&#125; else &#123;</span><br><span class="line">					System.out.println(&quot;抱歉，商品已经卖完&quot;);</span><br><span class="line">					break;</span><br><span class="line">				&#125;</span><br><span class="line">			&#125; catch (Exception e) &#123;</span><br><span class="line">				e.printStackTrace();</span><br><span class="line">			&#125; finally &#123;</span><br><span class="line">				jedis.unwatch(); &#x2F;&#x2F; 解除被监视的key</span><br><span class="line">				RedisUtil.returnResource(jedis);</span><br><span class="line">			&#125;</span><br><span class="line">		&#125;</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>在代码的实现中有一个重要的点就是<strong>商品的数据量被watch了</strong>，当前的客户端只要发现数量被改变就会抢购失败，然后不断的自旋进行抢购。</p>
<p>这个是基于Redis事务实现的简单的秒杀系统，Redis事务中的<code>watch</code>命令有点类似乐观锁的机制，只要发现商品数量被修改，就执行失败。</p>
<p>Redis实现分布式锁的第二种方式，可以使用<code>setnx、getset、expire、del</code>这四个命令来实现。</p>
<ol>
<li><code>setnx</code>：命令表示如果key不存在，就会执行set命令，若是key已经存在，不会执行任何操作。</li>
<li><code>getset</code>：将key设置为给定的value值，并返回原来的旧value值，若是key不存在就会返回返回nil 。</li>
<li><code>expire</code>：设置key生存时间，当当前时间超出了给定的时间，就会自动删除key。</li>
<li><code>del</code>：删除key，它可以删除多个key，语法如下：<code>DEL key [key …]</code>，若是key不存在直接忽略。</li>
</ol>
<p>下面通过一个代码案例是实现以下这个命令的操作方式：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">public void redis(Produce produce) &#123;</span><br><span class="line">        long timeout&#x3D; 10000L; &#x2F;&#x2F; 超时时间</span><br><span class="line">        Long result&#x3D; RedisUtil.setnx(produce.getId(), String.valueOf(System.currentTimeMillis() + timeout));</span><br><span class="line">        if (result!&#x3D; null &amp;&amp; result.intValue() &#x3D;&#x3D; 1) &#123; &#x2F;&#x2F; 返回1表示成功获取到锁</span><br><span class="line">	        RedisUtil.expire(produce.getId(), 10);&#x2F;&#x2F;有效期为5秒，防止死锁</span><br><span class="line">	        &#x2F;&#x2F;执行业务操作</span><br><span class="line">	        ......</span><br><span class="line">	        &#x2F;&#x2F;执行完业务后，释放锁</span><br><span class="line">	        RedisUtil.del(produce.getId());</span><br><span class="line">        &#125; else &#123;</span><br><span class="line">           System.println.out(&quot;没有获取到锁&quot;)</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure>
<p>在线程A通过<code>setnx</code>方法尝试去获取到produce对象的锁，若是获取成功旧会返回1，获取不成功，说明当前对象的锁已经被其它线程锁持有。</p>
<p>获取锁成功后并设置key的生存时间，能够有效的防止出现死锁，最后就是通过<code>del</code>来实现删除key，这样其它的线程就也可以获取到这个对象的锁。</p>
<p>执行的逻辑很简单，但是简单的同时也会出现问题，比如你在执行完setnx成功后设置生存时间不生效，此时服务器宕机，那么key就会一直存在Redis中。</p>
<p>当然解决的办法，你可以在服务器<code>destroy</code>函数里面再次执行：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">RedisUtil.del(produce.getId());</span><br></pre></td></tr></table></figure>
<p>或者通过<strong>定时任务检查是否有设置生存时间</strong>，没有的话都会统一进行设置生存时间。</p>
<p>还有比较好的解决方案就是，在上面的执行逻辑里面，若是没有获取到锁再次进行key的生存时间：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line">public void redis(Produce produce) &#123;</span><br><span class="line">        long timeout&#x3D; 10000L; &#x2F;&#x2F; 超时时间</span><br><span class="line">        Long result&#x3D; RedisUtil.setnx(produce.getId(), String.valueOf(System.currentTimeMillis() + timeout));</span><br><span class="line">        if (result!&#x3D; null &amp;&amp; result.intValue() &#x3D;&#x3D; 1) &#123; &#x2F;&#x2F; 返回1表示成功获取到锁</span><br><span class="line">	        RedisUtil.expire(produce.getId(), 10);&#x2F;&#x2F;有效期为10秒，防止死锁</span><br><span class="line">	        &#x2F;&#x2F;执行业务操作</span><br><span class="line">	        ......</span><br><span class="line">	        &#x2F;&#x2F;执行完业务后，释放锁</span><br><span class="line">	        RedisUtil.del(produce.getId());</span><br><span class="line">        &#125; else &#123;</span><br><span class="line">            String value&#x3D; RedisUtil.get(produce.getId());</span><br><span class="line">            &#x2F;&#x2F; 存在该key，并且已经超时</span><br><span class="line">            if (value!&#x3D; null &amp;&amp; System.currentTimeMillis() &gt; Long.parseLong(value)) &#123;</span><br><span class="line">                String result &#x3D; RedisUtil.getSet(produce.getId(), String.valueOf(System.currentTimeMillis() + timeout)); </span><br><span class="line">                if (result &#x3D;&#x3D; null || (result !&#x3D; null &amp;&amp; StringUtils.equals(value, result))) &#123;</span><br><span class="line">                     RedisUtil.expire(produce.getId(), 10);&#x2F;&#x2F;有效期为10秒，防止死锁</span><br><span class="line">			        &#x2F;&#x2F;执行业务操作</span><br><span class="line">			        ......</span><br><span class="line">			        &#x2F;&#x2F;执行完业务后，释放锁</span><br><span class="line">			        RedisUtil.del(produce.getId());</span><br><span class="line">                &#125; else &#123;</span><br><span class="line">                    System.println(&quot;没有获取到锁&quot;)</span><br><span class="line">                &#125;</span><br><span class="line">            &#125; else &#123;</span><br><span class="line">                System.println(&quot;没有获取到锁&quot;)</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure>
<p>这里对上面的代码进行了改进，在获取setnx失败的时候，再次重新判断该key的锁时间是否失效或者不存在，并重新设置生存的时间，避免出现死锁的情况。</p>
<p>第三种Redis实现分布式锁，可以使用<code>Redisson</code>来实现，它的实现简单，已经帮我们封装好了，屏蔽了底层复杂的实现逻辑。</p>
<p>先来一个Redisson的原理图，后面回对这个原理图进行详细的介绍：<br><img src="https://img-blog.csdnimg.cn/20200712164801569.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQzMjU1MDE3,size_16,color_FFFFFF,t_70" alt="图片来源于网络"></p>
<p>我们在实际的项目中要使用它，只需要引入它的依赖，然后执行下面的代码：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">RLock lock &#x3D; redisson.getLock(&quot;lockName&quot;);</span><br><span class="line">lock.locl();</span><br><span class="line">lock.unlock();</span><br></pre></td></tr></table></figure>
<p>并且它还支持<strong>Redis单实例、Redis哨兵、redis cluster、redis master-slave</strong>等各种部署架构，都给你完美的实现，不用自己再次拧螺丝。</p>
<p>但是，crud的同时还是要学习一下它的底层的实现原理，下面我们来了解下一下，对于一个分布式的锁的框架主要的学习分为下面的5个点：</p>
<ol>
<li>加锁机制</li>
<li>解锁机制</li>
<li>生存时间延长机制</li>
<li>可重入加锁机制</li>
<li>锁释放机制</li>
</ol>
<p>只要掌握一个框架的这五个大点，基本这个框架的核心思想就已经掌握了，若是要你去实现一个锁机制框架，就会有大体的一个思路。</p>
<p><code>Redisson</code>中的加锁机制是通过lua脚本进行实现，<code>Redisson</code>首先会通过<strong>hash算法</strong>，选择<code>redis cluster</code>集群中的一个节点，接着会把一个lua脚本发送到Redis中。</p>
<p>它底层实现的lua脚本如下：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">returncommandExecutor.evalWriteAsync(getName(), LongCodec.INSTANCE, command,</span><br><span class="line">	&quot;if (redis.call(&#39;exists&#39;, KEYS[1]) &#x3D;&#x3D; 0) then &quot; +</span><br><span class="line">	      &quot;redis.call(&#39;hset&#39;, KEYS[1], ARGV[2], 1); &quot; +</span><br><span class="line">	      &quot;redis.call(&#39;pexpire&#39;, KEYS[1], ARGV[1]); &quot; +</span><br><span class="line">	      &quot;return nil; &quot; +</span><br><span class="line">	  &quot;end; &quot; +</span><br><span class="line">	  &quot;if (redis.call(&#39;hexists&#39;, KEYS[1], ARGV[2]) &#x3D;&#x3D; 1) then &quot; +</span><br><span class="line">	      &quot;redis.call(&#39;hincrby&#39;, KEYS[1], ARGV[2], 1); &quot; +</span><br><span class="line">	      &quot;redis.call(&#39;pexpire&#39;, KEYS[1], ARGV[1]); &quot; +</span><br><span class="line">	      &quot;return nil; &quot; +</span><br><span class="line">	  &quot;end; &quot; +</span><br><span class="line">	  &quot;return redis.call(&#39;pttl&#39;, KEYS[1]);&quot;,</span><br><span class="line">	    Collections.&lt;Object&gt;singletonList(getName()), internalLockLeaseTime, getLockName(threadId));</span><br></pre></td></tr></table></figure>

<p><strong>redis.call()的第一个参数表示要执行的命令，KEYS[1]表示要加锁的key值，ARGV[1]表示key的生存时间，默认时30秒，ARGV[2]表示加锁的客户端的ID。</strong></p>
<p>比如第一行中<code>redis.call(&#39;exists&#39;, KEYS[1]) == 0)</code> 表示执行exists命令判断Redis中是否含有KEYS[1]，这个还是比较好理解的。</p>
<p>lua脚本中封装了要执行的业务逻辑代码，它能够保证执行业务代码的原子性，它通过<code>hset lockName</code>命令完成加锁。</p>
<p>若是第一个客户端已经通过<code>hset</code>命令成功加锁，当第二个客户端继续执行lua脚本时，会发现锁已经被占用，就会通过<code>pttl myLock</code>返回第一个客户端的持锁生存时间。</p>
<p>若是还有生存时间，表示第一个客户端会继续持有锁，那么第二个客户端就会不停的自旋尝试取获取锁。</p>
<p>假如第一个客户端持有锁的时间快到期了，想继续持有锁，可以给它启动一个<code>watch dog</code>看门狗，他是一个后台线程会每隔10秒检查一次，可以不断的延长持有锁的时间。</p>
<p><code>Redisson</code>中可重入锁的实现是通过<code>incrby lockName</code>来实现，<strong>重入一个计数就会+1，释放一次锁计数就会-1</strong>。</p>
<p>最后，使用完锁后执行<code>del lockName</code>就可以直接<strong>释放锁</strong>，这样其它的客户端就可以争抢到该锁了。</p>
<p>这就是分布式锁的开源Redisson框架底层锁机制的实现原理，我们可以在生产中实现该框架实现分布式锁的高效使用。</p>
<p>下面通过一个多窗口抢票的例子代码来实现：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line">public class SellTicket implements Runnable &#123;</span><br><span class="line">    private int ticketNum &#x3D; 1000;</span><br><span class="line">    RLock lock &#x3D; getLock();</span><br><span class="line">    &#x2F;&#x2F; 获取锁 </span><br><span class="line">    private RLock getLock() &#123;</span><br><span class="line">        Config config &#x3D; new Config();</span><br><span class="line">        config.useSingleServer().setAddress(&quot;redis:&#x2F;&#x2F;localhost:6379&quot;);</span><br><span class="line">        Redisson redisson &#x3D; (Redisson) Redisson.create(config);</span><br><span class="line">        RLock lock &#x3D; redisson.getLock(&quot;keyName&quot;);</span><br><span class="line">        return lock;</span><br><span class="line">    &#125;</span><br><span class="line"> </span><br><span class="line">    @Override</span><br><span class="line">    public void run() &#123;</span><br><span class="line">        while (ticketNum&gt;0) &#123;</span><br><span class="line">            &#x2F;&#x2F; 获取锁,并设置超时时间</span><br><span class="line">            lock.lock(1, TimeUnit.MINUTES);</span><br><span class="line">            try &#123;</span><br><span class="line">                if (ticketNum&gt; 0) &#123;</span><br><span class="line">                    System.out.println(Thread.currentThread().getName() + &quot;出售第 &quot; + ticketNum-- + &quot; 张票&quot;);</span><br><span class="line">                &#125;</span><br><span class="line">            &#125; finally &#123;</span><br><span class="line">                lock.unlock(); &#x2F;&#x2F; 释放锁</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>测试的代码如下：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">public class Test &#123;</span><br><span class="line">    public static void main(String[] args) &#123;</span><br><span class="line">        SellTicket sellTick&#x3D; new SellTicket();</span><br><span class="line">        &#x2F;&#x2F; 开启5五条线程，模拟5个窗口</span><br><span class="line">        for (int i&#x3D;1; i&lt;&#x3D;5; i++) &#123;</span><br><span class="line">            new Thread(sellTick, &quot;窗口&quot; + i).start();</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>是不是感觉很简单，因为多线程竞争共享资源的复杂的过程它在底层都帮你实现了，屏蔽了这些复杂的过程，而你也就成为了优秀的API调用者。</p>
<p>上面就是Redis三种方式实现分布式锁的方式，基于Redis的实现方式基本都会选择Redisson的方式进行实现，因为简单命令，不用自己拧螺丝，开箱即用。</p>
</div><div class="index-category-tag">  <hr></div></article></div><nav class="pagination" role="navigation" aria-label="pagination"><div class="pagination-previous"><a href="/">Previous</a></div><div class="pagination-next is-invisible is-hidden-mobile"><a href="/page/3/">Next</a></div><ul class="pagination-list is-hidden-mobile"><li><a class="pagination-link" href="/">1</a></li><li><a class="pagination-link is-current" href="/page/2/">2</a></li></ul></nav></div><div class="column column-left is-4-tablet is-4-desktop is-3-widescreen  order-1 is-sticky"><!--!--><div class="card widget" data-type="profile"><div class="card-content"><nav class="level"><div class="level-item has-text-centered flex-shrink-1"><div><figure class="image is-128x128 mx-auto mb-2"><img class="avatar is-rounded" src="https://pic1.zhimg.com/v2-bfd9b8d48b2d2ef0bcd80d2cc4cc6604_xl.jpg" alt="黎杜"></figure><p class="title is-size-4 is-block" style="line-height:inherit;">黎杜</p><p class="is-size-6 is-block">一个钻研技术和热爱分享的博主</p><p class="is-size-6 is-flex justify-content-center"><i class="fas fa-map-marker-alt mr-1"></i><span>广东.广州</span></p></div></div></nav><nav class="level is-mobile"><div class="level-item has-text-centered is-marginless"><div><p class="heading">Posts</p><a href="/archives"><p class="title">14</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">Categories</p><a href="/categories"><p class="title">0</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">Tags</p><a href="/tags"><p class="title">0</p></a></div></div></nav><div class="level"><a class="level-item button is-primary is-rounded" href="https://github.com/ppoffice" target="_blank" rel="noopener">Follow</a></div><div class="level is-mobile"><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Github" href="https://github.com/"><i class="fab fa-github"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Weibo" href="https://weibo.com/u/2084518621?is_all=1"><i class="fab fa-weibo"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Email" href="/730500468@qq.com"><i class="fa fa-envelope"></i></a></div><div><hr><p id="hitokoto">:D 一言句子获取中...</p><script type="text/javascript" defer>function getYiyan(){
                                $.getJSON("https://v1.hitokoto.cn/", function (data) {
                                if(data){
                                    $('#hitokoto').html("");
                                    $('#hitokoto').append("<strong style='color: #3273dc;'>"+data.hitokoto+"</strong>"+
                                    "<p>"+"From《"+data.from+"》</p><p>Provider-"+data.creator+"</p>");
                                }});}
                                $(function (){getYiyan();$('#hitokoto').click(function(){getYiyan();})});</script></div></div></div><div class="card widget" data-type="links"><div class="card-content"><div class="menu"><h3 class="menu-label">Links</h3><ul class="menu-list"><li><a class="level is-mobile" href="https://hexo.io" target="_blank" rel="noopener"><span class="level-left"><span class="level-item">Hexo</span></span><span class="level-right"><span class="level-item tag">hexo.io</span></span></a></li><li><a class="level is-mobile" href="https://bulma.io" target="_blank" rel="noopener"><span class="level-left"><span class="level-item">Bulma</span></span><span class="level-right"><span class="level-item tag">bulma.io</span></span></a></li></ul></div></div></div><div class="column-right-shadow is-hidden-widescreen"></div></div><div class="column column-right is-4-tablet is-4-desktop is-3-widescreen is-hidden-touch is-hidden-desktop-only order-3"><div class="card widget"><div class="card-content"><h3 class="menu-label">Latest Comment</h3><span class="body_hot_comment">Loading...Wait a Minute!</span></div></div><div class="card widget"><div class="card-content"><h3 class="menu-label">Recents</h3><article class="media"><div class="media-content"><p class="date"><time dateTime="2020-10-14T10:04:30.012Z">2020-10-14</time></p><p class="title"><a href="/2020/10/14/JAVA%20%E7%BA%BF%E4%B8%8A%E6%95%85%E9%9A%9C%E6%8E%92%E6%9F%A5%E5%AE%8C%E6%95%B4%E5%A5%97%E8%B7%AF%EF%BC%8C%E4%BB%8E%20CPU%E3%80%81%E7%A3%81%E7%9B%98%E3%80%81%E5%86%85%E5%AD%98%E3%80%81%E7%BD%91%E7%BB%9C%E3%80%81GC%20%E4%B8%80%E6%9D%A1%E9%BE%99%EF%BC%81/"> </a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2020-10-14T10:04:20.188Z">2020-10-14</time></p><p class="title"><a href="/2020/10/14/%E5%9B%BE%E7%89%87%E5%AD%98%E5%82%A8%E6%96%B9%E6%A1%88%E5%AE%9E%E6%88%98%E6%95%99%E7%A8%8B-%E4%B8%83%E7%89%9B%E4%BA%91%E5%AD%98%E5%82%A8/"> </a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2020-10-14T10:01:35.526Z">2020-10-14</time></p><p class="title"><a href="/2020/10/14/%E4%B8%80%E6%96%87%E6%90%9E%E6%87%82TCP-IP%E5%92%8CHTTP%E3%80%81HTTPS/"> </a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2020-10-14T10:01:31.281Z">2020-10-14</time></p><p class="title"><a href="/2020/10/14/%E8%BF%98%E5%9C%A8%E5%AD%A6JVM%EF%BC%9F%E6%88%91%E9%83%BD%E5%B8%AE%E4%BD%A0%E6%80%BB%E7%BB%93%E5%A5%BD%E4%BA%86%EF%BC%88%E9%99%84%E8%84%91%E5%9B%BE%EF%BC%89/"> </a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2020-10-14T10:01:28.566Z">2020-10-14</time></p><p class="title"><a href="/2020/10/14/%E5%88%AB%E5%86%8D%E9%97%AE%E6%88%91Redis%E5%86%85%E5%AD%98%E6%BB%A1%E4%BA%86%E8%AF%A5%E6%80%8E%E4%B9%88%E5%8A%9E%E4%BA%86/"> </a></p></div></article></div></div><!--!--><div class="card widget"><div class="card-content"><div class="menu"><h3 class="menu-label">Archives</h3><ul class="menu-list"><li><a class="level is-mobile is-marginless" href="/archives/2020/10/"><span class="level-start"><span class="level-item">October 2020</span></span><span class="level-end"><span class="level-item tag">14</span></span></a></li></ul></div></div></div><!--!--><div class="card widget" data-type="subscribe-email"><div class="card-content"><div class="menu"><h3 class="menu-label">Subscribe for updates</h3><form action="https://feedburner.google.com/fb/a/mailverify" method="post" target="popupwindow" onsubmit="window.open(&#039;https://feedburner.google.com/fb/a/mailverify?uri=&#039;,&#039;popupwindow&#039;,&#039;scrollbars=yes,width=550,height=520&#039;);return true"><input type="hidden" value="" name="uri"><input type="hidden" name="loc" value="en_US"><div class="field has-addons"><div class="control has-icons-left is-expanded"><input class="input" name="email" type="email" placeholder="Email"><span class="icon is-small is-left"><i class="fas fa-envelope"></i></span></div><div class="control"><input class="button" type="submit" value="Subscribe"></div></div></form></div></div></div><!--!--></div></div></div></section><footer class="footer"><div class="container"><div class="level"><div class="level-start"><a class="footer-logo is-block mb-2" href="/"><img src="https://cdn.jsdelivr.net/gh/removeif/removeif-demo@latest/img/logo.png" alt="非科班的科班" height="28"></a><p class="size-small"><span>&copy; 2020 黎杜</span>  Powered by <a href="https://hexo.io/" target="_blank">Hexo</a> &amp; <a href="https://github.com/ppoffice/hexo-theme-icarus" target="_blank">Icarus</a> &amp; <a href="https://github.com/removeif/hexo-theme-amazing" target="_blank">Amazing</a> <br><span>© <a href="http://www.beian.miit.gov.cn/" target="_blank">川ICP备88888888号-8（测试）</a><br></span><span>© 版权说明：[本网站所有内容均收集于互联网或自己创作,<br />&nbsp;&nbsp;&nbsp;&nbsp;方便于网友与自己学习交流，如有侵权，请<a href="/message" target="_blank">留言</a>，立即处理]<br /></span><span><span id="statistic-times">loading...</span><script>function createTime(time) {
            var n = new Date(time);
            now.setTime(now.getTime() + 250),
                days = (now - n) / 1e3 / 60 / 60 / 24,
                dnum = Math.floor(days),
                hours = (now - n) / 1e3 / 60 / 60 - 24 * dnum,
                hnum = Math.floor(hours),
            1 == String(hnum).length && (hnum = "0" + hnum),
                minutes = (now - n) / 1e3 / 60 - 1440 * dnum - 60 * hnum,
                mnum = Math.floor(minutes),
            1 == String(mnum).length && (mnum = "0" + mnum),
                seconds = (now - n) / 1e3 - 86400 * dnum - 3600 * hnum - 60 * mnum,
                snum = Math.round(seconds),
            1 == String(snum).length && (snum = "0" + snum),
                document.getElementById("statistic-times").innerHTML = "❤️Site from <strong>"+time.split(" ")[0].replace(/\//g,".")+"</strong> has existed <strong>" + dnum + "</strong> d <strong>" + hnum + "</strong> h <strong>" + mnum + "</strong> m <strong>" + snum + "</strong> s！❤️";
        }var now = new Date();setInterval("createTime('2018/11/11 00:00:00')", 250,"");</script><br></span><div class="size-small"><span>❤️Thx <strong><span id="busuanzi_value_site_uv">99+</span></strong> users <strong><span id="busuanzi_value_site_pv">99+</span></strong> visited！❤️</span></div></p></div><div class="level-end"><div class="field has-addons"><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Creative Commons" href="https://creativecommons.org/"><i class="fab fa-creative-commons"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Attribution 4.0 International" href="https://creativecommons.org/licenses/by/4.0/"><i class="fab fa-creative-commons-by"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Download on GitHub" href="https://github.com/removeif/hexo-theme-amazing"><i class="fab fa-github"></i></a></p></div><div class="sideMusic"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/aplayer/dist/APlayer.min.css"><script src="/js/APlayer.min.js"></script><script src="https://cdn.jsdelivr.net/npm/meting@2/dist/Meting.min.js"></script><meting-js style="width: auto;height: 2000px;" server="netease" type="playlist" id="2364053447" theme="#2980b9" loop="all" autoplay="false" order="list" storageName="aplayer-setting" lrctype="0" list-max-height="400px" fixed="true"></meting-js></div></div></div></div></footer><script src="https://cdnjs.loli.net/ajax/libs/moment.js/2.22.2/moment-with-locales.min.js"></script><script src="https://cdnjs.loli.net/ajax/libs/clipboard.js/2.0.4/clipboard.min.js" async></script><script>moment.locale("en");</script><script>var IcarusThemeSettings = {
            article: {
                highlight: {
                    clipboard: true,
                    fold: 'folded'
                }
            }
        };</script><script src="/js/column.js"></script><script src="/js/animation.js"></script><a id="back-to-top" title="Back to top" href="javascript:;"><i class="fas fa-chevron-up"></i></a><script src="/js/back_to_top.js" defer></script><!--!--><!--!--><!--!--><script src="https://cdnjs.loli.net/ajax/libs/lightgallery/1.6.8/js/lightgallery.min.js" defer></script><script src="https://cdnjs.loli.net/ajax/libs/justifiedGallery/3.7.0/js/jquery.justifiedGallery.min.js" defer></script><script>window.addEventListener("load", () => {
            if (typeof $.fn.lightGallery === 'function') {
                $('.article').lightGallery({ selector: '.gallery-item' });
            }
            if (typeof $.fn.justifiedGallery === 'function') {
                if ($('.justified-gallery > p > .gallery-item').length) {
                    $('.justified-gallery > p > .gallery-item').unwrap();
                }
                $('.justified-gallery').justifiedGallery();
            }
        });</script><!--!--><!--!--><!--!--><script src="/js/main.js" defer></script><script>$.getScript('/js/comment-issue-data.js',function(){loadIssueData('46a9f3481b46ea0129d8','79c7c9cb847e141757d7864453bcbf89f0655b24','黎杜','blog_comment',false);})</script><div class="searchbox"><div class="searchbox-container"><div class="searchbox-header"><div class="searchbox-input-container"><input class="searchbox-input" type="text" placeholder="Type something..."></div><a class="searchbox-close" href="javascript:;">×</a></div><div class="searchbox-body"></div></div></div><script src="/js/insight.js" defer></script><script>document.addEventListener('DOMContentLoaded', function () {
            loadInsight({"contentUrl":"/content.json"}, {"hint":"Type something...","untitled":"(Untitled)","posts":"Posts","pages":"Pages","categories":"Categories","tags":"Tags"});
        });</script><script src="https://cdn.jsdelivr.net/npm/pjax@0.2.8/pjax.js"></script><script type="text/javascript">var pjax = new Pjax({
            elements: "a",//代表点击链接就更新
            selectors: [  //代表要更新的节点
                ".section",
                "title"
            ],
            cache: true,
            cacheBust:false
        })

        function loadBusuanzi(){
        $.getScript("//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js", function () {});
        }

        // 开始 PJAX 执行的函数
        document.addEventListener('pjax:send', function () {
        });
        
        // PJAX 完成之后执行的函数，可以和上面的重载放在一起
        document.addEventListener('pjax:complete', function () {
            $(".section").css({opacity:1});
            if(true){
                $.getScript('/js/comment-issue-data.js',function(){loadIssueData('46a9f3481b46ea0129d8','79c7c9cb847e141757d7864453bcbf89f0655b24','黎杜','blog_comment',false);});
            }
            if(false){
                loadMathJax();
            }
            loadMainJs(jQuery, window.moment, window.ClipboardJS, window.IcarusThemeSettings);
            loadBackTop();
            loadBusuanzi();
            if(typeof loadBanner == 'function'){
                loadBanner();
            }
        });</script></body></html>